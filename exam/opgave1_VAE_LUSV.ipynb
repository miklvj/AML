{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN7S7WVQZUZO"
      },
      "source": [
        "#### Loading and preparing the PCam data for training deep learning models using tensorflow dataset (tfds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75GMaV43ZUZP"
      },
      "source": [
        "Loading the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwYxBsjXZUZQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "# Please use the following line after importing TensorFlow to enable run function eagerly as you attempt\n",
        "# to utilize the function decorator in TF 2.0:\n",
        "tf.config.run_functions_eagerly(True)\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWJoR1_oZUZQ"
      },
      "source": [
        "Defining a function that splits images and labels and one-hot-encodes the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBKDXK9sZUZR"
      },
      "outputs": [],
      "source": [
        "def convert_sample(sample, mode):\n",
        "    if mode == 'autoencoder':\n",
        "        image, label = sample['image'], sample['image']\n",
        "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "        label = tf.image.convert_image_dtype(label, tf.float32)\n",
        "    elif mode == 'classifier':     \n",
        "        image, label = sample['image'], sample['label']\n",
        "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "        label = tf.one_hot(label, 2, dtype=tf.float32)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading data from your path\n",
        "Remember to change to the correct destination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s87QMCspZUZR"
      },
      "outputs": [],
      "source": [
        "ds1,ds2,ds3 = tfds.load('patch_camelyon',split=['train[:20%]','test[:5%]','validation[:5%]'],\n",
        "                        data_dir = 'D:/data',\n",
        "                        download=False,\n",
        "                        shuffle_files=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dpsruvlZUZS"
      },
      "source": [
        "Next we simple transform the data (by the function convert sample described previously) and getting ready for training by splitting it into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvFSb5XgZUZS"
      },
      "outputs": [],
      "source": [
        "train_dataset       = ds1.map(lambda x: convert_sample(x, 'autoencoder')).batch(32)\n",
        "validation_dataset  = ds3.map(lambda x: convert_sample(x, 'autoencoder')).batch(32)\n",
        "test_dataset        = ds2.map(lambda x: convert_sample(x, 'autoencoder')).batch(32)\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining a function that splits the dataset to x(images) and y(labels) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#def split_dataset_2_xy(dataset):\n",
        "#    x = []\n",
        "#    y = []\n",
        "#    for inputs, labels in dataset:\n",
        "#        x.append(inputs.numpy())\n",
        "#        y.append(labels.numpy())\n",
        "#    # Convert lists to numpy arrays\n",
        "#    x = np.concatenate(x, axis=0)\n",
        "#    y = np.argmax(np.concatenate(y, axis=0),axis=1)\n",
        "#    x = (tf.data.Dataset.from_tensor_slices(x).batch(32))\n",
        "#    y = (tf.data.Dataset.from_tensor_slices(y).batch(32))\n",
        "#    return x,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Printing the dimentions of the datasplits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch in train_dataset.take(1):\n",
        "    print(batch[0].shape)  # prints the shape of the inputs in the first batch\n",
        "    print(batch[1].shape)  # prints the shape of the target in the first batch\n",
        "for batch in validation_dataset.take(1):\n",
        "    print(batch[0].shape)  # prints the shape of the inputs in the first batch\n",
        "    print(batch[1].shape)  # prints the shape of the target in the first batch\n",
        "for batch in test_dataset.take(1):\n",
        "    print(batch[0].shape)  # prints the shape of the inputs in the first batch\n",
        "    print(batch[1].shape)  # prints the shape of the target in the first batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Defining a function to plot the first 10 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_10(x):\n",
        "    n = 10\n",
        "    plt.figure(figsize=(20, 2))\n",
        "    for i in range(n):\n",
        "        ax = plt.subplot(1, n, i + 1)\n",
        "        plt.title(str(i + 1))\n",
        "        plt.imshow(tf.squeeze(x[i]))\n",
        "        plt.gray()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plotting the first 10 images in training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch in train_dataset.take(1):\n",
        "    plot_10(batch[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Defining our AE\n",
        "\n",
        "creating af function to use in a hyperparameter selection setting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_autoencoder(nb_layers=2, nb_filters=[32,32], kernel_size=(3,3), input_shape=(96,96,3), batch_normalization=False, Regularization=None, optimizer='adam'):\n",
        "    encoder = tf.keras.Sequential(name='encoder')\n",
        "    encoder.add(tf.keras.layers.Conv2D(filters=nb_filters[0],\n",
        "                                       kernel_size=kernel_size,\n",
        "                                       strides=2, padding='same',\n",
        "                                       activation='relu',\n",
        "                                       input_shape=input_shape))\n",
        "    for i in range(1,nb_layers):\n",
        "        if Regularization == 'l1':\n",
        "            encoder.add(tf.keras.layers.Conv2D(filters=nb_filters[i],\n",
        "                                               kernel_size=kernel_size,\n",
        "                                               strides=2,\n",
        "                                               padding='same',\n",
        "                                               activation='relu',\n",
        "                                               activity_regularizer=tf.keras.regularizers.l1(10e-5)))\n",
        "        elif Regularization == 'l2':\n",
        "            encoder.add(tf.keras.layers.Conv2D(filters=nb_filters[i],\n",
        "                                               kernel_size=kernel_size,\n",
        "                                               strides=2,\n",
        "                                               padding='same',\n",
        "                                               activation='relu',\n",
        "                                               activity_regularizer=tf.keras.regularizers.l2(10e-5)))\n",
        "        else:\n",
        "            encoder.add(tf.keras.layers.Conv2D(filters=nb_filters[i], kernel_size=kernel_size, strides=2, padding='same', activation='relu'))\n",
        "\n",
        "        if batch_normalization == True:\n",
        "            encoder.add(tf.keras.layers.BatchNormalization())\n",
        "    \n",
        "    encoder.add(tf.keras.layers.Conv2D(filters=1,\n",
        "                                       kernel_size=kernel_size,\n",
        "                                       strides=1,\n",
        "                                       padding='same',\n",
        "                                       activation='sigmoid'))\n",
        "    \n",
        "    decoder = tf.keras.Sequential(name='decoder')\n",
        "    decoder.add(tf.keras.layers.Conv2DTranspose(filters=nb_filters[-1],\n",
        "                                                kernel_size=kernel_size,\n",
        "                                                strides=2, padding='same',\n",
        "                                                activation='relu',\n",
        "                                                input_shape=(input_shape[0]//2**nb_layers,input_shape[1]//2**nb_layers,1)))\n",
        "    for i in range(nb_layers-2,-1,-1):\n",
        "        if Regularization == 'l1':\n",
        "            decoder.add(tf.keras.layers.Conv2DTranspose(filters=nb_filters[i],\n",
        "                                                        kernel_size=kernel_size,\n",
        "                                                        strides=2,\n",
        "                                                        padding='same',\n",
        "                                                        activation='relu',\n",
        "                                                        activity_regularizer=tf.keras.regularizers.l1(10e-5)))\n",
        "        elif Regularization == 'l2':\n",
        "            decoder.add(tf.keras.layers.Conv2DTranspose(filters=nb_filters[i],\n",
        "                                                        kernel_size=kernel_size,\n",
        "                                                        strides=2,\n",
        "                                                        padding='same',\n",
        "                                                        activation='relu',\n",
        "                                                        activity_regularizer=tf.keras.regularizers.l2(10e-5)))\n",
        "        else:\n",
        "            decoder.add(tf.keras.layers.Conv2DTranspose(filters=nb_filters[i], kernel_size=kernel_size, strides=2, padding='same', activation='relu'))\n",
        "        if batch_normalization == True:\n",
        "            decoder.add(tf.keras.layers.BatchNormalization())\n",
        "        \n",
        "    decoder.add(tf.keras.layers.Conv2DTranspose(filters=3,\n",
        "                                                kernel_size=kernel_size,\n",
        "                                                strides=1, padding='same',\n",
        "                                                activation='sigmoid'))\n",
        "\n",
        "    autoencoder = tf.keras.models.Sequential([encoder, decoder], name='autoencoder')\n",
        "    autoencoder.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
        "    \n",
        "    #encoder.summary() #only use these when testing the function\n",
        "    #decoder.summary() #only use these when testing the function\n",
        "    \n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# testing the function create_autoencoder:\n",
        "nb_layers = 4\n",
        "nb_filters_list = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "nb_filters = nb_filters_list[0:nb_layers]\n",
        "Regularization = 'l2'\n",
        "batch_normalization = True\n",
        "optimizer = 'adam'\n",
        "model = create_autoencoder(nb_layers, nb_filters, kernel_size, input_shape, batch_normalization, Regularization, optimizer)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train our autoencoder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# prepare list for storing results\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "train_mae = []\n",
        "val_mae = []\n",
        "\n",
        "# set epochs:\n",
        "epochs = 20 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "# set parameters for autoencoder\n",
        "nb_layers_list = [3,4]\n",
        "nb_filters_list = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "Regularizations = [None, 'l2']\n",
        "batch_normalizations = [True, False]\n",
        "optimizers = ['adam','rmsprop','adagrad']\n",
        "\n",
        "results = []\n",
        "\n",
        "# train model and store results and test models\n",
        "for nb_layers in nb_layers_list:\n",
        "    for Regularization in Regularizations:\n",
        "        for batch_normalization in batch_normalizations:\n",
        "            for optimizer in optimizers:\n",
        "                # create model\n",
        "                print(f'Creating and Training autoencoder-model with {nb_layers} layers in encoder and decoder, Regularization: {Regularization}, batch_normalization: {batch_normalization}, optimizer: {optimizer}')\n",
        "                # determine number of filters from nb_filters_list [32,32,32,32]\n",
        "                nb_filters = nb_filters_list[0:nb_layers]\n",
        "                model = create_autoencoder(nb_layers, nb_filters, kernel_size, input_shape, batch_normalization=batch_normalization, Regularization=Regularization, optimizer=optimizer)\n",
        "                model.summary()\n",
        "                # train model\n",
        "                hist = model.fit(train_dataset, epochs=epochs, validation_data=validation_dataset)\n",
        "                print(f'Training model with {nb_layers} layers done')\n",
        "                # store results\n",
        "                train_loss.append(hist.history['loss'])\n",
        "                val_loss.append(hist.history['val_loss'])\n",
        "                train_mae.append(hist.history['mae'])\n",
        "                val_mae.append(hist.history['val_mae'])\n",
        "                # print main results\n",
        "                print('loss: ', hist.history['val_loss'][0])\n",
        "                print('mae: ', hist.history['val_mae'][0])\n",
        "                # test model\n",
        "                for batch in test_dataset.take(1):\n",
        "                    y_test = model.predict(batch[0])\n",
        "                    plot_10(batch[0])\n",
        "                    plot_10(y_test)\n",
        "\n",
        "                    mse = tf.reduce_mean(tf.keras.losses.mse(y_test, batch[0]))\n",
        "                    mae = tf.reduce_mean(tf.keras.losses.mae(y_test, batch[0]))\n",
        "                    mse = round(mse.numpy().astype(float), 4)\n",
        "                    mae = round(mae.numpy().astype(float), 4)\n",
        "\n",
        "                results.append([nb_layers, Regularization, batch_normalization, optimizer, hist.history['val_loss'][0], hist.history['val_mae'][0], mse, mae])\n",
        "df_result = pd.DataFrame(results, columns=['nb_layers', 'Regularization', 'batch_normalization', 'optimizer', 'val_loss', 'val_mae', 'test_mse', 'test_mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_result = pd.DataFrame(results, columns=['nb_layers', 'Regularization', 'batch_normalization', 'optimizer', 'val_loss', 'val_mae', 'test_mse', 'test_mae'])\n",
        "df_result.sort_values(by=['test_mae'], inplace=True, ascending=True, ignore_index=True)\n",
        "df_result.to_csv('autoencoder_results.csv', index=False)\n",
        "print(df_result[0:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot results for the different models\n",
        "\n",
        "for i, result in enumerate(df_result.values[0:5]):\n",
        "    label = str(result[0]) + \" layers, \" + str(result[1]) + \", \" + str(result[2]) + \", \" + str(result[3])\n",
        "    plt.plot(train_loss[i], label=\"train: \" + label)\n",
        "    plt.plot(val_loss[i], label=\"val: \" + label)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(\"Top 5. Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "for i, result in enumerate(df_result.values[0:5]):\n",
        "    label = str(result[0]) + \" layers, \" + str(result[1]) + \", \" + str(result[2]) + \", \" + str(result[3])\n",
        "    plt.plot(train_mae[i], label=\"train: \" + label)\n",
        "    plt.plot(val_mae[i], label=\"val: \" + label)\n",
        "plt.legend()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MAE')\n",
        "plt.title(\"Top 5. MAE\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, latent_dim, encoder, decoder):\n",
        "        super(VAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "    \n",
        "    def encode(self, x):\n",
        "        params = self.encoder(x)\n",
        "        return tf.split(params, num_or_size_splits=2, axis=1) # mean, logvar\n",
        "        \n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "    \n",
        "    def reparameterize(self, mean, logvar):\n",
        "        eps = tf.random.normal(shape=mean.shape)\n",
        "        return eps * tf.exp(logvar * 0.5) + mean\n",
        "    \n",
        "    @tf.function\n",
        "    def sample(self, eps=None):\n",
        "        if eps is None:\n",
        "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "        return tf.sigmoid(self.decode(eps))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "    log2pi = tf.math.log(2. * np.pi)\n",
        "    vals = -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi)\n",
        "\n",
        "    return tf.reduce_sum(vals, axis=raxis)\n",
        "\n",
        "def compute_loss(model, x):\n",
        "    mean, logvar = model.encode(x)\n",
        "    z = model.reparameterize(mean, logvar)\n",
        "    x_logit = model.decode(z)\n",
        "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "    logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "    logpz = log_normal_pdf(z, 0., 0.)\n",
        "    logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "\n",
        "    return -tf.reduce_mean(logpx_z + logpz - logqz_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(model, x, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(model, x)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Showing Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_and_show_images(model, epoch, test_sample):\n",
        "    mean, logvar = model.encode(test_sample)\n",
        "    z = model.reparameterize(mean, logvar)\n",
        "    predictions = model.sample(z)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    #for i in range(predictions.shape[0]):\n",
        "    for i in range(16):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.suptitle(\"Predicted image\")\n",
        "\n",
        "    plt.show()\n",
        "    for i in range(16):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(test_sample[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.suptitle(\"Original image\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2D latensplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_2d_latent_images(model, n, image_size=28):\n",
        "    grid_x = tf.math.ndtri(np.linspace(0.05, 0.95, n))\n",
        "    grid_y = tf.math.ndtri(np.linspace(0.05, 0.95, n))\n",
        "    image_width = image_size * n\n",
        "    image_height = image_width\n",
        "    image = np.zeros((image_height, image_width))\n",
        "\n",
        "    for i, yi in enumerate(grid_x):\n",
        "        for j, xi in enumerate(grid_y):\n",
        "            z = np.array([[xi, yi]])\n",
        "            x_decoded = model.sample(z)\n",
        "            digit = tf.reshape(x_decoded[0], (image_size, image_size))\n",
        "            image[i * image_size: (i + 1) * image_size, j * image_size: (j + 1) * image_size] = digit.numpy()\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image, cmap='Greys_r')\n",
        "    plt.axis('Off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_VAE(latent_dim, nb_layers=2, nb_filters=[32,32], kernel_size=(3,3), input_shape=(96,96,3), batch_normalization=False, Regularization=None, optimizer=tf.keras.optimizers.Adam(1e-4)):\n",
        "#    encoder = tf.keras.models.Sequential([\n",
        "#        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), strides=2, activation='relu', padding='same', input_shape=(96, 96, 3)),\n",
        "#        tf.keras.layers.Conv2D(64, kernel_size=(3, 3), strides=2, activation='relu', padding='same',),\n",
        "#        tf.keras.layers.Flatten(),\n",
        "#        tf.keras.layers.Dense(2 * latent_dim), # 2 since we encode mean and standard deviation\n",
        "#    ])\n",
        "#    encoder.summary()\n",
        "#    decoder = tf.keras.models.Sequential([\n",
        "#        tf.keras.layers.Dense(units=24*24*32, activation='relu', input_shape=(latent_dim,)),\n",
        "#        tf.keras.layers.Reshape(target_shape=(24, 24, 32)), # To get in \"image format\"\n",
        "#        tf.keras.layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=2, padding='same', activation='relu'),\n",
        "#        tf.keras.layers.Conv2DTranspose(32, kernel_size=(3, 3), strides=2, padding='same', activation='relu'),\n",
        "#        tf.keras.layers.Conv2DTranspose(3, kernel_size=(3, 3), strides=1, padding='same'),\n",
        "#    ])\n",
        "#    decoder.summary()\n",
        "\n",
        "# ENCODER\n",
        "    encoder = tf.keras.Sequential(name='encoder')\n",
        "    encoder.add(tf.keras.layers.Conv2D(filters=nb_filters[0],\n",
        "                                       kernel_size=kernel_size,\n",
        "                                       strides=2, padding='same',\n",
        "                                       activation='relu',\n",
        "                                       input_shape=input_shape))\n",
        "    for i in range(1,nb_layers):\n",
        "        if Regularization == 'l1':\n",
        "            encoder.add(tf.keras.layers.Conv2D(filters=nb_filters[i],\n",
        "                                               kernel_size=kernel_size,\n",
        "                                               strides=2,\n",
        "                                               padding='same',\n",
        "                                               activation='relu',\n",
        "                                               activity_regularizer=tf.keras.regularizers.l1(10e-5)))\n",
        "        elif Regularization == 'l2':\n",
        "            encoder.add(tf.keras.layers.Conv2D(filters=nb_filters[i],\n",
        "                                               kernel_size=kernel_size,\n",
        "                                               strides=2,\n",
        "                                               padding='same',\n",
        "                                               activation='relu',\n",
        "                                               activity_regularizer=tf.keras.regularizers.l2(10e-5)))\n",
        "        else:\n",
        "            encoder.add(tf.keras.layers.Conv2D(filters=nb_filters[i], kernel_size=kernel_size, strides=2, padding='same', activation='relu'))\n",
        "\n",
        "        if batch_normalization == True:\n",
        "            encoder.add(tf.keras.layers.BatchNormalization())\n",
        "    \n",
        "    encoder.add(tf.keras.layers.Flatten())\n",
        "    encoder.add(tf.keras.layers.Dense(2 * latent_dim)) # 2 since we encode mean and standard deviation\n",
        "# END OF ENDODER\n",
        "\n",
        "# DECODER\n",
        "    decoder = tf.keras.Sequential(name='decoder')\n",
        "    decoder.add(tf.keras.layers.Dense(units=input_shape[0]//2**nb_layers*input_shape[1]//2**nb_layers*32,\n",
        "                          activation='relu',\n",
        "                          input_shape=(latent_dim,)))\n",
        "    decoder.add(tf.keras.layers.Reshape(target_shape=(input_shape[0]//2**nb_layers,input_shape[1]//2**nb_layers,32))) # To get in \"image format\"\n",
        "    \n",
        "    for i in range(nb_layers-1,-1,-1):\n",
        "        if Regularization == 'l1':\n",
        "            decoder.add(tf.keras.layers.Conv2DTranspose(filters=nb_filters[i],\n",
        "                                                        kernel_size=kernel_size,\n",
        "                                                        strides=2,\n",
        "                                                        padding='same',\n",
        "                                                        activation='relu',\n",
        "                                                        activity_regularizer=tf.keras.regularizers.l1(10e-5)))\n",
        "        elif Regularization == 'l2':\n",
        "            decoder.add(tf.keras.layers.Conv2DTranspose(filters=nb_filters[i],\n",
        "                                                        kernel_size=kernel_size,\n",
        "                                                        strides=2,\n",
        "                                                        padding='same',\n",
        "                                                        activation='relu',\n",
        "                                                        activity_regularizer=tf.keras.regularizers.l2(10e-5)))\n",
        "        else:\n",
        "            decoder.add(tf.keras.layers.Conv2DTranspose(filters=nb_filters[i], kernel_size=kernel_size, strides=2, padding='same', activation='relu'))\n",
        "        if batch_normalization == True:\n",
        "            decoder.add(tf.keras.layers.BatchNormalization())\n",
        "    \n",
        "    decoder.add(tf.keras.layers.Conv2DTranspose(filters=3,\n",
        "                                                kernel_size=kernel_size,\n",
        "                                                strides=1, padding='same',\n",
        "                                                activation='sigmoid'))\n",
        "    encoder.summary()\n",
        "    decoder.summary()\n",
        "# END OF DECODER\n",
        "    model = VAE(latent_dim, encoder, decoder)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [3]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [False]\n",
        "Regularization = [None]\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n",
        "#df_result = pd.DataFrame(results, columns=['latent_dim', 'nb_layers', 'Regularization', 'batch_normalization', 'optimizer', 'variational_lower_bound'])\n",
        "#df_result.sort_values(by=['variational_lower_bound'], inplace=True, ascending=False, ignore_index=True)\n",
        "#df_result.to_csv('VAE_results.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [3]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [False]\n",
        "Regularization = ['l2']\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [3]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [False]\n",
        "Regularization = ['l1']\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [3]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [True]\n",
        "Regularization = [None]\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [3]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [True]\n",
        "Regularization = ['l2']\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [3]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [True]\n",
        "Regularization = ['l1']\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [4]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [False]\n",
        "Regularization = [None]\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [4]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [False]\n",
        "Regularization = ['l2']\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [4]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [False]\n",
        "Regularization = ['l1']\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [4]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [True]\n",
        "Regularization = [None]\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [4]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [True]\n",
        "Regularization = ['l2']\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "latent_dims = [25]\n",
        "nb_layers = [4]\n",
        "nb_filters = [32,32,32,32]\n",
        "kernel_size = (3,3)\n",
        "input_shape = (96,96,3)\n",
        "batch_normalization = [True]\n",
        "Regularization = ['l1']\n",
        "optimizers = [tf.keras.optimizers.Adam(1e-4), tf.keras.optimizers.RMSprop(1e-4), tf.keras.optimizers.Adagrad(1e-4)]\n",
        "\n",
        "for batch in test_dataset.take(1):\n",
        "    test_sample = batch[0]\n",
        "\n",
        "epochs = 50 # EDIT THIS TO CHANGE NUMBER OF EPOCHS BEFORE RUNNING\n",
        "\n",
        "results = []\n",
        "\n",
        "for latent_dim in latent_dims:\n",
        "    for nb_layer in nb_layers:\n",
        "        for batch_norm in batch_normalization:\n",
        "            for reg in Regularization:\n",
        "                for opt in optimizers:\n",
        "                    model = create_VAE(latent_dim, nb_layer, nb_filters, kernel_size, input_shape, batch_norm, reg)\n",
        "                    print(f'Creating and Training VAE-model with {latent_dim} latent dimensions, {nb_layer} layers in encoder and decoder, batch_normalization: {batch_norm}, Regularization: {reg}, optimizer: {opt}')\n",
        "\n",
        "                    for epoch in range(epochs):\n",
        "                        start_time = time.time()\n",
        "                        \n",
        "                        for x in train_dataset:\n",
        "                            train_step(model, x[0], opt)\n",
        "\n",
        "                        loss = tf.keras.metrics.Mean()\n",
        "                        for x in validation_dataset:\n",
        "                            loss(compute_loss(model, x[0]))\n",
        "                        variational_lower_bound = -loss.result()\n",
        "\n",
        "                        end_time = time.time()\n",
        "                        elapsed_time = end_time - start_time\n",
        "\n",
        "                        print(f'Epoch: {epoch+1}, Test set variational lower bound: {variational_lower_bound}, Time: {elapsed_time/60} minuts')\n",
        "                        generate_and_show_images(model, epoch, test_sample)\n",
        "                    \n",
        "\n",
        "                    results.append([latent_dim, nb_layers, Regularization, batch_normalization, opt, variational_lower_bound])\n",
        "df_result = pd.DataFrame(results, columns=['latent_dim', 'nb_layers', 'Regularization', 'batch_normalization', 'opt', 'variational_lower_bound'])\n",
        "df_result.sort_values(by=['variational_lower_bound'], inplace=True, ascending=False, ignore_index=True)\n",
        "df_result.to_csv('VAE_results.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "amlfall22",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d3cedec8935a2c28d6fd602c3007747750e2af1c4c937c29fac0d323bf1b544b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
