{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xBc3Nlkrq21l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT96upgorjQC",
        "outputId": "bea8530c-055f-4810-ebc9-1f3d315efdf5"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Jh-u1rsZc6",
        "outputId": "fe1aec60-a55d-45fd-efb8-e10fe330b64e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "datasets = ['All_Beauty_5', 'AMAZON_FASHION_5', 'Arts_Crafts_and_Sewing_5', 'Clothing_Shoes_and_Jewelry_5', 'Luxury_Beauty_5']\n",
        "\n",
        "for i in datasets:\n",
        "    input_file = f'D:/aml_data/{i}.json'\n",
        "    output_file = f'D:/aml_data/{i}.csv'\n",
        "\n",
        "    with open(input_file, \"r\", encoding=\"utf-8\") as input_json, open(output_file, \"w\", encoding=\"utf-8\") as output_csv:\n",
        "        csv_writer = csv.writer(output_csv)\n",
        "        flag = 0\n",
        "        for line in input_json:\n",
        "                dic = json.loads(line)\n",
        "                if flag == 0:\n",
        "                    csv_writer.writerow(dic.keys())\n",
        "                    flag = 1\n",
        "                csv_writer.writerow(dic.values())\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_TgD2Uit07s0"
      },
      "outputs": [],
      "source": [
        "df_1 = pd.read_csv('D:/aml_data//All_Beauty_5.csv', usecols=['overall', 'reviewText', \"summary\"])\n",
        "df_2 = pd.read_csv('D:/aml_data//AMAZON_FASHION_5.csv', usecols=['overall', 'reviewText', \"summary\"])\n",
        "df_3 = pd.read_csv('D:/aml_data//Arts_Crafts_and_Sewing_5.csv', usecols=['overall', 'reviewText', \"summary\"])\n",
        "df_4 = pd.read_csv('D:/aml_data//Clothing_Shoes_and_Jewelry_5.csv', usecols=['overall', 'reviewText', \"summary\"])\n",
        "df_test = pd.read_csv('D:/aml_data//Luxury_Beauty_5.csv', usecols=['overall', 'reviewText', \"summary\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "be6nafmI1UnZ"
      },
      "outputs": [],
      "source": [
        "df_train = pd.concat([df_1, df_2, df_3, df_4], axis=0, ignore_index=True)\n",
        "df_train = df_train.dropna()\n",
        "df_test = df_test.dropna()\n",
        "\n",
        "df_train = df_train[df_train[\"overall\"] != '3']\n",
        "df_train[\"label\"] = df_train[\"overall\"].apply(lambda rating : 1 if str(rating) > '3' else 0)\n",
        "\n",
        "df_test = df_test[df_test[\"overall\"] != '3']\n",
        "df_test[\"label\"] = df_test[\"overall\"].apply(lambda rating : 1 if str(rating) > '3' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw1ECvN_G725",
        "outputId": "beccf83e-608b-45b9-b75f-5996e8ec7338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First review = As advertised. Reasonably priced\n",
            "First review has length = 32\n",
            " \n",
            "First review overall rating = 5.0\n",
            "First review binary rating = 1\n"
          ]
        }
      ],
      "source": [
        "print(f'First review = {df_train.loc[0, \"reviewText\"]}')\n",
        "print(f'First review has length = {len(df_train.loc[0, \"reviewText\"])}\\n ')\n",
        "print(f'First review overall rating = {df_train.loc[0, \"overall\"]}')\n",
        "print(f'First review binary rating = {df_train.loc[0, \"label\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.9.1\n",
            "Num GPUs Available:  1\n",
            "Name: /physical_device:GPU:0   Type: GPU\n"
          ]
        }
      ],
      "source": [
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "\n",
        "# Check available GPUs\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(gpus))\n",
        "for gpu in gpus:\n",
        "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = pd.DataFrame(df_train, columns = [\"reviewText\"])\n",
        "y = pd.DataFrame(df_train, columns = [\"label\"])\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(X, y, train_size=0.8, random_state=50, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_Xtrain = pd.DataFrame(train_x,columns=['reviewText'])\n",
        "df_ytrain = pd.DataFrame(train_y,columns=['label'])\n",
        "df_train = pd.concat([df_ytrain, df_Xtrain], axis=1)\n",
        "df_Xval = pd.DataFrame(val_x,columns=['reviewText'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8111964\n",
            "2027992\n",
            "         label                reviewText\n",
            "2567756      1           Nice sunglasses\n",
            "6585046      1            Fits perfectly\n",
            "7522833      0  You get what you pay for\n",
            "1465266      1              Soft leather\n",
            "6909483      1                Five Stars\n",
            "                       reviewText\n",
            "7259421  Durable and Easy to Move\n",
            "8237271      I Love these sandals\n",
            "6135424                Five Stars\n",
            "4290872                Five Stars\n",
            "9102221      A Very Good T- shirt\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train))\n",
        "print(len(df_Xval))\n",
        "\n",
        "print(df_train.head())\n",
        "print(df_Xval.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6BU0DZ5YwUd"
      },
      "source": [
        "**Train:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "HuKFli3cS9rk",
        "outputId": "949464c3-052e-4eca-8e43-4b1eade2f512"
      },
      "outputs": [],
      "source": [
        "max_tokens = 1000\n",
        "output_sequence_length = 100\n",
        "pad_to_max_tokens = True\n",
        "\n",
        "df_train['reviewText'] = df_train['reviewText'].fillna('').astype(str)\n",
        "\n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=max_tokens, output_sequence_length=output_sequence_length, pad_to_max_tokens=pad_to_max_tokens)\n",
        "\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(df_train['reviewText']).batch(128)\n",
        "encoder.adapt(text_ds)\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((df_train['reviewText'], df_train['label'])).batch(128)\n",
        "train_ds = train_ds.map(lambda x, y: (encoder(x), y))\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmMRzcUZYy5t"
      },
      "source": [
        "**Test:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZvC5ATWQYEZZ"
      },
      "outputs": [],
      "source": [
        "df_Xval['reviewText'] = df_Xval['reviewText'].fillna('').astype(str)\n",
        "\n",
        "text_test_ds = tf.data.Dataset.from_tensor_slices(df_Xval['reviewText']).batch(128)\n",
        "df_val = text_test_ds.map(lambda x: encoder(x))\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "test_ds = df_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<PrefetchDataset element_spec=TensorSpec(shape=(None, 100), dtype=tf.int64, name=None)>\n"
          ]
        }
      ],
      "source": [
        "print(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJHXolZMaiGE",
        "outputId": "453cb0a9-a377-473b-8228-8b1a5cebe318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: [ 34 691   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [ 79 192   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [ 37  77  76  37 538  10   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 0\n",
            "---\n",
            "Review: [118 204   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [7 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Label: 1\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(\"Review:\", text_batch.numpy()[i])\n",
        "        print(\"Label:\", label_batch.numpy()[i])\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEWOA2I2a8vj",
        "outputId": "70456fac-5e74-42bf-bae9-eb4672ec1d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          128000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 256)         263168    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                82176     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 477,569\n",
            "Trainable params: 477,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_dimension = 128\n",
        "embedding_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(vocab),\n",
        "                              output_dim=embedding_dimension,\n",
        "                              input_length=100,\n",
        "                              name=\"embedding\"),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "embedding_model.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "embedding_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ieu95iXJesc-",
        "outputId": "47166155-12e6-4f91-a5bc-af2dcf86901c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension of the embedding vector: \n",
            "(1000, 128)\n"
          ]
        }
      ],
      "source": [
        "embedding_weights = embedding_model.get_layer('embedding').get_weights()[0]\n",
        "print(f'Dimension of the embedding vector: \\n{embedding_weights.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt0Jkdjkgahl",
        "outputId": "a25be3d6-2ba2-49bc-9b45-daac7f4f7f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['lots' 'expect' 'quickly' 'huge' 'us' 'issue' 'customer' 'between' 'show'\n",
            " 'gave' 'flat' 'although' 'says' 'job' 'decent' 'either' 'house' 'couldnt'\n",
            " 'travel' 'instead' 'head' 'seller' 'carry' 'needs' 'fall' 'each' 'washed'\n",
            " 'weather' 'stuff' 'lbs' 'outside' 'pink' 'hours' 'clothes' 'sized'\n",
            " 'paper' 'ankle' 'decided' 'pay' 'havent' 'somewhat' 'machine' 'thank'\n",
            " 'someone' 'necklace' 'bright' 'gold' 'bras' 'everyday' 'stretchy']\n"
          ]
        }
      ],
      "source": [
        "print(vocab[500:550])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT0pgrVTe5IM",
        "outputId": "85e77111-10b4-4af5-baea-a1950d6af2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"dad\" not in vocabulary\n",
            "today: [ 0.044 -0.046  0.031 -0.023  0.037  0.017 -0.003  0.021 -0.023 -0.028\n",
            " -0.033  0.041  0.044  0.027 -0.005 -0.01  -0.008  0.042  0.047  0.043\n",
            "  0.027 -0.048  0.047 -0.016 -0.023  0.035  0.002 -0.011  0.048  0.024\n",
            " -0.019  0.042 -0.02   0.038  0.048 -0.008 -0.029 -0.01  -0.031  0.018\n",
            "  0.033 -0.018  0.02   0.023  0.041  0.044 -0.038  0.048 -0.     0.026\n",
            " -0.012 -0.028 -0.023  0.007 -0.008 -0.036 -0.027 -0.036  0.014 -0.017\n",
            "  0.045 -0.035  0.038 -0.049 -0.038 -0.021 -0.043  0.012  0.03   0.017\n",
            "  0.029  0.023  0.035 -0.022  0.031 -0.021 -0.022 -0.039  0.002  0.008\n",
            "  0.035  0.025 -0.048 -0.021 -0.004  0.013  0.014  0.005 -0.031 -0.049\n",
            "  0.046 -0.013  0.033  0.001 -0.002 -0.039  0.032  0.031 -0.032  0.046\n",
            "  0.042  0.031  0.02  -0.034  0.022 -0.023 -0.001 -0.026 -0.002  0.042\n",
            "  0.006 -0.043 -0.05   0.039  0.012 -0.037 -0.023  0.008  0.027  0.04\n",
            " -0.043 -0.009  0.019 -0.005 -0.014  0.022  0.001  0.034]\n"
          ]
        }
      ],
      "source": [
        "def get_word_index(word, encoder):\n",
        "    try:\n",
        "        return encoder.get_vocabulary().index(word)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "words = ['dad', 'today']\n",
        "\n",
        "for word in words:\n",
        "    word_index = get_word_index(word, encoder)\n",
        "    if word_index is not None:\n",
        "        word_vector = embedding_weights[word_index]\n",
        "        print(f'{word}: {np.round(word_vector, 3)}')\n",
        "    else:\n",
        "        print(f'\"{word}\" not in vocabulary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdBrFFrfbewN",
        "outputId": "78f19560-db69-429d-cd40-058886d503ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          128000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 256)         263168    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                82176     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 477,569\n",
            "Trainable params: 477,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_model.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "embedding_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "val_x['reviewText'] = val_x['reviewText'].fillna('').astype(str)\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_x['reviewText'], val_y)).batch(128)\n",
        "val_ds = val_ds.map(lambda x, y: (encoder(x), y))\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "tWsRLBLPcHFq",
        "outputId": "73b9cd54-99b7-4370-de22-e640d20c39fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63375/63375 [==============================] - 2872s 45ms/step - loss: 0.1496 - accuracy: 0.9428 - val_loss: 0.1274 - val_accuracy: 0.9483\n",
            "Epoch 2/10\n",
            "63375/63375 [==============================] - 2112s 33ms/step - loss: 0.1258 - accuracy: 0.9489 - val_loss: 0.1245 - val_accuracy: 0.9494\n",
            "Epoch 3/10\n",
            "63375/63375 [==============================] - 2061s 33ms/step - loss: 0.1235 - accuracy: 0.9498 - val_loss: 0.1236 - val_accuracy: 0.9498\n",
            "Epoch 4/10\n",
            "63375/63375 [==============================] - 2267s 36ms/step - loss: 0.1224 - accuracy: 0.9503 - val_loss: 0.1232 - val_accuracy: 0.9500\n",
            "Epoch 5/10\n",
            "63375/63375 [==============================] - 2279s 36ms/step - loss: 0.1218 - accuracy: 0.9506 - val_loss: 0.1230 - val_accuracy: 0.9502\n",
            "Epoch 6/10\n",
            "63375/63375 [==============================] - 2432s 38ms/step - loss: 0.1214 - accuracy: 0.9507 - val_loss: 0.1228 - val_accuracy: 0.9501\n",
            "Epoch 7/10\n",
            "63375/63375 [==============================] - 2422s 38ms/step - loss: 0.1214 - accuracy: 0.9507 - val_loss: 0.1230 - val_accuracy: 0.9501\n",
            "Epoch 8/10\n",
            "63375/63375 [==============================] - 2765s 44ms/step - loss: 0.1214 - accuracy: 0.9507 - val_loss: 0.1231 - val_accuracy: 0.9500\n",
            "Epoch 9/10\n",
            "63375/63375 [==============================] - 2800s 44ms/step - loss: 0.1214 - accuracy: 0.9507 - val_loss: 0.1232 - val_accuracy: 0.9500\n",
            "Epoch 10/10\n",
            "63375/63375 [==============================] - 2145s 34ms/step - loss: 0.1215 - accuracy: 0.9506 - val_loss: 0.1233 - val_accuracy: 0.9500\n"
          ]
        }
      ],
      "source": [
        "hist_ex1 = embedding_model.fit(train_ds, validation_data=val_ds, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J60PNoY8h9Fj",
        "outputId": "8963230a-94f0-4c8d-adc8-11bcec0dace8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15844/15844 [==============================] - 151s 9ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[0.9992512 ],\n",
              "       [0.9986981 ],\n",
              "       [0.9998454 ],\n",
              "       ...,\n",
              "       [0.99839824],\n",
              "       [0.26230383],\n",
              "       [0.71835023]], dtype=float32)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = embedding_model.predict(val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on Validation Set: 0.9499608479717869\n"
          ]
        }
      ],
      "source": [
        "# For classification models\n",
        "predicted_classes = (predictions > 0.5).astype(int)\n",
        "\n",
        "\n",
        "# Extract actual labels from the validation dataset\n",
        "actual_labels = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(actual_labels, predicted_classes)\n",
        "print(\"Accuracy on Validation Set:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5T_0dHiAY0",
        "outputId": "64bc5389-dcd5-4e5a-807d-9623b11c3111"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: initial_model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: initial_model\\assets\n"
          ]
        }
      ],
      "source": [
        "embedding_model.save('initial_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 6). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: initial_model_full\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: initial_model_full\\assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(embedding_model, 'initial_model_full')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
