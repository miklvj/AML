{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xBc3Nlkrq21l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT96upgorjQC",
        "outputId": "c8c6790c-af70-430d-b79e-e8e9c0cf76d5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = ['Electronics', 'Cell_Phones_and_Accessories', 'Luxury_Beauty']\n",
        "\n",
        "for i in datasets:\n",
        "    input_file = f'/content/gdrive/My Drive/fashion/{i}.json'\n",
        "    output_file = f'/content/gdrive/My Drive/fashion/{i}.csv'\n",
        "\n",
        "    with open(input_file, \"r\", encoding=\"utf-8\") as input_json, open(output_file, \"w\", encoding=\"utf-8\") as output_csv:\n",
        "        csv_writer = csv.writer(output_csv)\n",
        "        flag = 0\n",
        "        line_count = 0 #delete?\n",
        "        for line in input_json:\n",
        "            if line_count < 1000: #delete\n",
        "                dic = json.loads(line)\n",
        "                if flag == 0:\n",
        "                    csv_writer.writerow(dic.keys())\n",
        "                    flag = 1\n",
        "                csv_writer.writerow(dic.values())\n",
        "                line_count += 1 #delte\n",
        "            else: #delete\n",
        "                break #delete\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Jh-u1rsZc6",
        "outputId": "0cf3fd20-e0f1-4c1f-f36e-322cb6dc60ca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_e = pd.read_csv('/content/gdrive/My Drive/fashion/Electronics.csv', usecols=['overall', 'reviewText'])\n",
        "df_cpaa = pd.read_csv('/content/gdrive/My Drive/fashion/Cell_Phones_and_Accessories.csv', usecols=['overall', 'reviewText'])\n",
        "df_lb = pd.read_csv('/content/gdrive/My Drive/fashion/Luxury_Beauty.csv', usecols=['overall', 'reviewText'])"
      ],
      "metadata": {
        "id": "_TgD2Uit07s0"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df_e, df_cpaa], axis=0, ignore_index=True)\n",
        "df_test = df_lb\n",
        "df_train = df_train.dropna()\n",
        "df_test = df_test.dropna()\n",
        "\n",
        "df_train = df_train[df_train[\"overall\"] != '3']\n",
        "df_train[\"label\"] = df_train[\"overall\"].apply(lambda rating : 1 if str(rating) > '3' else 0)\n",
        "\n",
        "df_test = df_test[df_test[\"overall\"] != '3']\n",
        "df_test[\"label\"] = df_test[\"overall\"].apply(lambda rating : 1 if str(rating) > '3' else 0)"
      ],
      "metadata": {
        "id": "be6nafmI1UnZ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(df_train['reviewText'])\n",
        "y = pd.DataFrame(df_train['label'])\n",
        "\n",
        "train_X, val_X, trian_y, val_y = train_test_split(X, y, random_state=50, shuffle=True, train_size=0.2)"
      ],
      "metadata": {
        "id": "0Bm7lX7LELCh"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'First review = {df_train.loc[0, \"reviewText\"]}')\n",
        "print(f'First review has length = {len(df_train.loc[0, \"reviewText\"])}\\n ')\n",
        "print(f'First review overall rating = {df_train.loc[0, \"overall\"]}')\n",
        "print(f'First review binary rating = {df_train.loc[0, \"label\"]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw1ECvN_G725",
        "outputId": "eff017b2-5044-446b-dd9b-d21908d4c361"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First review = This was the first time I read Garcia-Aguilera.  I came upon the name of this book on Live with Regis and Kelly. This book was exactly what I was looking for ... it hit the spot.  I really enjoyed this book because it was well written. Once I started this book it kept me coming back for more. It had culture, family, friendship and romance. I was looking for a little more romance when I picked this book but in the end it turned out to be just right.  I love the main chartachter Margarita (aka Daisy). I've never been to Miami but the way Daisy told the story I certainly felt I'd been there.\n",
            "Also after going through all of Daisy's perils ... I closed the book with a feeling I had grown emotionally as well.\n",
            "First review has length = 712\n",
            " \n",
            "First review overall rating = 5.0\n",
            "First review binary rating = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train:**"
      ],
      "metadata": {
        "id": "Z6BU0DZ5YwUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 1000\n",
        "output_sequence_length = 100\n",
        "pad_to_max_tokens = True\n",
        "\n",
        "df_train['reviewText'] = df_train['reviewText'].fillna('').astype(str)\n",
        "\n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=max_tokens, output_sequence_length=output_sequence_length, pad_to_max_tokens=pad_to_max_tokens)\n",
        "\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(df_train['reviewText']).batch(128)\n",
        "encoder.adapt(text_ds)\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((df_train['reviewText'], df_train['label'])).batch(128)\n",
        "train_ds = train_ds.map(lambda x, y: (encoder(x), y))\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "HuKFli3cS9rk"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test:**"
      ],
      "metadata": {
        "id": "SmMRzcUZYy5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['reviewText'] = df_test['reviewText'].fillna('').astype(str)\n",
        "\n",
        "text_test_ds = tf.data.Dataset.from_tensor_slices(df_test['reviewText']).batch(128)\n",
        "test_ds = text_test_ds.map(lambda x: encoder(x))\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "ZvC5ATWQYEZZ"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(\"Review:\", text_batch.numpy()[i])\n",
        "        print(\"Label:\", label_batch.numpy()[i])\n",
        "        print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJHXolZMaiGE",
        "outputId": "453cb0a9-a377-473b-8228-8b1a5cebe318"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: [ 10  12   2  90  59   4  58   1   4  99   1   2 883   9  10  31  17 522\n",
            "  19   1   5   1  10  31  12 241  53   4  12 178  11   3 896   2   1   4\n",
            "  51 402  10  31  65   3  12  66 334 306   4 200  10  31   3 613  54 385\n",
            "  96  11  64   3  43   1 319   1   5   1   4  12 178  11   6 104  64   1\n",
            "  40   4 956  10  31  16  13   2 288   3 534  63   7  39  38 192   4  32\n",
            "   2 369   1   1   1   1 149 180 107   7]\n",
            "Label: 1\n",
            "---\n",
            "Review: [ 23  19  34   9 684   1 157   4 146  10   8   6 382  58   1   7 123 186\n",
            "   1   1  52 544   1   1   1   2  27   1   9   2   1   1 134   5   1   1\n",
            "   9   1   1   5   1   1   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [  1   1   1  55 320   3 151 605 334 170 299   1  31   5   1   3  19   2\n",
            " 192 842   9   1   1  14 319   5   4 759 123  46 157 186 306 106 485   5\n",
            "  10  30  12  21   6 468 186   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 1\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dimension = 128\n",
        "embedding_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(vocab),\n",
        "                              output_dim=embedding_dimension,\n",
        "                              input_length=100,\n",
        "                              name=\"embedding\"),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "embedding_model.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "embedding_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEWOA2I2a8vj",
        "outputId": "70456fac-5e74-42bf-bae9-eb4672ec1d5f"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          128000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 100, 256)          263168    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 64)                82176     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 477569 (1.82 MB)\n",
            "Trainable params: 477569 (1.82 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_weights = embedding_model.get_layer('embedding').get_weights()[0]\n",
        "print(f'Dimension of the embedding vector: \\n{embedding_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ieu95iXJesc-",
        "outputId": "47166155-12e6-4f91-a5bc-af2dcf86901c"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimension of the embedding vector: \n",
            "(1000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab[500:550])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt0Jkdjkgahl",
        "outputId": "a25be3d6-2ba2-49bc-9b45-daac7f4f7f49"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['date' 'chargers' 'car' 'break' 'working' 'wonderful' 'war' 'wants'\n",
            " 'update' 'top' 'told' 'today' 'show' 'short' 'seems' 'room' 'putting'\n",
            " 'paint' 'paid' 'opened' 'often' 'multiple' 'live' 'light' 'itself' 'held'\n",
            " 'forward' 'expect' 'dad' 'assistant' '700' '20' 'young' 'understand'\n",
            " 'turned' 'thank' 'stop' 'someone' 'silver' 'sienna' 'service' 'reader'\n",
            " 'quinn' 'point' 'past' 'others' 'ones' 'okay' 'oem' 'novels']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_index(word, encoder):\n",
        "    try:\n",
        "        return encoder.get_vocabulary().index(word)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "words = ['dad', 'today']\n",
        "\n",
        "for word in words:\n",
        "    word_index = get_word_index(word, encoder)\n",
        "    if word_index is not None:\n",
        "        word_vector = embedding_weights[word_index]\n",
        "        print(f'{word}: {np.round(word_vector, 3)}')\n",
        "    else:\n",
        "        print(f'\"{word}\" not in vocabulary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT0pgrVTe5IM",
        "outputId": "85e77111-10b4-4af5-baea-a1950d6af2e4"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dad: [ 0.015  0.042  0.046  0.022 -0.042 -0.027  0.001 -0.009  0.036  0.003\n",
            " -0.012 -0.049 -0.048  0.032 -0.006  0.027  0.003  0.031 -0.021  0.037\n",
            " -0.033  0.048 -0.039 -0.011  0.045 -0.003 -0.036 -0.029 -0.023 -0.007\n",
            " -0.009 -0.026  0.002 -0.018 -0.047 -0.003 -0.023 -0.006 -0.027 -0.017\n",
            "  0.046 -0.014 -0.025 -0.049 -0.046 -0.045  0.003  0.017 -0.022  0.05\n",
            "  0.038 -0.047  0.021 -0.048 -0.033  0.019  0.015  0.037 -0.029 -0.029\n",
            " -0.019 -0.003 -0.016 -0.02  -0.02  -0.04   0.049 -0.022 -0.022  0.024\n",
            "  0.047  0.025  0.017  0.014 -0.021 -0.001  0.01  -0.041  0.002 -0.006\n",
            "  0.039 -0.022  0.044  0.031 -0.047  0.016 -0.028 -0.001  0.021 -0.001\n",
            " -0.037  0.02   0.008 -0.025 -0.012 -0.015 -0.047 -0.049 -0.015  0.017\n",
            "  0.025  0.006  0.015  0.003  0.003 -0.037 -0.032 -0.035 -0.034 -0.005\n",
            "  0.041  0.032  0.045  0.018 -0.031  0.011  0.044  0.031  0.025  0.02\n",
            "  0.035  0.046  0.021  0.033 -0.001  0.044  0.006 -0.006]\n",
            "today: [-0.025 -0.047 -0.049 -0.032 -0.046  0.017 -0.04  -0.039 -0.039 -0.049\n",
            "  0.012 -0.033  0.013  0.026 -0.023  0.003 -0.001  0.037  0.001  0.042\n",
            "  0.009  0.031 -0.042  0.035 -0.025 -0.015 -0.044 -0.004 -0.018  0.018\n",
            "  0.013 -0.018 -0.026 -0.033  0.005  0.006  0.044  0.019  0.016  0.005\n",
            " -0.046  0.025 -0.005 -0.048 -0.031  0.029 -0.006 -0.037  0.004 -0.016\n",
            " -0.013 -0.008  0.002 -0.015 -0.012 -0.048 -0.037  0.032  0.047 -0.038\n",
            " -0.046  0.011 -0.047  0.049 -0.024  0.025 -0.011  0.001 -0.022  0.043\n",
            "  0.028 -0.047 -0.015  0.048 -0.035 -0.033 -0.011  0.026 -0.008 -0.007\n",
            " -0.047  0.02   0.01  -0.037 -0.031 -0.008 -0.022  0.048 -0.018 -0.015\n",
            " -0.007  0.017  0.001  0.011  0.043  0.023 -0.019 -0.04   0.042  0.023\n",
            "  0.028  0.026 -0.024 -0.023 -0.044  0.041  0.045  0.014 -0.011  0.039\n",
            "  0.001  0.016 -0.048 -0.031 -0.025 -0.045 -0.005  0.032 -0.042 -0.042\n",
            "  0.025 -0.031  0.026  0.008 -0.009 -0.013 -0.042  0.02 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "embedding_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdBrFFrfbewN",
        "outputId": "78f19560-db69-429d-cd40-058886d503ed"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          128000    \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 100, 256)          263168    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 64)                82176     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 477569 (1.82 MB)\n",
            "Trainable params: 477569 (1.82 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model.fit(train_ds, epochs=10, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "tWsRLBLPcHFq",
        "outputId": "73b9cd54-99b7-4370-de22-e640d20c39fb"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            " 9/16 [===============>..............] - ETA: 6s - loss: 0.3693 - accuracy: 0.8924"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-149-5d006825019c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = embedding_model.predict(test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J60PNoY8h9Fj",
        "outputId": "8963230a-94f0-4c8d-adc8-11bcec0dace8"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 2s 229ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5T_0dHiAY0",
        "outputId": "64bc5389-dcd5-4e5a-807d-9623b11c3111"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.8410684 ]\n",
            " [0.629067  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841071  ]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84105265]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8405561 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410718 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409079 ]\n",
            " [0.8361913 ]\n",
            " [0.8410677 ]\n",
            " [0.84107214]\n",
            " [0.84107167]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107053]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410708 ]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410686 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106594]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107053]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410261 ]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.82665867]\n",
            " [0.84107083]\n",
            " [0.75955206]\n",
            " [0.84107214]\n",
            " [0.84107053]\n",
            " [0.8410672 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84104353]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409275 ]\n",
            " [0.84107214]\n",
            " [0.8410715 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410707 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410678 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409814 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107053]\n",
            " [0.8410687 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106714]\n",
            " [0.8410718 ]\n",
            " [0.8404938 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.80258495]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.8410697 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84105766]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107053]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106964]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106797]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8408685 ]\n",
            " [0.84106684]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107167]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410715 ]\n",
            " [0.84107214]\n",
            " [0.83990544]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106404]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410718 ]\n",
            " [0.8410721 ]\n",
            " [0.84107196]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107107]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107035]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8088585 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106684]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841067  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106594]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410715 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410716 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410698 ]\n",
            " [0.8410721 ]\n",
            " [0.8354806 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106946]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8094704 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410718 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106946]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410658 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107065]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.8410637 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410684 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8373848 ]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107167]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409679 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.8410683 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410716 ]\n",
            " [0.84106743]\n",
            " [0.84107214]\n",
            " [0.84106785]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410715 ]\n",
            " [0.8410721 ]\n",
            " [0.84105974]\n",
            " [0.8410721 ]\n",
            " [0.8410658 ]\n",
            " [0.77521914]\n",
            " [0.841052  ]\n",
            " [0.84107214]\n",
            " [0.84107006]\n",
            " [0.8410715 ]\n",
            " [0.84106606]\n",
            " [0.84106636]\n",
            " [0.84101284]\n",
            " [0.841071  ]\n",
            " [0.841072  ]\n",
            " [0.841072  ]\n",
            " [0.8410721 ]\n",
            " [0.8410707 ]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107196]\n",
            " [0.8410721 ]\n",
            " [0.7483977 ]\n",
            " [0.8410632 ]\n",
            " [0.84107184]\n",
            " [0.84107184]\n",
            " [0.8410708 ]\n",
            " [0.8410689 ]\n",
            " [0.84106946]\n",
            " [0.8410695 ]\n",
            " [0.62315154]\n",
            " [0.8410721 ]\n",
            " [0.8410719 ]\n",
            " [0.8410698 ]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107184]\n",
            " [0.8403591 ]\n",
            " [0.84107214]\n",
            " [0.8410713 ]\n",
            " [0.78166366]\n",
            " [0.84107184]\n",
            " [0.8410718 ]\n",
            " [0.8246222 ]\n",
            " [0.8410721 ]\n",
            " [0.8410719 ]\n",
            " [0.8410699 ]\n",
            " [0.84107196]\n",
            " [0.8410717 ]\n",
            " [0.8410719 ]\n",
            " [0.841072  ]\n",
            " [0.841072  ]\n",
            " [0.8410709 ]\n",
            " [0.8410711 ]\n",
            " [0.77658683]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84106773]\n",
            " [0.8410716 ]\n",
            " [0.84106886]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.8410718 ]\n",
            " [0.84107196]\n",
            " [0.7435024 ]\n",
            " [0.8410705 ]\n",
            " [0.80417967]\n",
            " [0.8410694 ]\n",
            " [0.8410334 ]\n",
            " [0.84106684]\n",
            " [0.84103215]\n",
            " [0.81797606]\n",
            " [0.83999026]\n",
            " [0.84107214]\n",
            " [0.84106743]\n",
            " [0.84106946]\n",
            " [0.84107   ]\n",
            " [0.8182078 ]\n",
            " [0.84107214]\n",
            " [0.8410665 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107167]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84095937]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410707 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8207058 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.68952966]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.7588225 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107095]\n",
            " [0.84107214]\n",
            " [0.59744   ]\n",
            " [0.84098506]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.76441926]\n",
            " [0.84107214]\n",
            " [0.8397301 ]\n",
            " [0.84106344]\n",
            " [0.8318599 ]\n",
            " [0.8410563 ]\n",
            " [0.70872283]\n",
            " [0.6966085 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.7925136 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410714 ]\n",
            " [0.8410655 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8407277 ]\n",
            " [0.84107214]\n",
            " [0.84106773]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410645 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410674 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409947 ]\n",
            " [0.8410718 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84101474]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.74468607]\n",
            " [0.8410716 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410663 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410693 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410711 ]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410711 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107184]\n",
            " [0.84107167]\n",
            " [0.8410681 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.5547144 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.8147071 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.82760954]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410677 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.841071  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.8407071 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410706 ]\n",
            " [0.8410708 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410715 ]\n",
            " [0.84107214]\n",
            " [0.8410707 ]\n",
            " [0.84107214]\n",
            " [0.8410713 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8065003 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.841072  ]\n",
            " [0.84107196]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.7828146 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8222277 ]\n",
            " [0.8410666 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.81736034]\n",
            " [0.84107214]\n",
            " [0.84105027]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410709 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84090716]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.83338535]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84087306]\n",
            " [0.84107196]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.795513  ]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106565]\n",
            " [0.84107214]\n",
            " [0.84107214]]\n"
          ]
        }
      ]
    }
  ]
}