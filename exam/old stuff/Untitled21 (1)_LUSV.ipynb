{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xBc3Nlkrq21l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT96upgorjQC",
        "outputId": "bea8530c-055f-4810-ebc9-1f3d315efdf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Jh-u1rsZc6",
        "outputId": "fe1aec60-a55d-45fd-efb8-e10fe330b64e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "datasets = ['All_Beauty_5', 'AMAZON_FASHION_5', 'Arts_Crafts_and_Sewing_5', 'Clothing_Shoes_and_Jewelry_5', 'Luxury_Beauty_5']\n",
        "\n",
        "for i in datasets:\n",
        "    input_file = f'D:/aml_data/{i}.json'\n",
        "    output_file = f'D:/aml_data/{i}.csv'\n",
        "\n",
        "    with open(input_file, \"r\", encoding=\"utf-8\") as input_json, open(output_file, \"w\", encoding=\"utf-8\") as output_csv:\n",
        "        csv_writer = csv.writer(output_csv)\n",
        "        flag = 0\n",
        "        for line in input_json:\n",
        "                dic = json.loads(line)\n",
        "                if flag == 0:\n",
        "                    csv_writer.writerow(dic.keys())\n",
        "                    flag = 1\n",
        "                csv_writer.writerow(dic.values())\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_TgD2Uit07s0"
      },
      "outputs": [],
      "source": [
        "df_1 = pd.read_csv('D:/aml_data//All_Beauty_5.csv', usecols=['overall', 'reviewText', \"summary\"])\n",
        "df_2 = pd.read_csv('D:/aml_data//AMAZON_FASHION_5.csv', usecols=['overall', 'reviewText', \"summary\"])\n",
        "df_3 = pd.read_csv('D:/aml_data//Arts_Crafts_and_Sewing_5.csv', usecols=['overall', 'reviewText', \"summary\"])\n",
        "df_4 = pd.read_csv('D:/aml_data//Clothing_Shoes_and_Jewelry_5.csv', usecols=['overall', 'reviewText', \"summary\"])\n",
        "df_test = pd.read_csv('D:/aml_data//Luxury_Beauty_5.csv', usecols=['overall', 'reviewText', \"summary\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "be6nafmI1UnZ"
      },
      "outputs": [],
      "source": [
        "df_train = pd.concat([df_1, df_2, df_3, df_4], axis=0, ignore_index=True)\n",
        "df_train = df_train.dropna()\n",
        "df_test = df_test.dropna()\n",
        "\n",
        "df_train = df_train[df_train[\"overall\"] != '3']\n",
        "df_train[\"label\"] = df_train[\"overall\"].apply(lambda rating : 1 if str(rating) > '3' else 0)\n",
        "\n",
        "df_test = df_test[df_test[\"overall\"] != '3']\n",
        "df_test[\"label\"] = df_test[\"overall\"].apply(lambda rating : 1 if str(rating) > '3' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw1ECvN_G725",
        "outputId": "beccf83e-608b-45b9-b75f-5996e8ec7338"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First review = As advertised. Reasonably priced\n",
            "First review has length = 32\n",
            " \n",
            "First review overall rating = 5.0\n",
            "First review binary rating = 1\n"
          ]
        }
      ],
      "source": [
        "print(f'First review = {df_train.loc[0, \"reviewText\"]}')\n",
        "print(f'First review has length = {len(df_train.loc[0, \"reviewText\"])}\\n ')\n",
        "print(f'First review overall rating = {df_train.loc[0, \"overall\"]}')\n",
        "print(f'First review binary rating = {df_train.loc[0, \"label\"]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.9.1\n",
            "Num GPUs Available:  1\n",
            "Name: /physical_device:GPU:0   Type: GPU\n"
          ]
        }
      ],
      "source": [
        "print(\"TensorFlow Version:\", tf.__version__)\n",
        "\n",
        "# Check available GPUs\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs Available: \", len(gpus))\n",
        "for gpu in gpus:\n",
        "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = pd.DataFrame(df_train, columns = [\"reviewText\"])\n",
        "y = pd.DataFrame(df_train, columns = [\"label\"])\n",
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(X, y, train_size=0.8, random_state=50, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_Xtrain = pd.DataFrame(train_x,columns=['reviewText'])\n",
        "df_ytrain = pd.DataFrame(train_y,columns=['label'])\n",
        "df_train = pd.concat([df_ytrain, df_Xtrain], axis=1)\n",
        "df_Xval = pd.DataFrame(val_x,columns=['reviewText'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8111964\n",
            "2027992\n",
            "         label                reviewText\n",
            "2567756      1           Nice sunglasses\n",
            "6585046      1            Fits perfectly\n",
            "7522833      0  You get what you pay for\n",
            "1465266      1              Soft leather\n",
            "6909483      1                Five Stars\n",
            "                       reviewText\n",
            "7259421  Durable and Easy to Move\n",
            "8237271      I Love these sandals\n",
            "6135424                Five Stars\n",
            "4290872                Five Stars\n",
            "9102221      A Very Good T- shirt\n"
          ]
        }
      ],
      "source": [
        "print(len(df_train))\n",
        "print(len(df_Xval))\n",
        "\n",
        "print(df_train.head())\n",
        "print(df_Xval.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6BU0DZ5YwUd"
      },
      "source": [
        "**Train:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "HuKFli3cS9rk",
        "outputId": "949464c3-052e-4eca-8e43-4b1eade2f512"
      },
      "outputs": [],
      "source": [
        "max_tokens = 1000\n",
        "output_sequence_length = 100\n",
        "pad_to_max_tokens = True\n",
        "\n",
        "df_train['reviewText'] = df_train['reviewText'].fillna('').astype(str)\n",
        "\n",
        "encoder = tf.keras.layers.TextVectorization(max_tokens=max_tokens, output_sequence_length=output_sequence_length, pad_to_max_tokens=pad_to_max_tokens)\n",
        "\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(df_train['reviewText']).batch(128)\n",
        "encoder.adapt(text_ds)\n",
        "vocab = np.array(encoder.get_vocabulary())\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((df_train['reviewText'], df_train['label'])).batch(128)\n",
        "train_ds = train_ds.map(lambda x, y: (encoder(x), y))\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmMRzcUZYy5t"
      },
      "source": [
        "**Test:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZvC5ATWQYEZZ"
      },
      "outputs": [],
      "source": [
        "df_Xval['reviewText'] = df_Xval['reviewText'].fillna('').astype(str)\n",
        "\n",
        "text_test_ds = tf.data.Dataset.from_tensor_slices(df_Xval['reviewText']).batch(128)\n",
        "df_val = text_test_ds.map(lambda x: encoder(x))\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "test_ds = df_val.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<PrefetchDataset element_spec=TensorSpec(shape=(None, 100), dtype=tf.int64, name=None)>\n"
          ]
        }
      ],
      "source": [
        "print(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJHXolZMaiGE",
        "outputId": "453cb0a9-a377-473b-8228-8b1a5cebe318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: [ 34 691   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [ 79 192   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [ 37  77  76  37 538  10   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 0\n",
            "---\n",
            "Review: [118 204   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n",
            "Label: 1\n",
            "---\n",
            "Review: [7 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Label: 1\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(\"Review:\", text_batch.numpy()[i])\n",
        "        print(\"Label:\", label_batch.numpy()[i])\n",
        "        print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEWOA2I2a8vj",
        "outputId": "70456fac-5e74-42bf-bae9-eb4672ec1d5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          128000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 256)         263168    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                82176     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 477,569\n",
            "Trainable params: 477,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_dimension = 128\n",
        "embedding_model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(vocab),\n",
        "                              output_dim=embedding_dimension,\n",
        "                              input_length=100,\n",
        "                              name=\"embedding\"),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "embedding_model.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "embedding_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ieu95iXJesc-",
        "outputId": "47166155-12e6-4f91-a5bc-af2dcf86901c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimension of the embedding vector: \n",
            "(1000, 128)\n"
          ]
        }
      ],
      "source": [
        "embedding_weights = embedding_model.get_layer('embedding').get_weights()[0]\n",
        "print(f'Dimension of the embedding vector: \\n{embedding_weights.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt0Jkdjkgahl",
        "outputId": "a25be3d6-2ba2-49bc-9b45-daac7f4f7f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['lots' 'expect' 'quickly' 'huge' 'us' 'issue' 'customer' 'between' 'show'\n",
            " 'gave' 'flat' 'although' 'says' 'job' 'decent' 'either' 'house' 'couldnt'\n",
            " 'travel' 'instead' 'head' 'seller' 'carry' 'needs' 'fall' 'each' 'washed'\n",
            " 'weather' 'stuff' 'lbs' 'outside' 'pink' 'hours' 'clothes' 'sized'\n",
            " 'paper' 'ankle' 'decided' 'pay' 'havent' 'somewhat' 'machine' 'thank'\n",
            " 'someone' 'necklace' 'bright' 'gold' 'bras' 'everyday' 'stretchy']\n"
          ]
        }
      ],
      "source": [
        "print(vocab[500:550])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT0pgrVTe5IM",
        "outputId": "85e77111-10b4-4af5-baea-a1950d6af2e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"dad\" not in vocabulary\n",
            "today: [ 0.017  0.004  0.003 -0.043 -0.013  0.032 -0.001 -0.029  0.04   0.025\n",
            "  0.038  0.043  0.013 -0.026  0.013  0.011 -0.04  -0.002 -0.015  0.016\n",
            " -0.027 -0.005 -0.042  0.033  0.03  -0.008  0.026  0.009 -0.042 -0.019\n",
            "  0.005  0.015 -0.023 -0.021 -0.018 -0.011 -0.008  0.043  0.011 -0.011\n",
            " -0.01  -0.046  0.029  0.006 -0.019  0.038 -0.024 -0.032  0.001  0.044\n",
            "  0.024 -0.011  0.033  0.045 -0.048  0.027 -0.002 -0.019 -0.048 -0.035\n",
            " -0.041  0.01  -0.043  0.033  0.027  0.022 -0.027 -0.047 -0.037 -0.022\n",
            " -0.043 -0.016 -0.003  0.039  0.001  0.033  0.02  -0.03  -0.039 -0.022\n",
            " -0.05  -0.038 -0.007  0.009 -0.041  0.012 -0.     0.012 -0.022  0.011\n",
            " -0.045 -0.015  0.003 -0.034  0.009  0.008  0.031 -0.022 -0.02  -0.024\n",
            "  0.047 -0.025 -0.044  0.013 -0.038  0.001  0.025  0.016  0.044  0.05\n",
            "  0.023  0.006  0.012  0.031  0.031 -0.004  0.05   0.008 -0.019  0.033\n",
            " -0.005 -0.037  0.047 -0.045 -0.041  0.025  0.014 -0.012]\n"
          ]
        }
      ],
      "source": [
        "def get_word_index(word, encoder):\n",
        "    try:\n",
        "        return encoder.get_vocabulary().index(word)\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "words = ['dad', 'today']\n",
        "\n",
        "for word in words:\n",
        "    word_index = get_word_index(word, encoder)\n",
        "    if word_index is not None:\n",
        "        word_vector = embedding_weights[word_index]\n",
        "        print(f'{word}: {np.round(word_vector, 3)}')\n",
        "    else:\n",
        "        print(f'\"{word}\" not in vocabulary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdBrFFrfbewN",
        "outputId": "78f19560-db69-429d-cd40-058886d503ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          128000    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 256)         263168    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100, 256)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                82176     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 477,569\n",
            "Trainable params: 477,569\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "embedding_model.compile(optimizer='adam',\n",
        "                        loss='binary_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "\n",
        "embedding_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "tWsRLBLPcHFq",
        "outputId": "73b9cd54-99b7-4370-de22-e640d20c39fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   76/63375 [..............................] - ETA: 40:57 - loss: 0.0963 - accuracy: 0.9646"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hist_ex1 \u001b[38;5;241m=\u001b[39m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hist_ex1 = embedding_model.fit(train_ds, validation_data=test_ds, epochs=10, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J60PNoY8h9Fj",
        "outputId": "8963230a-94f0-4c8d-adc8-11bcec0dace8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 2s 229ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = embedding_model.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k5T_0dHiAY0",
        "outputId": "64bc5389-dcd5-4e5a-807d-9623b11c3111"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.8410684 ]\n",
            " [0.629067  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841071  ]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84105265]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8405561 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410718 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409079 ]\n",
            " [0.8361913 ]\n",
            " [0.8410677 ]\n",
            " [0.84107214]\n",
            " [0.84107167]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107053]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410708 ]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410686 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106594]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107053]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410261 ]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.82665867]\n",
            " [0.84107083]\n",
            " [0.75955206]\n",
            " [0.84107214]\n",
            " [0.84107053]\n",
            " [0.8410672 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84104353]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409275 ]\n",
            " [0.84107214]\n",
            " [0.8410715 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410707 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410678 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409814 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107053]\n",
            " [0.8410687 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106714]\n",
            " [0.8410718 ]\n",
            " [0.8404938 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.80258495]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.8410697 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84105766]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107053]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106964]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106797]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8408685 ]\n",
            " [0.84106684]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107167]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410715 ]\n",
            " [0.84107214]\n",
            " [0.83990544]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106404]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410718 ]\n",
            " [0.8410721 ]\n",
            " [0.84107196]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107107]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107035]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8088585 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106684]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841067  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106594]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410715 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410716 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410698 ]\n",
            " [0.8410721 ]\n",
            " [0.8354806 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106946]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8094704 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410718 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106946]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410658 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107065]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.8410637 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410684 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8373848 ]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107167]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409679 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.8410683 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410716 ]\n",
            " [0.84106743]\n",
            " [0.84107214]\n",
            " [0.84106785]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410715 ]\n",
            " [0.8410721 ]\n",
            " [0.84105974]\n",
            " [0.8410721 ]\n",
            " [0.8410658 ]\n",
            " [0.77521914]\n",
            " [0.841052  ]\n",
            " [0.84107214]\n",
            " [0.84107006]\n",
            " [0.8410715 ]\n",
            " [0.84106606]\n",
            " [0.84106636]\n",
            " [0.84101284]\n",
            " [0.841071  ]\n",
            " [0.841072  ]\n",
            " [0.841072  ]\n",
            " [0.8410721 ]\n",
            " [0.8410707 ]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107196]\n",
            " [0.8410721 ]\n",
            " [0.7483977 ]\n",
            " [0.8410632 ]\n",
            " [0.84107184]\n",
            " [0.84107184]\n",
            " [0.8410708 ]\n",
            " [0.8410689 ]\n",
            " [0.84106946]\n",
            " [0.8410695 ]\n",
            " [0.62315154]\n",
            " [0.8410721 ]\n",
            " [0.8410719 ]\n",
            " [0.8410698 ]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107184]\n",
            " [0.8403591 ]\n",
            " [0.84107214]\n",
            " [0.8410713 ]\n",
            " [0.78166366]\n",
            " [0.84107184]\n",
            " [0.8410718 ]\n",
            " [0.8246222 ]\n",
            " [0.8410721 ]\n",
            " [0.8410719 ]\n",
            " [0.8410699 ]\n",
            " [0.84107196]\n",
            " [0.8410717 ]\n",
            " [0.8410719 ]\n",
            " [0.841072  ]\n",
            " [0.841072  ]\n",
            " [0.8410709 ]\n",
            " [0.8410711 ]\n",
            " [0.77658683]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84106773]\n",
            " [0.8410716 ]\n",
            " [0.84106886]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.8410718 ]\n",
            " [0.84107196]\n",
            " [0.7435024 ]\n",
            " [0.8410705 ]\n",
            " [0.80417967]\n",
            " [0.8410694 ]\n",
            " [0.8410334 ]\n",
            " [0.84106684]\n",
            " [0.84103215]\n",
            " [0.81797606]\n",
            " [0.83999026]\n",
            " [0.84107214]\n",
            " [0.84106743]\n",
            " [0.84106946]\n",
            " [0.84107   ]\n",
            " [0.8182078 ]\n",
            " [0.84107214]\n",
            " [0.8410665 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107167]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84095937]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410707 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8207058 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.68952966]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.7588225 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107095]\n",
            " [0.84107214]\n",
            " [0.59744   ]\n",
            " [0.84098506]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.76441926]\n",
            " [0.84107214]\n",
            " [0.8397301 ]\n",
            " [0.84106344]\n",
            " [0.8318599 ]\n",
            " [0.8410563 ]\n",
            " [0.70872283]\n",
            " [0.6966085 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.7925136 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410714 ]\n",
            " [0.8410655 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8407277 ]\n",
            " [0.84107214]\n",
            " [0.84106773]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410645 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410674 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8409947 ]\n",
            " [0.8410718 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84101474]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.74468607]\n",
            " [0.8410716 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410663 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410693 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410711 ]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410711 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.8410717 ]\n",
            " [0.84107184]\n",
            " [0.84107167]\n",
            " [0.8410681 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.5547144 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.8147071 ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.82760954]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410677 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.841071  ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107184]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.8407071 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410706 ]\n",
            " [0.8410708 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410715 ]\n",
            " [0.84107214]\n",
            " [0.8410707 ]\n",
            " [0.84107214]\n",
            " [0.8410713 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8065003 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.841072  ]\n",
            " [0.841072  ]\n",
            " [0.84107196]\n",
            " [0.84107196]\n",
            " [0.84107214]\n",
            " [0.7828146 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8222277 ]\n",
            " [0.8410666 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.81736034]\n",
            " [0.84107214]\n",
            " [0.84105027]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410709 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84090716]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.83338535]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84087306]\n",
            " [0.84107196]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.8410721 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107196]\n",
            " [0.84107155]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.795513  ]\n",
            " [0.8410719 ]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84107214]\n",
            " [0.84106565]\n",
            " [0.84107214]\n",
            " [0.84107214]]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
