{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfpLBFoKgnVP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import ensemble\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5pQseYSiYA6",
        "outputId": "a80dd391-1ac8-4c5a-9d17-bf1a9876fd41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8vYbQ6wig2n"
      },
      "outputs": [],
      "source": [
        "device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZrDYMQailHC",
        "outputId": "9cfeb2cd-278b-453a-fd02-09157f2c607f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (20000, 48)\n",
            "Shape of test data: (5000, 48)\n",
            "Shape of labels/targets: (20000,)\n"
          ]
        }
      ],
      "source": [
        "x_train = np.load('/content/gdrive/My Drive/Assignment 3/x_train.npy')\n",
        "print(f'Shape of training data: {x_train.shape}')\n",
        "\n",
        "x_test = np.load('/content/gdrive/My Drive/Assignment 3/x_test.npy')\n",
        "print(f'Shape of test data: {x_test.shape}')\n",
        "\n",
        "y_train = np.load('/content/gdrive/My Drive/Assignment 3/y_train.npy')\n",
        "print(f'Shape of labels/targets: {y_train.shape}')\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNYdP5hEL4cz"
      },
      "outputs": [],
      "source": [
        "x_train_copy = x_train\n",
        "y_train_copy = y_train\n",
        "\n",
        "num_ensembles = 3\n",
        "samples_per_ensemble = x_train_copy.shape[0] // num_ensembles\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "datasets = {}\n",
        "\n",
        "for i in range(1, 4):\n",
        "    indices = np.random.choice(x_train_copy.shape[0], samples_per_ensemble, replace=False)\n",
        "\n",
        "    X_subset = x_train_copy[indices]\n",
        "    y_subset = y_train_copy[indices]\n",
        "\n",
        "    datasets[f'X_{i}'] = X_subset\n",
        "    datasets[f'y_{i}'] = y_subset\n",
        "\n",
        "    x_train_copy = np.delete(x_train_copy, indices, axis=0)\n",
        "    y_train_copy = np.delete(y_train_copy, indices, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "by72Dh02pYsS",
        "outputId": "cc45c5cb-f5f7-450a-887d-13cd767c0453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_1: (6666, 48)\n",
            "Shape of y_1: (6666,)\n",
            "Shape of X_2: (6666, 48)\n",
            "Shape of y_2: (6666,)\n",
            "Shape of X_3: (6666, 48)\n",
            "Shape of y_3: (6666,)\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 4):\n",
        "    X = datasets[f'X_{i}']\n",
        "    y = datasets[f'y_{i}']\n",
        "    print(f\"Shape of X_{i}: {X.shape}\")\n",
        "    print(f\"Shape of y_{i}: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4D-sEr1cNngl"
      },
      "source": [
        "## Hyperparameters for 3 Models:\n",
        "\n",
        "<br>\n",
        "\n",
        "**Model 1: FFNN**\n",
        "\n",
        "**Model 2: Boosting**\n",
        "\n",
        "**Model 3: Random Forest**\n",
        "\n",
        "<br>\n",
        "\n",
        "Each model is based on 1/3 of the training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBymgEy_rtJY"
      },
      "source": [
        "**Model 1 (Hyperparameters search):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNPCMGJ2pj9K"
      },
      "outputs": [],
      "source": [
        "model_1 = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(48,)),\n",
        "    tf.keras.layers.Dense(96, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(48, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    #tf.keras.layers.Dropout(0.35),\n",
        "    tf.keras.layers.Dense(1, activation='linear'),\n",
        "])\n",
        "\n",
        "model_1.compile(\n",
        "    loss='mse',\n",
        "    optimizer=tf.keras.optimizers.experimental.Adam(0.0001),\n",
        "    metrics=['mae'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v4_1VHbr30w",
        "outputId": "cb79aa8b-c789-4858-acc7-7e61ff47b638"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 48)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 96)                4704      \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 96)                384       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 48)                4656      \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 48)                192       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 49        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9985 (39.00 KB)\n",
            "Trainable params: 9697 (37.88 KB)\n",
            "Non-trainable params: 288 (1.12 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "167/167 [==============================] - 4s 6ms/step - loss: 143.8693 - mae: 8.9381 - val_loss: 151.4951 - val_mae: 9.2094\n",
            "Epoch 2/10\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 140.1060 - mae: 8.7827 - val_loss: 149.7269 - val_mae: 9.1406\n",
            "Epoch 3/10\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 136.9272 - mae: 8.6528 - val_loss: 146.9386 - val_mae: 9.0230\n",
            "Epoch 4/10\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 134.0513 - mae: 8.5136 - val_loss: 144.0146 - val_mae: 8.8986\n",
            "Epoch 5/10\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 130.8333 - mae: 8.3879 - val_loss: 140.7718 - val_mae: 8.7535\n",
            "Epoch 6/10\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 127.1645 - mae: 8.2385 - val_loss: 137.3024 - val_mae: 8.6040\n",
            "Epoch 7/10\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 123.6480 - mae: 8.0827 - val_loss: 133.8948 - val_mae: 8.4567\n",
            "Epoch 8/10\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 119.9845 - mae: 7.9312 - val_loss: 130.2713 - val_mae: 8.3094\n",
            "Epoch 9/10\n",
            "167/167 [==============================] - 1s 5ms/step - loss: 116.2184 - mae: 7.7648 - val_loss: 126.1144 - val_mae: 8.1406\n",
            "Epoch 10/10\n",
            "167/167 [==============================] - 1s 6ms/step - loss: 111.9396 - mae: 7.5845 - val_loss: 122.1221 - val_mae: 7.9824\n"
          ]
        }
      ],
      "source": [
        "X_1 = datasets['X_1']\n",
        "y_1 = datasets['y_1']\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_mae',\n",
        "                                            patience=30,\n",
        "                                            restore_best_weights=True)\n",
        "\n",
        "model_1.summary()\n",
        "\n",
        "history_1 = model_1.fit(\n",
        "    X_1,\n",
        "    y_1,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_split=0.2,\n",
        "    callbacks=callback\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "jyU3pL-2IaVq",
        "outputId": "d4af2e64-f534-47ac-8f77-3e8d23c63273"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x320 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "history_x = history_1\n",
        "history_y = history_1\n",
        "\n",
        "fig = plt.figure(figsize=plt.figaspect(0.2))\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 1)\n",
        "ax.plot(history_x.history['loss'], label='Training loss')\n",
        "ax.plot(history_y.history['val_loss'], label='Validation loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title(f'Loss over Epochs')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "ax = fig.add_subplot(1, 2, 2)\n",
        "ax.plot(history_x.history['mae'], label='Mean average error')\n",
        "ax.plot(history_y.history['val_mae'], label='Validation MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MAE')\n",
        "plt.title(f'MAE over Epochs')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Go8qRTFXOSPx"
      },
      "source": [
        "**Model 2 (Hyperparameters search):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "6elZ6EbiOUVm",
        "outputId": "0e12ea72-63f3-4936-dfe8-5e13a53fa37a"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 23\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_grid:\n\u001b[0;32m     17\u001b[0m   gbt_current \u001b[38;5;241m=\u001b[39m ensemble\u001b[38;5;241m.\u001b[39mGradientBoostingRegressor(\n\u001b[0;32m     18\u001b[0m                 n_estimators\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     19\u001b[0m                 min_samples_split\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     20\u001b[0m                 min_samples_leaf\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     21\u001b[0m                 learning_rate\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     22\u001b[0m                 )\n\u001b[1;32m---> 23\u001b[0m   \u001b[43mgbt_current\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m   y_val_hat \u001b[38;5;241m=\u001b[39m gbt_current\u001b[38;5;241m.\u001b[39mpredict(X_val_2)\n\u001b[0;32m     25\u001b[0m   val_MAE \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_val_hat, y_val_2)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:525\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[0;32m    524\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[1;32m--> 525\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:603\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    596\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m loss_(\n\u001b[0;32m    597\u001b[0m             y[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    598\u001b[0m             raw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    599\u001b[0m             sample_weight[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[0;32m    600\u001b[0m         )\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:245\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    242\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[0;32m    244\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 245\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[0;32m    248\u001b[0m loss\u001b[38;5;241m.\u001b[39mupdate_terminal_regions(\n\u001b[0;32m    249\u001b[0m     tree\u001b[38;5;241m.\u001b[39mtree_,\n\u001b[0;32m    250\u001b[0m     X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m     k\u001b[38;5;241m=\u001b[39mk,\n\u001b[0;32m    258\u001b[0m )\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "X_2 = datasets['X_2']\n",
        "y_2 = datasets['y_2']\n",
        "\n",
        "X_train_2, X_val_2, y_train_2, y_val_2 = train_test_split(X_2, y_2, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = ParameterGrid({\n",
        "    'n_estimators': [250, 500, 1000],\n",
        "    'min_samples_split': [10, 25, 250],\n",
        "    'min_samples_leaf': [10, 25, 250],\n",
        "    'learning_rate': [0.015, 0.1, 0.25]\n",
        "    })\n",
        "\n",
        "score_ = 0\n",
        "params_ = None\n",
        "\n",
        "for params in param_grid:\n",
        "  gbt_current = ensemble.GradientBoostingRegressor(\n",
        "                n_estimators=params['n_estimators'],\n",
        "                min_samples_split=params['min_samples_split'],\n",
        "                min_samples_leaf=params['min_samples_leaf'],\n",
        "                learning_rate=params['learning_rate'],\n",
        "                )\n",
        "  gbt_current.fit(X_train_2, y_train_2)\n",
        "  y_val_hat = gbt_current.predict(X_val_2)\n",
        "  val_MAE = mean_absolute_error(y_val_hat, y_val_2)\n",
        "  if val_MAE > score_:\n",
        "    score_ = val_MAE\n",
        "    params_ = params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "alm-p8iAT-xI",
        "outputId": "d263e1d5-8cfe-4620-edea-812b6a5de583"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For GB the best hyperparameters are: {'learning_rate': 0.5, 'min_samples_leaf': 10, 'min_samples_split': 250, 'n_estimators': 8000}, the mean average error of the model is: 8.066256368107819\n"
          ]
        }
      ],
      "source": [
        "print(f\"For GB the best hyperparameters are: {params_}, the mean average error of the model is: {val_MAE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsaPxhsaTtk2"
      },
      "source": [
        "**Model 3 (Hyperparameters search):**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0k8p0_dTw_8",
        "outputId": "3e1cf7af-bffc-4c98-e25d-104a27030246"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 24\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_grid:\n\u001b[0;32m     17\u001b[0m   rf_current \u001b[38;5;241m=\u001b[39m ensemble\u001b[38;5;241m.\u001b[39mRandomForestRegressor(\n\u001b[0;32m     18\u001b[0m                 n_estimators\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     19\u001b[0m                 min_samples_split\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m                 max_features\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     23\u001b[0m                 )\n\u001b[1;32m---> 24\u001b[0m   \u001b[43mrf_current\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m   y_val_hat \u001b[38;5;241m=\u001b[39m rf_current\u001b[38;5;241m.\u001b[39mpredict(X_val_3)\n\u001b[0;32m     26\u001b[0m   val_MAE \u001b[38;5;241m=\u001b[39m mean_absolute_error(y_val_hat, y_val_3)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "X_3 = datasets['X_3']\n",
        "y_3 = datasets['y_3']\n",
        "\n",
        "X_train_3, X_val_3, y_train_3, y_val_3 = train_test_split(X_3, y_3, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = ParameterGrid({\n",
        "    'n_estimators': [250, 500, 1000, 2000, 4000, 8000],\n",
        "    'min_samples_split': [10, 20, 50, 100, 250],\n",
        "    'min_samples_leaf': [10, 20, 50, 100, 250],\n",
        "    'max_depth': [None, 30, 20, 15, 10, 3, 2],\n",
        "    'max_features': ['sqrt', 'log2', 20, 10]\n",
        "    })\n",
        "\n",
        "score_ = 0\n",
        "params_ = None\n",
        "for params in param_grid:\n",
        "  rf_current = ensemble.RandomForestRegressor(\n",
        "                n_estimators=params['n_estimators'],\n",
        "                min_samples_split=params['min_samples_split'],\n",
        "                min_samples_leaf=params['min_samples_leaf'],\n",
        "                max_depth=params['max_depth'],\n",
        "                max_features=params['max_features'],\n",
        "                )\n",
        "  rf_current.fit(X_train_3, y_train_3)\n",
        "  y_val_hat = rf_current.predict(X_val_3)\n",
        "  val_MAE = mean_absolute_error(y_val_hat, y_val_3)\n",
        "  if val_MAE > score_:\n",
        "    score_ = val_MAE\n",
        "    params_ = params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLzpFxdhaO9W",
        "outputId": "cf6c3d5d-b18f-4599-be24-23f6b1d2d420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For RF the best hyperparameters are: {'max_depth': None, 'max_features': 20, 'min_samples_leaf': 10, 'min_samples_split': 20, 'n_estimators': 500}, the mean average error of the model is: 6.561423749354163\n"
          ]
        }
      ],
      "source": [
        "print(f\"For RF the best hyperparameters are: {params_}, the mean average error of the model is: {val_MAE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG36H_xdbSBv"
      },
      "source": [
        "## Train the models with the chosen hyperparameters, and predict on the test data for kaggle upload."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey8EMZmXh6jN"
      },
      "source": [
        "**Dataframe for ensemble:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-fB9P64iCiZ"
      },
      "outputs": [],
      "source": [
        "df_ensemble = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8doYyx-QiD5q"
      },
      "source": [
        "**Model 1 (FFNN) predictions:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxcpxVoRrlwP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1362c0c-9519-42a7-fae9-2ccec940be9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 142.5507 - mae: 8.9124 - val_loss: 146.1193 - val_mae: 9.0125\n",
            "Epoch 2/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 142.3622 - mae: 8.8955 - val_loss: 145.7676 - val_mae: 8.9969\n",
            "Epoch 3/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 141.9073 - mae: 8.8776 - val_loss: 145.4147 - val_mae: 8.9798\n",
            "Epoch 4/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 141.9206 - mae: 8.8739 - val_loss: 145.7307 - val_mae: 8.9929\n",
            "Epoch 5/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 141.4021 - mae: 8.8546 - val_loss: 145.1270 - val_mae: 8.9660\n",
            "Epoch 6/10000\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 141.4425 - mae: 8.8488 - val_loss: 144.4010 - val_mae: 8.9327\n",
            "Epoch 7/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 141.0882 - mae: 8.8381 - val_loss: 144.7233 - val_mae: 8.9466\n",
            "Epoch 8/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 140.9837 - mae: 8.8352 - val_loss: 144.0053 - val_mae: 8.9145\n",
            "Epoch 9/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 140.6047 - mae: 8.8098 - val_loss: 144.3473 - val_mae: 8.9298\n",
            "Epoch 10/10000\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 140.3636 - mae: 8.7982 - val_loss: 144.0245 - val_mae: 8.9148\n",
            "Epoch 11/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 140.2635 - mae: 8.8076 - val_loss: 143.7212 - val_mae: 8.9011\n",
            "Epoch 12/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 139.7688 - mae: 8.7768 - val_loss: 143.6362 - val_mae: 8.8967\n",
            "Epoch 13/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 139.5033 - mae: 8.7704 - val_loss: 143.1441 - val_mae: 8.8746\n",
            "Epoch 14/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 139.5652 - mae: 8.7620 - val_loss: 143.0488 - val_mae: 8.8704\n",
            "Epoch 15/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 139.4581 - mae: 8.7716 - val_loss: 142.8131 - val_mae: 8.8586\n",
            "Epoch 16/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 139.0077 - mae: 8.7384 - val_loss: 142.9012 - val_mae: 8.8621\n",
            "Epoch 17/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 139.3729 - mae: 8.7532 - val_loss: 142.1910 - val_mae: 8.8311\n",
            "Epoch 18/10000\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 138.7214 - mae: 8.7279 - val_loss: 142.5145 - val_mae: 8.8440\n",
            "Epoch 19/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 138.5066 - mae: 8.7255 - val_loss: 142.2867 - val_mae: 8.8353\n",
            "Epoch 20/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 138.6845 - mae: 8.7293 - val_loss: 142.0304 - val_mae: 8.8229\n",
            "Epoch 21/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 138.3549 - mae: 8.7274 - val_loss: 142.1069 - val_mae: 8.8271\n",
            "Epoch 22/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 138.5692 - mae: 8.7250 - val_loss: 141.6208 - val_mae: 8.8036\n",
            "Epoch 23/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 138.2270 - mae: 8.7082 - val_loss: 141.7220 - val_mae: 8.8090\n",
            "Epoch 24/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 138.4923 - mae: 8.7275 - val_loss: 141.5109 - val_mae: 8.7982\n",
            "Epoch 25/10000\n",
            "500/500 [==============================] - 6s 11ms/step - loss: 137.5562 - mae: 8.6843 - val_loss: 141.7989 - val_mae: 8.8122\n",
            "Epoch 26/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 137.8367 - mae: 8.7020 - val_loss: 141.5100 - val_mae: 8.7986\n",
            "Epoch 27/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 137.6930 - mae: 8.6897 - val_loss: 141.2504 - val_mae: 8.7867\n",
            "Epoch 28/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 137.5110 - mae: 8.6827 - val_loss: 141.0530 - val_mae: 8.7776\n",
            "Epoch 29/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 137.6447 - mae: 8.6864 - val_loss: 141.1590 - val_mae: 8.7827\n",
            "Epoch 30/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 137.1219 - mae: 8.6623 - val_loss: 140.8744 - val_mae: 8.7690\n",
            "Epoch 31/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 137.1223 - mae: 8.6669 - val_loss: 140.9179 - val_mae: 8.7713\n",
            "Epoch 32/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 137.0281 - mae: 8.6493 - val_loss: 140.6453 - val_mae: 8.7589\n",
            "Epoch 33/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 137.0507 - mae: 8.6612 - val_loss: 140.4725 - val_mae: 8.7512\n",
            "Epoch 34/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 136.9821 - mae: 8.6575 - val_loss: 140.2545 - val_mae: 8.7410\n",
            "Epoch 35/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 136.5376 - mae: 8.6335 - val_loss: 140.0231 - val_mae: 8.7303\n",
            "Epoch 36/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 136.7927 - mae: 8.6465 - val_loss: 140.3800 - val_mae: 8.7455\n",
            "Epoch 37/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 136.6403 - mae: 8.6405 - val_loss: 140.3852 - val_mae: 8.7450\n",
            "Epoch 38/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 136.0716 - mae: 8.6257 - val_loss: 139.5924 - val_mae: 8.7103\n",
            "Epoch 39/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 136.0812 - mae: 8.6151 - val_loss: 139.8988 - val_mae: 8.7228\n",
            "Epoch 40/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 135.8962 - mae: 8.6097 - val_loss: 139.6218 - val_mae: 8.7117\n",
            "Epoch 41/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 135.9465 - mae: 8.6080 - val_loss: 139.5312 - val_mae: 8.7066\n",
            "Epoch 42/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 136.1773 - mae: 8.6121 - val_loss: 139.3539 - val_mae: 8.6995\n",
            "Epoch 43/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 135.6524 - mae: 8.5994 - val_loss: 139.0439 - val_mae: 8.6857\n",
            "Epoch 44/10000\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 135.5164 - mae: 8.5945 - val_loss: 139.1471 - val_mae: 8.6886\n",
            "Epoch 45/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 135.7957 - mae: 8.6019 - val_loss: 138.9303 - val_mae: 8.6791\n",
            "Epoch 46/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 135.3609 - mae: 8.5845 - val_loss: 139.1303 - val_mae: 8.6892\n",
            "Epoch 47/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 135.0898 - mae: 8.5704 - val_loss: 138.8555 - val_mae: 8.6767\n",
            "Epoch 48/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 135.2200 - mae: 8.5787 - val_loss: 139.1443 - val_mae: 8.6896\n",
            "Epoch 49/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 135.2251 - mae: 8.5710 - val_loss: 138.6678 - val_mae: 8.6668\n",
            "Epoch 50/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 134.8026 - mae: 8.5643 - val_loss: 138.7229 - val_mae: 8.6687\n",
            "Epoch 51/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 135.2978 - mae: 8.5805 - val_loss: 138.6267 - val_mae: 8.6646\n",
            "Epoch 52/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 134.6182 - mae: 8.5521 - val_loss: 138.3100 - val_mae: 8.6509\n",
            "Epoch 53/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 134.8495 - mae: 8.5552 - val_loss: 137.9708 - val_mae: 8.6361\n",
            "Epoch 54/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 134.8282 - mae: 8.5554 - val_loss: 137.9354 - val_mae: 8.6327\n",
            "Epoch 55/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 134.7452 - mae: 8.5476 - val_loss: 138.2451 - val_mae: 8.6463\n",
            "Epoch 56/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 134.2957 - mae: 8.5330 - val_loss: 137.9773 - val_mae: 8.6346\n",
            "Epoch 57/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 135.2703 - mae: 8.5801 - val_loss: 138.0858 - val_mae: 8.6393\n",
            "Epoch 58/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 134.3346 - mae: 8.5289 - val_loss: 137.7185 - val_mae: 8.6231\n",
            "Epoch 59/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 134.2569 - mae: 8.5259 - val_loss: 137.2999 - val_mae: 8.6052\n",
            "Epoch 60/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 133.8550 - mae: 8.5177 - val_loss: 137.7480 - val_mae: 8.6243\n",
            "Epoch 61/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 134.0590 - mae: 8.5252 - val_loss: 137.2606 - val_mae: 8.6025\n",
            "Epoch 62/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 133.7719 - mae: 8.5141 - val_loss: 137.9261 - val_mae: 8.6317\n",
            "Epoch 63/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 134.1513 - mae: 8.5280 - val_loss: 137.5494 - val_mae: 8.6161\n",
            "Epoch 64/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 133.6492 - mae: 8.5051 - val_loss: 137.2102 - val_mae: 8.6007\n",
            "Epoch 65/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 133.9162 - mae: 8.5158 - val_loss: 136.9110 - val_mae: 8.5874\n",
            "Epoch 66/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 133.5372 - mae: 8.5032 - val_loss: 137.0992 - val_mae: 8.5944\n",
            "Epoch 67/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 133.5038 - mae: 8.5077 - val_loss: 136.8166 - val_mae: 8.5814\n",
            "Epoch 68/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 133.6082 - mae: 8.5036 - val_loss: 136.8255 - val_mae: 8.5820\n",
            "Epoch 69/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 133.0885 - mae: 8.4796 - val_loss: 136.7219 - val_mae: 8.5775\n",
            "Epoch 70/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 133.2456 - mae: 8.4845 - val_loss: 136.9784 - val_mae: 8.5889\n",
            "Epoch 71/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 132.8613 - mae: 8.4659 - val_loss: 136.5617 - val_mae: 8.5712\n",
            "Epoch 72/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 133.0562 - mae: 8.4866 - val_loss: 136.4927 - val_mae: 8.5668\n",
            "Epoch 73/10000\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 132.7868 - mae: 8.4725 - val_loss: 136.5084 - val_mae: 8.5674\n",
            "Epoch 74/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 132.8212 - mae: 8.4582 - val_loss: 136.3775 - val_mae: 8.5612\n",
            "Epoch 75/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 132.6382 - mae: 8.4748 - val_loss: 136.2539 - val_mae: 8.5564\n",
            "Epoch 76/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 132.5941 - mae: 8.4644 - val_loss: 136.3637 - val_mae: 8.5611\n",
            "Epoch 77/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 132.3133 - mae: 8.4590 - val_loss: 136.1315 - val_mae: 8.5499\n",
            "Epoch 78/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 132.8084 - mae: 8.4656 - val_loss: 136.1857 - val_mae: 8.5521\n",
            "Epoch 79/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 132.2390 - mae: 8.4453 - val_loss: 136.3533 - val_mae: 8.5603\n",
            "Epoch 80/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 132.8148 - mae: 8.4668 - val_loss: 135.6681 - val_mae: 8.5298\n",
            "Epoch 81/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 132.5959 - mae: 8.4593 - val_loss: 135.9152 - val_mae: 8.5405\n",
            "Epoch 82/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 132.3332 - mae: 8.4440 - val_loss: 135.6380 - val_mae: 8.5280\n",
            "Epoch 83/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 132.3373 - mae: 8.4429 - val_loss: 135.6246 - val_mae: 8.5269\n",
            "Epoch 84/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 132.1332 - mae: 8.4378 - val_loss: 135.6093 - val_mae: 8.5269\n",
            "Epoch 85/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 132.1800 - mae: 8.4404 - val_loss: 135.4439 - val_mae: 8.5198\n",
            "Epoch 86/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 131.8958 - mae: 8.4274 - val_loss: 135.2285 - val_mae: 8.5094\n",
            "Epoch 87/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 132.3124 - mae: 8.4407 - val_loss: 135.6235 - val_mae: 8.5263\n",
            "Epoch 88/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 131.6307 - mae: 8.4213 - val_loss: 135.4508 - val_mae: 8.5192\n",
            "Epoch 89/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 131.5121 - mae: 8.4162 - val_loss: 134.8800 - val_mae: 8.4937\n",
            "Epoch 90/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 131.5399 - mae: 8.4135 - val_loss: 134.9301 - val_mae: 8.4954\n",
            "Epoch 91/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 131.4171 - mae: 8.4062 - val_loss: 134.8268 - val_mae: 8.4912\n",
            "Epoch 92/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 131.2648 - mae: 8.4009 - val_loss: 135.1106 - val_mae: 8.5033\n",
            "Epoch 93/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 131.5032 - mae: 8.4161 - val_loss: 134.9705 - val_mae: 8.4971\n",
            "Epoch 94/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 131.2137 - mae: 8.4001 - val_loss: 135.1025 - val_mae: 8.5015\n",
            "Epoch 95/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 131.4782 - mae: 8.4020 - val_loss: 134.6844 - val_mae: 8.4839\n",
            "Epoch 96/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 131.5223 - mae: 8.4075 - val_loss: 134.6280 - val_mae: 8.4809\n",
            "Epoch 97/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 130.9164 - mae: 8.3916 - val_loss: 134.6485 - val_mae: 8.4833\n",
            "Epoch 98/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 131.0939 - mae: 8.3899 - val_loss: 134.3710 - val_mae: 8.4709\n",
            "Epoch 99/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 131.2053 - mae: 8.3877 - val_loss: 134.2492 - val_mae: 8.4646\n",
            "Epoch 100/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 130.8807 - mae: 8.3787 - val_loss: 134.5559 - val_mae: 8.4772\n",
            "Epoch 101/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 131.1371 - mae: 8.3887 - val_loss: 134.4333 - val_mae: 8.4727\n",
            "Epoch 102/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 130.6371 - mae: 8.3759 - val_loss: 134.2193 - val_mae: 8.4626\n",
            "Epoch 103/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 130.8753 - mae: 8.3823 - val_loss: 134.0689 - val_mae: 8.4557\n",
            "Epoch 104/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 130.5744 - mae: 8.3795 - val_loss: 134.3743 - val_mae: 8.4693\n",
            "Epoch 105/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 130.4433 - mae: 8.3643 - val_loss: 134.0580 - val_mae: 8.4564\n",
            "Epoch 106/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 130.3966 - mae: 8.3704 - val_loss: 133.9401 - val_mae: 8.4499\n",
            "Epoch 107/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 130.5278 - mae: 8.3663 - val_loss: 134.0206 - val_mae: 8.4535\n",
            "Epoch 108/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 130.3806 - mae: 8.3577 - val_loss: 133.9740 - val_mae: 8.4515\n",
            "Epoch 109/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 130.4363 - mae: 8.3634 - val_loss: 133.7236 - val_mae: 8.4417\n",
            "Epoch 110/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 130.4558 - mae: 8.3546 - val_loss: 133.8930 - val_mae: 8.4475\n",
            "Epoch 111/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 130.0196 - mae: 8.3554 - val_loss: 133.7856 - val_mae: 8.4438\n",
            "Epoch 112/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 130.1018 - mae: 8.3483 - val_loss: 133.4957 - val_mae: 8.4294\n",
            "Epoch 113/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 130.0338 - mae: 8.3414 - val_loss: 133.4003 - val_mae: 8.4247\n",
            "Epoch 114/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 129.7149 - mae: 8.3292 - val_loss: 133.3586 - val_mae: 8.4240\n",
            "Epoch 115/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 129.6346 - mae: 8.3313 - val_loss: 133.3821 - val_mae: 8.4245\n",
            "Epoch 116/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 129.6125 - mae: 8.3236 - val_loss: 133.2591 - val_mae: 8.4185\n",
            "Epoch 117/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 129.4601 - mae: 8.3217 - val_loss: 133.3419 - val_mae: 8.4227\n",
            "Epoch 118/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 129.8786 - mae: 8.3395 - val_loss: 133.0283 - val_mae: 8.4092\n",
            "Epoch 119/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 129.6745 - mae: 8.3344 - val_loss: 132.9456 - val_mae: 8.4052\n",
            "Epoch 120/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 129.6625 - mae: 8.3278 - val_loss: 132.8365 - val_mae: 8.4015\n",
            "Epoch 121/10000\n",
            "500/500 [==============================] - 2s 5ms/step - loss: 129.4484 - mae: 8.3228 - val_loss: 132.8104 - val_mae: 8.3987\n",
            "Epoch 122/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 129.5840 - mae: 8.3201 - val_loss: 132.8296 - val_mae: 8.3996\n",
            "Epoch 123/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 129.1414 - mae: 8.3113 - val_loss: 132.8914 - val_mae: 8.4018\n",
            "Epoch 124/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 129.1415 - mae: 8.3063 - val_loss: 132.6100 - val_mae: 8.3901\n",
            "Epoch 125/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 128.6837 - mae: 8.2908 - val_loss: 132.6161 - val_mae: 8.3898\n",
            "Epoch 126/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 129.2528 - mae: 8.3066 - val_loss: 132.0968 - val_mae: 8.3678\n",
            "Epoch 127/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 129.1409 - mae: 8.3037 - val_loss: 132.5305 - val_mae: 8.3857\n",
            "Epoch 128/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 128.7170 - mae: 8.2918 - val_loss: 132.5154 - val_mae: 8.3857\n",
            "Epoch 129/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 128.7641 - mae: 8.2964 - val_loss: 132.6400 - val_mae: 8.3907\n",
            "Epoch 130/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 128.7142 - mae: 8.2949 - val_loss: 132.4274 - val_mae: 8.3815\n",
            "Epoch 131/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 128.9383 - mae: 8.2926 - val_loss: 131.9397 - val_mae: 8.3601\n",
            "Epoch 132/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 128.3366 - mae: 8.2755 - val_loss: 132.3224 - val_mae: 8.3752\n",
            "Epoch 133/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 128.4533 - mae: 8.2727 - val_loss: 132.2299 - val_mae: 8.3721\n",
            "Epoch 134/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 128.6732 - mae: 8.2837 - val_loss: 132.1142 - val_mae: 8.3668\n",
            "Epoch 135/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 128.5280 - mae: 8.2808 - val_loss: 131.8961 - val_mae: 8.3575\n",
            "Epoch 136/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 128.4572 - mae: 8.2850 - val_loss: 131.9215 - val_mae: 8.3574\n",
            "Epoch 137/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 127.8484 - mae: 8.2556 - val_loss: 131.5611 - val_mae: 8.3430\n",
            "Epoch 138/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 128.5167 - mae: 8.2682 - val_loss: 131.7778 - val_mae: 8.3531\n",
            "Epoch 139/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 128.2847 - mae: 8.2667 - val_loss: 131.5754 - val_mae: 8.3429\n",
            "Epoch 140/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 128.3971 - mae: 8.2770 - val_loss: 131.7408 - val_mae: 8.3494\n",
            "Epoch 141/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 128.0952 - mae: 8.2712 - val_loss: 131.7894 - val_mae: 8.3526\n",
            "Epoch 142/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 128.0133 - mae: 8.2517 - val_loss: 131.5621 - val_mae: 8.3425\n",
            "Epoch 143/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 127.6530 - mae: 8.2469 - val_loss: 131.2024 - val_mae: 8.3263\n",
            "Epoch 144/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 127.8363 - mae: 8.2488 - val_loss: 131.5468 - val_mae: 8.3412\n",
            "Epoch 145/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 127.7239 - mae: 8.2517 - val_loss: 131.2570 - val_mae: 8.3290\n",
            "Epoch 146/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 127.9453 - mae: 8.2520 - val_loss: 131.2179 - val_mae: 8.3263\n",
            "Epoch 147/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 127.4281 - mae: 8.2360 - val_loss: 131.2185 - val_mae: 8.3273\n",
            "Epoch 148/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 127.4833 - mae: 8.2455 - val_loss: 131.1523 - val_mae: 8.3238\n",
            "Epoch 149/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 127.7270 - mae: 8.2398 - val_loss: 131.1115 - val_mae: 8.3213\n",
            "Epoch 150/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 127.4235 - mae: 8.2353 - val_loss: 130.9718 - val_mae: 8.3161\n",
            "Epoch 151/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 127.4676 - mae: 8.2287 - val_loss: 131.0150 - val_mae: 8.3180\n",
            "Epoch 152/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 127.2505 - mae: 8.2255 - val_loss: 130.7220 - val_mae: 8.3043\n",
            "Epoch 153/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 127.0103 - mae: 8.2225 - val_loss: 130.8932 - val_mae: 8.3111\n",
            "Epoch 154/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 127.3642 - mae: 8.2206 - val_loss: 130.7636 - val_mae: 8.3058\n",
            "Epoch 155/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 127.0422 - mae: 8.2183 - val_loss: 130.6526 - val_mae: 8.3011\n",
            "Epoch 156/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 127.1703 - mae: 8.2128 - val_loss: 130.7166 - val_mae: 8.3036\n",
            "Epoch 157/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 127.3256 - mae: 8.2196 - val_loss: 130.5879 - val_mae: 8.2977\n",
            "Epoch 158/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 126.7013 - mae: 8.2081 - val_loss: 130.6615 - val_mae: 8.2999\n",
            "Epoch 159/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 127.0009 - mae: 8.2122 - val_loss: 130.3664 - val_mae: 8.2873\n",
            "Epoch 160/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 127.0033 - mae: 8.2146 - val_loss: 130.5279 - val_mae: 8.2952\n",
            "Epoch 161/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 126.8289 - mae: 8.2087 - val_loss: 130.2467 - val_mae: 8.2829\n",
            "Epoch 162/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 126.8576 - mae: 8.1990 - val_loss: 129.9406 - val_mae: 8.2707\n",
            "Epoch 163/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 126.9356 - mae: 8.2097 - val_loss: 130.3797 - val_mae: 8.2886\n",
            "Epoch 164/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 126.6169 - mae: 8.1872 - val_loss: 130.1627 - val_mae: 8.2790\n",
            "Epoch 165/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 126.5205 - mae: 8.1949 - val_loss: 130.4359 - val_mae: 8.2901\n",
            "Epoch 166/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 126.6690 - mae: 8.2041 - val_loss: 130.0965 - val_mae: 8.2751\n",
            "Epoch 167/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 126.4797 - mae: 8.1912 - val_loss: 129.6769 - val_mae: 8.2574\n",
            "Epoch 168/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 126.6936 - mae: 8.1901 - val_loss: 129.7526 - val_mae: 8.2600\n",
            "Epoch 169/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 126.3065 - mae: 8.1743 - val_loss: 129.7744 - val_mae: 8.2612\n",
            "Epoch 170/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 126.4111 - mae: 8.1985 - val_loss: 129.5503 - val_mae: 8.2521\n",
            "Epoch 171/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 126.0461 - mae: 8.1694 - val_loss: 129.4929 - val_mae: 8.2498\n",
            "Epoch 172/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 126.3016 - mae: 8.1886 - val_loss: 129.6269 - val_mae: 8.2544\n",
            "Epoch 173/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 126.5224 - mae: 8.1923 - val_loss: 129.0612 - val_mae: 8.2304\n",
            "Epoch 174/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 125.8279 - mae: 8.1728 - val_loss: 129.5111 - val_mae: 8.2499\n",
            "Epoch 175/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 126.0005 - mae: 8.1657 - val_loss: 129.2344 - val_mae: 8.2382\n",
            "Epoch 176/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 125.8780 - mae: 8.1683 - val_loss: 129.6533 - val_mae: 8.2559\n",
            "Epoch 177/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 126.0349 - mae: 8.1691 - val_loss: 129.2926 - val_mae: 8.2391\n",
            "Epoch 178/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 126.4506 - mae: 8.1873 - val_loss: 129.3572 - val_mae: 8.2420\n",
            "Epoch 179/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 125.9992 - mae: 8.1735 - val_loss: 129.2665 - val_mae: 8.2379\n",
            "Epoch 180/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 125.9516 - mae: 8.1613 - val_loss: 129.1017 - val_mae: 8.2317\n",
            "Epoch 181/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 125.7134 - mae: 8.1564 - val_loss: 129.4601 - val_mae: 8.2475\n",
            "Epoch 182/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 125.7197 - mae: 8.1589 - val_loss: 129.0868 - val_mae: 8.2301\n",
            "Epoch 183/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 125.4908 - mae: 8.1478 - val_loss: 129.1183 - val_mae: 8.2309\n",
            "Epoch 184/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 125.3921 - mae: 8.1497 - val_loss: 128.9864 - val_mae: 8.2252\n",
            "Epoch 185/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 125.1726 - mae: 8.1471 - val_loss: 128.8217 - val_mae: 8.2199\n",
            "Epoch 186/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 125.4893 - mae: 8.1408 - val_loss: 128.8358 - val_mae: 8.2194\n",
            "Epoch 187/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 125.4273 - mae: 8.1528 - val_loss: 128.6954 - val_mae: 8.2118\n",
            "Epoch 188/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 125.1279 - mae: 8.1349 - val_loss: 128.8794 - val_mae: 8.2210\n",
            "Epoch 189/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 125.3249 - mae: 8.1388 - val_loss: 128.8478 - val_mae: 8.2200\n",
            "Epoch 190/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 125.0751 - mae: 8.1337 - val_loss: 128.6131 - val_mae: 8.2094\n",
            "Epoch 191/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.8503 - mae: 8.1198 - val_loss: 128.2268 - val_mae: 8.1928\n",
            "Epoch 192/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 125.0241 - mae: 8.1305 - val_loss: 128.6436 - val_mae: 8.2107\n",
            "Epoch 193/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 124.7186 - mae: 8.1200 - val_loss: 128.2864 - val_mae: 8.1957\n",
            "Epoch 194/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 124.7302 - mae: 8.1258 - val_loss: 128.2708 - val_mae: 8.1945\n",
            "Epoch 195/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.7460 - mae: 8.1106 - val_loss: 128.3414 - val_mae: 8.1973\n",
            "Epoch 196/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.9677 - mae: 8.1300 - val_loss: 128.3382 - val_mae: 8.1964\n",
            "Epoch 197/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 124.7179 - mae: 8.1137 - val_loss: 128.0771 - val_mae: 8.1862\n",
            "Epoch 198/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 124.5699 - mae: 8.1215 - val_loss: 127.9715 - val_mae: 8.1810\n",
            "Epoch 199/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.3404 - mae: 8.1032 - val_loss: 127.9961 - val_mae: 8.1823\n",
            "Epoch 200/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.4548 - mae: 8.1023 - val_loss: 128.2734 - val_mae: 8.1937\n",
            "Epoch 201/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.6026 - mae: 8.0959 - val_loss: 127.8221 - val_mae: 8.1745\n",
            "Epoch 202/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 124.8631 - mae: 8.1204 - val_loss: 127.9586 - val_mae: 8.1807\n",
            "Epoch 203/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 124.4906 - mae: 8.1018 - val_loss: 127.8195 - val_mae: 8.1738\n",
            "Epoch 204/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 124.3035 - mae: 8.1010 - val_loss: 127.9043 - val_mae: 8.1777\n",
            "Epoch 205/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.1634 - mae: 8.0853 - val_loss: 127.8251 - val_mae: 8.1744\n",
            "Epoch 206/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.4749 - mae: 8.1033 - val_loss: 127.8430 - val_mae: 8.1752\n",
            "Epoch 207/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.2693 - mae: 8.0754 - val_loss: 127.6137 - val_mae: 8.1655\n",
            "Epoch 208/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 124.2170 - mae: 8.0846 - val_loss: 127.7914 - val_mae: 8.1724\n",
            "Epoch 209/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 124.2534 - mae: 8.0867 - val_loss: 127.3668 - val_mae: 8.1548\n",
            "Epoch 210/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 124.0346 - mae: 8.0885 - val_loss: 127.5453 - val_mae: 8.1625\n",
            "Epoch 211/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.7679 - mae: 8.0711 - val_loss: 127.6264 - val_mae: 8.1642\n",
            "Epoch 212/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.8146 - mae: 8.0740 - val_loss: 127.1907 - val_mae: 8.1474\n",
            "Epoch 213/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 123.5948 - mae: 8.0708 - val_loss: 127.3760 - val_mae: 8.1543\n",
            "Epoch 214/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 123.7416 - mae: 8.0767 - val_loss: 126.8529 - val_mae: 8.1313\n",
            "Epoch 215/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 123.8302 - mae: 8.0791 - val_loss: 127.0375 - val_mae: 8.1399\n",
            "Epoch 216/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.8530 - mae: 8.0758 - val_loss: 127.1532 - val_mae: 8.1450\n",
            "Epoch 217/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.7080 - mae: 8.0711 - val_loss: 126.6805 - val_mae: 8.1247\n",
            "Epoch 218/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.8426 - mae: 8.0804 - val_loss: 126.8695 - val_mae: 8.1323\n",
            "Epoch 219/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 123.5832 - mae: 8.0700 - val_loss: 126.8536 - val_mae: 8.1328\n",
            "Epoch 220/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 123.5824 - mae: 8.0714 - val_loss: 127.0094 - val_mae: 8.1388\n",
            "Epoch 221/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.2861 - mae: 8.0602 - val_loss: 126.7961 - val_mae: 8.1284\n",
            "Epoch 222/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.6324 - mae: 8.0629 - val_loss: 126.7601 - val_mae: 8.1284\n",
            "Epoch 223/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.2341 - mae: 8.0448 - val_loss: 126.4221 - val_mae: 8.1130\n",
            "Epoch 224/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 123.5601 - mae: 8.0602 - val_loss: 126.9246 - val_mae: 8.1338\n",
            "Epoch 225/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 123.1507 - mae: 8.0415 - val_loss: 126.4413 - val_mae: 8.1137\n",
            "Epoch 226/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 122.9631 - mae: 8.0364 - val_loss: 126.5657 - val_mae: 8.1186\n",
            "Epoch 227/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 123.2621 - mae: 8.0366 - val_loss: 126.3028 - val_mae: 8.1073\n",
            "Epoch 228/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.0889 - mae: 8.0502 - val_loss: 126.5679 - val_mae: 8.1185\n",
            "Epoch 229/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 122.9986 - mae: 8.0357 - val_loss: 126.2688 - val_mae: 8.1061\n",
            "Epoch 230/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 122.6246 - mae: 8.0313 - val_loss: 126.3815 - val_mae: 8.1099\n",
            "Epoch 231/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 122.7911 - mae: 8.0385 - val_loss: 126.0471 - val_mae: 8.0966\n",
            "Epoch 232/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 123.3131 - mae: 8.0420 - val_loss: 126.1715 - val_mae: 8.1032\n",
            "Epoch 233/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 122.3691 - mae: 8.0176 - val_loss: 126.0145 - val_mae: 8.0954\n",
            "Epoch 234/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 122.7212 - mae: 8.0191 - val_loss: 125.7681 - val_mae: 8.0839\n",
            "Epoch 235/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 122.5872 - mae: 8.0252 - val_loss: 126.2058 - val_mae: 8.1021\n",
            "Epoch 236/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 122.6219 - mae: 8.0211 - val_loss: 125.9579 - val_mae: 8.0926\n",
            "Epoch 237/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 122.8161 - mae: 8.0261 - val_loss: 125.9680 - val_mae: 8.0930\n",
            "Epoch 238/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 122.7064 - mae: 8.0271 - val_loss: 126.1226 - val_mae: 8.0987\n",
            "Epoch 239/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 122.4147 - mae: 8.0191 - val_loss: 125.8410 - val_mae: 8.0875\n",
            "Epoch 240/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 122.6383 - mae: 8.0247 - val_loss: 125.6880 - val_mae: 8.0804\n",
            "Epoch 241/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 122.3919 - mae: 8.0145 - val_loss: 125.7407 - val_mae: 8.0821\n",
            "Epoch 242/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 122.5467 - mae: 8.0144 - val_loss: 125.7868 - val_mae: 8.0845\n",
            "Epoch 243/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 122.3168 - mae: 8.0056 - val_loss: 125.3598 - val_mae: 8.0679\n",
            "Epoch 244/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 122.0012 - mae: 8.0035 - val_loss: 125.8299 - val_mae: 8.0859\n",
            "Epoch 245/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 122.2909 - mae: 8.0123 - val_loss: 125.2794 - val_mae: 8.0642\n",
            "Epoch 246/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 121.9789 - mae: 8.0010 - val_loss: 125.4595 - val_mae: 8.0699\n",
            "Epoch 247/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 121.9097 - mae: 8.0049 - val_loss: 125.5063 - val_mae: 8.0726\n",
            "Epoch 248/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 122.1477 - mae: 8.0061 - val_loss: 125.3291 - val_mae: 8.0648\n",
            "Epoch 249/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.9690 - mae: 8.0037 - val_loss: 125.5507 - val_mae: 8.0742\n",
            "Epoch 250/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.5686 - mae: 8.0000 - val_loss: 125.4239 - val_mae: 8.0685\n",
            "Epoch 251/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 121.7226 - mae: 7.9876 - val_loss: 124.9436 - val_mae: 8.0486\n",
            "Epoch 252/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 121.4186 - mae: 7.9809 - val_loss: 125.0944 - val_mae: 8.0548\n",
            "Epoch 253/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.6995 - mae: 7.9794 - val_loss: 125.1690 - val_mae: 8.0577\n",
            "Epoch 254/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 122.0403 - mae: 7.9956 - val_loss: 125.0483 - val_mae: 8.0522\n",
            "Epoch 255/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.4208 - mae: 7.9878 - val_loss: 124.7152 - val_mae: 8.0382\n",
            "Epoch 256/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 121.4634 - mae: 7.9771 - val_loss: 124.8213 - val_mae: 8.0442\n",
            "Epoch 257/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 121.6110 - mae: 7.9802 - val_loss: 125.2886 - val_mae: 8.0621\n",
            "Epoch 258/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 120.9765 - mae: 7.9639 - val_loss: 124.6682 - val_mae: 8.0363\n",
            "Epoch 259/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.2785 - mae: 7.9536 - val_loss: 124.6922 - val_mae: 8.0363\n",
            "Epoch 260/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.3512 - mae: 7.9594 - val_loss: 124.7833 - val_mae: 8.0408\n",
            "Epoch 261/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.2053 - mae: 7.9674 - val_loss: 124.3651 - val_mae: 8.0238\n",
            "Epoch 262/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 121.0480 - mae: 7.9671 - val_loss: 124.6291 - val_mae: 8.0340\n",
            "Epoch 263/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 120.7554 - mae: 7.9579 - val_loss: 124.4669 - val_mae: 8.0268\n",
            "Epoch 264/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 120.7206 - mae: 7.9471 - val_loss: 124.4417 - val_mae: 8.0259\n",
            "Epoch 265/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.8099 - mae: 7.9472 - val_loss: 124.2425 - val_mae: 8.0188\n",
            "Epoch 266/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.2385 - mae: 7.9546 - val_loss: 124.4346 - val_mae: 8.0246\n",
            "Epoch 267/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 120.8387 - mae: 7.9413 - val_loss: 124.1028 - val_mae: 8.0119\n",
            "Epoch 268/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 120.9026 - mae: 7.9488 - val_loss: 124.2077 - val_mae: 8.0171\n",
            "Epoch 269/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 121.0307 - mae: 7.9499 - val_loss: 124.1027 - val_mae: 8.0118\n",
            "Epoch 270/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.8264 - mae: 7.9512 - val_loss: 124.2889 - val_mae: 8.0202\n",
            "Epoch 271/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 120.5416 - mae: 7.9373 - val_loss: 124.2658 - val_mae: 8.0173\n",
            "Epoch 272/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 121.0863 - mae: 7.9592 - val_loss: 123.9143 - val_mae: 8.0042\n",
            "Epoch 273/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 121.1064 - mae: 7.9624 - val_loss: 123.8967 - val_mae: 8.0021\n",
            "Epoch 274/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 120.3320 - mae: 7.9308 - val_loss: 123.8061 - val_mae: 7.9991\n",
            "Epoch 275/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.5001 - mae: 7.9423 - val_loss: 123.9822 - val_mae: 8.0067\n",
            "Epoch 276/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.3344 - mae: 7.9341 - val_loss: 124.1898 - val_mae: 8.0140\n",
            "Epoch 277/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.5464 - mae: 7.9373 - val_loss: 123.9546 - val_mae: 8.0054\n",
            "Epoch 278/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 120.0471 - mae: 7.9166 - val_loss: 123.5653 - val_mae: 7.9889\n",
            "Epoch 279/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 120.4585 - mae: 7.9390 - val_loss: 123.7393 - val_mae: 7.9960\n",
            "Epoch 280/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.0444 - mae: 7.9153 - val_loss: 123.5775 - val_mae: 7.9892\n",
            "Epoch 281/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 119.9225 - mae: 7.9201 - val_loss: 123.9270 - val_mae: 8.0041\n",
            "Epoch 282/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.4080 - mae: 7.9299 - val_loss: 123.6561 - val_mae: 7.9912\n",
            "Epoch 283/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 120.3325 - mae: 7.9227 - val_loss: 123.7569 - val_mae: 7.9957\n",
            "Epoch 284/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 120.1572 - mae: 7.9212 - val_loss: 123.5668 - val_mae: 7.9880\n",
            "Epoch 285/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 119.7408 - mae: 7.8980 - val_loss: 123.3562 - val_mae: 7.9800\n",
            "Epoch 286/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 119.9198 - mae: 7.9083 - val_loss: 123.2268 - val_mae: 7.9741\n",
            "Epoch 287/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.0540 - mae: 7.9183 - val_loss: 123.2833 - val_mae: 7.9769\n",
            "Epoch 288/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 120.1740 - mae: 7.9138 - val_loss: 123.2829 - val_mae: 7.9748\n",
            "Epoch 289/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 120.0570 - mae: 7.9108 - val_loss: 123.2324 - val_mae: 7.9733\n",
            "Epoch 290/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 120.0611 - mae: 7.9158 - val_loss: 123.0788 - val_mae: 7.9674\n",
            "Epoch 291/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 119.6550 - mae: 7.8975 - val_loss: 122.9789 - val_mae: 7.9626\n",
            "Epoch 292/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 120.1717 - mae: 7.9169 - val_loss: 123.2977 - val_mae: 7.9759\n",
            "Epoch 293/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 119.6871 - mae: 7.8878 - val_loss: 123.1681 - val_mae: 7.9691\n",
            "Epoch 294/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 119.1028 - mae: 7.8707 - val_loss: 122.7612 - val_mae: 7.9532\n",
            "Epoch 295/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 119.4655 - mae: 7.9016 - val_loss: 123.1181 - val_mae: 7.9677\n",
            "Epoch 296/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 119.8466 - mae: 7.9109 - val_loss: 123.0150 - val_mae: 7.9631\n",
            "Epoch 297/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 119.6545 - mae: 7.8849 - val_loss: 122.9648 - val_mae: 7.9615\n",
            "Epoch 298/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 119.2876 - mae: 7.8832 - val_loss: 123.0201 - val_mae: 7.9632\n",
            "Epoch 299/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 119.3370 - mae: 7.8879 - val_loss: 122.8025 - val_mae: 7.9548\n",
            "Epoch 300/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 119.5350 - mae: 7.8875 - val_loss: 122.5658 - val_mae: 7.9453\n",
            "Epoch 301/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 119.1414 - mae: 7.8678 - val_loss: 122.5719 - val_mae: 7.9447\n",
            "Epoch 302/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 119.2798 - mae: 7.8864 - val_loss: 122.5919 - val_mae: 7.9472\n",
            "Epoch 303/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 119.1703 - mae: 7.8801 - val_loss: 122.4466 - val_mae: 7.9395\n",
            "Epoch 304/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.8102 - mae: 7.8704 - val_loss: 122.3201 - val_mae: 7.9338\n",
            "Epoch 305/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 118.8862 - mae: 7.8748 - val_loss: 122.3414 - val_mae: 7.9363\n",
            "Epoch 306/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 118.9024 - mae: 7.8761 - val_loss: 122.3710 - val_mae: 7.9364\n",
            "Epoch 307/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 119.2454 - mae: 7.8850 - val_loss: 122.2456 - val_mae: 7.9314\n",
            "Epoch 308/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.8985 - mae: 7.8688 - val_loss: 122.0528 - val_mae: 7.9230\n",
            "Epoch 309/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.7129 - mae: 7.8652 - val_loss: 122.5930 - val_mae: 7.9445\n",
            "Epoch 310/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 118.5687 - mae: 7.8549 - val_loss: 122.1461 - val_mae: 7.9261\n",
            "Epoch 311/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 118.6746 - mae: 7.8620 - val_loss: 122.1129 - val_mae: 7.9244\n",
            "Epoch 312/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 118.2990 - mae: 7.8465 - val_loss: 121.8266 - val_mae: 7.9122\n",
            "Epoch 313/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.7808 - mae: 7.8659 - val_loss: 121.9199 - val_mae: 7.9170\n",
            "Epoch 314/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.7377 - mae: 7.8665 - val_loss: 121.8822 - val_mae: 7.9155\n",
            "Epoch 315/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.3313 - mae: 7.8394 - val_loss: 121.6625 - val_mae: 7.9060\n",
            "Epoch 316/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 118.7534 - mae: 7.8613 - val_loss: 121.9024 - val_mae: 7.9166\n",
            "Epoch 317/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 118.3836 - mae: 7.8450 - val_loss: 121.8729 - val_mae: 7.9143\n",
            "Epoch 318/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 118.2727 - mae: 7.8387 - val_loss: 121.6557 - val_mae: 7.9059\n",
            "Epoch 319/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.3877 - mae: 7.8367 - val_loss: 121.7819 - val_mae: 7.9106\n",
            "Epoch 320/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.1697 - mae: 7.8356 - val_loss: 121.8549 - val_mae: 7.9129\n",
            "Epoch 321/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.2021 - mae: 7.8415 - val_loss: 121.5608 - val_mae: 7.9017\n",
            "Epoch 322/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 117.9981 - mae: 7.8401 - val_loss: 121.5607 - val_mae: 7.9013\n",
            "Epoch 323/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 118.2501 - mae: 7.8405 - val_loss: 121.3757 - val_mae: 7.8941\n",
            "Epoch 324/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 117.9477 - mae: 7.8229 - val_loss: 121.3228 - val_mae: 7.8907\n",
            "Epoch 325/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.0579 - mae: 7.8221 - val_loss: 121.3965 - val_mae: 7.8946\n",
            "Epoch 326/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 118.3233 - mae: 7.8488 - val_loss: 121.5443 - val_mae: 7.9008\n",
            "Epoch 327/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 117.9595 - mae: 7.8269 - val_loss: 121.3222 - val_mae: 7.8916\n",
            "Epoch 328/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 117.5772 - mae: 7.8070 - val_loss: 121.0570 - val_mae: 7.8802\n",
            "Epoch 329/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 117.6392 - mae: 7.8058 - val_loss: 121.3233 - val_mae: 7.8911\n",
            "Epoch 330/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 117.9152 - mae: 7.8190 - val_loss: 121.2918 - val_mae: 7.8896\n",
            "Epoch 331/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 117.9293 - mae: 7.8285 - val_loss: 121.2285 - val_mae: 7.8870\n",
            "Epoch 332/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 117.7512 - mae: 7.8128 - val_loss: 121.0024 - val_mae: 7.8781\n",
            "Epoch 333/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 118.1057 - mae: 7.8302 - val_loss: 120.9417 - val_mae: 7.8753\n",
            "Epoch 334/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 117.6071 - mae: 7.8262 - val_loss: 120.8458 - val_mae: 7.8709\n",
            "Epoch 335/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 117.6472 - mae: 7.8203 - val_loss: 120.6220 - val_mae: 7.8622\n",
            "Epoch 336/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 117.5087 - mae: 7.8050 - val_loss: 120.7959 - val_mae: 7.8695\n",
            "Epoch 337/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 117.3144 - mae: 7.8062 - val_loss: 120.6649 - val_mae: 7.8631\n",
            "Epoch 338/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 117.5418 - mae: 7.8020 - val_loss: 120.7518 - val_mae: 7.8658\n",
            "Epoch 339/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 117.5228 - mae: 7.8016 - val_loss: 120.4217 - val_mae: 7.8535\n",
            "Epoch 340/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 117.5228 - mae: 7.8155 - val_loss: 120.7699 - val_mae: 7.8670\n",
            "Epoch 341/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 117.6453 - mae: 7.8021 - val_loss: 120.6766 - val_mae: 7.8631\n",
            "Epoch 342/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 117.3457 - mae: 7.8059 - val_loss: 120.7112 - val_mae: 7.8645\n",
            "Epoch 343/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 117.1602 - mae: 7.8125 - val_loss: 120.5930 - val_mae: 7.8591\n",
            "Epoch 344/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 117.1587 - mae: 7.7972 - val_loss: 120.3073 - val_mae: 7.8479\n",
            "Epoch 345/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 117.3010 - mae: 7.8011 - val_loss: 120.7048 - val_mae: 7.8641\n",
            "Epoch 346/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 117.2518 - mae: 7.7975 - val_loss: 120.5680 - val_mae: 7.8593\n",
            "Epoch 347/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 116.9380 - mae: 7.7888 - val_loss: 120.1953 - val_mae: 7.8434\n",
            "Epoch 348/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 117.1424 - mae: 7.7927 - val_loss: 120.1000 - val_mae: 7.8391\n",
            "Epoch 349/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 116.7753 - mae: 7.7781 - val_loss: 120.1054 - val_mae: 7.8394\n",
            "Epoch 350/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 116.9554 - mae: 7.7842 - val_loss: 120.2371 - val_mae: 7.8440\n",
            "Epoch 351/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.6244 - mae: 7.7740 - val_loss: 119.8912 - val_mae: 7.8302\n",
            "Epoch 352/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.9426 - mae: 7.7842 - val_loss: 120.3075 - val_mae: 7.8458\n",
            "Epoch 353/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 117.0695 - mae: 7.7851 - val_loss: 119.9023 - val_mae: 7.8308\n",
            "Epoch 354/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 116.6611 - mae: 7.7819 - val_loss: 120.1818 - val_mae: 7.8419\n",
            "Epoch 355/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 116.5854 - mae: 7.7787 - val_loss: 119.9051 - val_mae: 7.8307\n",
            "Epoch 356/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.7737 - mae: 7.7684 - val_loss: 119.9148 - val_mae: 7.8318\n",
            "Epoch 357/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.6087 - mae: 7.7666 - val_loss: 119.6095 - val_mae: 7.8188\n",
            "Epoch 358/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.8801 - mae: 7.7772 - val_loss: 119.3829 - val_mae: 7.8089\n",
            "Epoch 359/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 116.4736 - mae: 7.7682 - val_loss: 119.9894 - val_mae: 7.8331\n",
            "Epoch 360/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 116.5802 - mae: 7.7577 - val_loss: 119.8562 - val_mae: 7.8289\n",
            "Epoch 361/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 116.3490 - mae: 7.7661 - val_loss: 119.5495 - val_mae: 7.8157\n",
            "Epoch 362/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.2562 - mae: 7.7567 - val_loss: 119.4607 - val_mae: 7.8118\n",
            "Epoch 363/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.2604 - mae: 7.7595 - val_loss: 119.8284 - val_mae: 7.8269\n",
            "Epoch 364/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.1376 - mae: 7.7527 - val_loss: 119.4837 - val_mae: 7.8127\n",
            "Epoch 365/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 116.1529 - mae: 7.7476 - val_loss: 119.4412 - val_mae: 7.8104\n",
            "Epoch 366/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 116.1818 - mae: 7.7531 - val_loss: 119.5041 - val_mae: 7.8131\n",
            "Epoch 367/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.1507 - mae: 7.7472 - val_loss: 119.3548 - val_mae: 7.8078\n",
            "Epoch 368/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 116.0217 - mae: 7.7505 - val_loss: 119.4139 - val_mae: 7.8088\n",
            "Epoch 369/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 115.6345 - mae: 7.7336 - val_loss: 119.3820 - val_mae: 7.8082\n",
            "Epoch 370/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 115.9724 - mae: 7.7473 - val_loss: 119.1612 - val_mae: 7.7992\n",
            "Epoch 371/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 115.4930 - mae: 7.7298 - val_loss: 119.4417 - val_mae: 7.8107\n",
            "Epoch 372/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 115.5609 - mae: 7.7289 - val_loss: 119.0374 - val_mae: 7.7940\n",
            "Epoch 373/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 115.9036 - mae: 7.7416 - val_loss: 118.8230 - val_mae: 7.7862\n",
            "Epoch 374/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 115.7561 - mae: 7.7389 - val_loss: 118.8897 - val_mae: 7.7871\n",
            "Epoch 375/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 115.5624 - mae: 7.7305 - val_loss: 119.3082 - val_mae: 7.8041\n",
            "Epoch 376/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 115.7619 - mae: 7.7494 - val_loss: 118.6879 - val_mae: 7.7794\n",
            "Epoch 377/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 115.8978 - mae: 7.7389 - val_loss: 118.7512 - val_mae: 7.7819\n",
            "Epoch 378/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 115.7470 - mae: 7.7305 - val_loss: 119.0606 - val_mae: 7.7953\n",
            "Epoch 379/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 115.7831 - mae: 7.7453 - val_loss: 118.4777 - val_mae: 7.7709\n",
            "Epoch 380/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 115.7269 - mae: 7.7275 - val_loss: 118.8759 - val_mae: 7.7862\n",
            "Epoch 381/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 115.6394 - mae: 7.7239 - val_loss: 118.9415 - val_mae: 7.7884\n",
            "Epoch 382/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 115.5070 - mae: 7.7172 - val_loss: 118.6516 - val_mae: 7.7773\n",
            "Epoch 383/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 115.1817 - mae: 7.7154 - val_loss: 118.9963 - val_mae: 7.7908\n",
            "Epoch 384/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 115.1594 - mae: 7.7036 - val_loss: 118.7005 - val_mae: 7.7793\n",
            "Epoch 385/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 115.2128 - mae: 7.7156 - val_loss: 118.3223 - val_mae: 7.7638\n",
            "Epoch 386/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 115.2817 - mae: 7.7101 - val_loss: 118.5777 - val_mae: 7.7737\n",
            "Epoch 387/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 115.3155 - mae: 7.7164 - val_loss: 118.6513 - val_mae: 7.7765\n",
            "Epoch 388/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.8799 - mae: 7.6989 - val_loss: 118.0954 - val_mae: 7.7540\n",
            "Epoch 389/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 115.2593 - mae: 7.7112 - val_loss: 118.6819 - val_mae: 7.7781\n",
            "Epoch 390/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 115.2124 - mae: 7.7245 - val_loss: 118.0599 - val_mae: 7.7525\n",
            "Epoch 391/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 115.1627 - mae: 7.7059 - val_loss: 118.0918 - val_mae: 7.7537\n",
            "Epoch 392/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 114.7771 - mae: 7.6990 - val_loss: 118.0791 - val_mae: 7.7527\n",
            "Epoch 393/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 115.0352 - mae: 7.7106 - val_loss: 118.3809 - val_mae: 7.7654\n",
            "Epoch 394/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.8942 - mae: 7.6963 - val_loss: 118.0233 - val_mae: 7.7508\n",
            "Epoch 395/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.5105 - mae: 7.6921 - val_loss: 118.2971 - val_mae: 7.7624\n",
            "Epoch 396/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.5365 - mae: 7.6760 - val_loss: 118.1389 - val_mae: 7.7556\n",
            "Epoch 397/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 114.6859 - mae: 7.6952 - val_loss: 118.1791 - val_mae: 7.7568\n",
            "Epoch 398/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 114.8063 - mae: 7.6937 - val_loss: 117.9504 - val_mae: 7.7474\n",
            "Epoch 399/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 114.7049 - mae: 7.6952 - val_loss: 117.8176 - val_mae: 7.7421\n",
            "Epoch 400/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 114.4016 - mae: 7.6813 - val_loss: 117.9115 - val_mae: 7.7462\n",
            "Epoch 401/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 114.6495 - mae: 7.6908 - val_loss: 117.9726 - val_mae: 7.7480\n",
            "Epoch 402/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 114.4231 - mae: 7.6758 - val_loss: 117.8594 - val_mae: 7.7433\n",
            "Epoch 403/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 114.4510 - mae: 7.6887 - val_loss: 117.9591 - val_mae: 7.7476\n",
            "Epoch 404/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 114.5539 - mae: 7.6880 - val_loss: 117.6250 - val_mae: 7.7341\n",
            "Epoch 405/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.4544 - mae: 7.6696 - val_loss: 117.7879 - val_mae: 7.7408\n",
            "Epoch 406/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.0212 - mae: 7.6573 - val_loss: 117.5873 - val_mae: 7.7326\n",
            "Epoch 407/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 114.4912 - mae: 7.6802 - val_loss: 117.5024 - val_mae: 7.7305\n",
            "Epoch 408/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 114.6872 - mae: 7.6791 - val_loss: 117.7027 - val_mae: 7.7377\n",
            "Epoch 409/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 114.3308 - mae: 7.6763 - val_loss: 117.2736 - val_mae: 7.7193\n",
            "Epoch 410/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 114.3288 - mae: 7.6790 - val_loss: 117.5134 - val_mae: 7.7290\n",
            "Epoch 411/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.1956 - mae: 7.6634 - val_loss: 117.3262 - val_mae: 7.7223\n",
            "Epoch 412/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 113.5818 - mae: 7.6481 - val_loss: 117.1337 - val_mae: 7.7132\n",
            "Epoch 413/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.0082 - mae: 7.6514 - val_loss: 117.4237 - val_mae: 7.7238\n",
            "Epoch 414/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 113.7137 - mae: 7.6454 - val_loss: 117.3231 - val_mae: 7.7207\n",
            "Epoch 415/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 114.0340 - mae: 7.6597 - val_loss: 117.1726 - val_mae: 7.7141\n",
            "Epoch 416/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 114.1430 - mae: 7.6690 - val_loss: 117.1023 - val_mae: 7.7115\n",
            "Epoch 417/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 114.0640 - mae: 7.6662 - val_loss: 117.0791 - val_mae: 7.7121\n",
            "Epoch 418/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 113.9223 - mae: 7.6579 - val_loss: 117.2960 - val_mae: 7.7197\n",
            "Epoch 419/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 113.7006 - mae: 7.6449 - val_loss: 116.8678 - val_mae: 7.7037\n",
            "Epoch 420/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 113.6077 - mae: 7.6561 - val_loss: 116.9950 - val_mae: 7.7069\n",
            "Epoch 421/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 113.4926 - mae: 7.6505 - val_loss: 116.8751 - val_mae: 7.7028\n",
            "Epoch 422/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 113.8374 - mae: 7.6695 - val_loss: 116.8213 - val_mae: 7.7007\n",
            "Epoch 423/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 113.6177 - mae: 7.6446 - val_loss: 116.8392 - val_mae: 7.7016\n",
            "Epoch 424/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 113.3054 - mae: 7.6351 - val_loss: 117.0083 - val_mae: 7.7079\n",
            "Epoch 425/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 113.6619 - mae: 7.6535 - val_loss: 116.7797 - val_mae: 7.6986\n",
            "Epoch 426/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 113.2881 - mae: 7.6397 - val_loss: 116.5347 - val_mae: 7.6887\n",
            "Epoch 427/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 113.1460 - mae: 7.6278 - val_loss: 116.9102 - val_mae: 7.7035\n",
            "Epoch 428/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 113.3600 - mae: 7.6306 - val_loss: 116.9044 - val_mae: 7.7024\n",
            "Epoch 429/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 113.2053 - mae: 7.6412 - val_loss: 116.7239 - val_mae: 7.6966\n",
            "Epoch 430/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 113.0319 - mae: 7.6326 - val_loss: 116.6798 - val_mae: 7.6936\n",
            "Epoch 431/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 113.2998 - mae: 7.6417 - val_loss: 116.4085 - val_mae: 7.6828\n",
            "Epoch 432/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 113.3273 - mae: 7.6338 - val_loss: 116.5098 - val_mae: 7.6878\n",
            "Epoch 433/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 113.2972 - mae: 7.6311 - val_loss: 116.1835 - val_mae: 7.6733\n",
            "Epoch 434/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 112.8924 - mae: 7.6143 - val_loss: 116.2459 - val_mae: 7.6755\n",
            "Epoch 435/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.9061 - mae: 7.6269 - val_loss: 116.2594 - val_mae: 7.6777\n",
            "Epoch 436/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 112.8089 - mae: 7.6237 - val_loss: 116.5489 - val_mae: 7.6886\n",
            "Epoch 437/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 113.1683 - mae: 7.6260 - val_loss: 116.2111 - val_mae: 7.6756\n",
            "Epoch 438/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 113.0376 - mae: 7.6227 - val_loss: 116.4373 - val_mae: 7.6843\n",
            "Epoch 439/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.8662 - mae: 7.6004 - val_loss: 116.2349 - val_mae: 7.6756\n",
            "Epoch 440/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 112.8946 - mae: 7.6240 - val_loss: 116.3113 - val_mae: 7.6787\n",
            "Epoch 441/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 112.9087 - mae: 7.6191 - val_loss: 116.3252 - val_mae: 7.6778\n",
            "Epoch 442/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 112.9192 - mae: 7.6210 - val_loss: 115.9965 - val_mae: 7.6654\n",
            "Epoch 443/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.6091 - mae: 7.6078 - val_loss: 116.0877 - val_mae: 7.6694\n",
            "Epoch 444/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 112.9851 - mae: 7.6292 - val_loss: 115.9310 - val_mae: 7.6634\n",
            "Epoch 445/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 112.6932 - mae: 7.6082 - val_loss: 115.7092 - val_mae: 7.6541\n",
            "Epoch 446/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.2928 - mae: 7.5922 - val_loss: 115.6270 - val_mae: 7.6504\n",
            "Epoch 447/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 112.5101 - mae: 7.6118 - val_loss: 115.5973 - val_mae: 7.6502\n",
            "Epoch 448/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 112.2421 - mae: 7.5966 - val_loss: 115.4137 - val_mae: 7.6429\n",
            "Epoch 449/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.4017 - mae: 7.6023 - val_loss: 115.6136 - val_mae: 7.6516\n",
            "Epoch 450/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.4275 - mae: 7.6013 - val_loss: 115.8695 - val_mae: 7.6594\n",
            "Epoch 451/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 112.2220 - mae: 7.5973 - val_loss: 115.5902 - val_mae: 7.6481\n",
            "Epoch 452/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 112.2559 - mae: 7.5956 - val_loss: 115.5974 - val_mae: 7.6496\n",
            "Epoch 453/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 112.2387 - mae: 7.5911 - val_loss: 115.4960 - val_mae: 7.6460\n",
            "Epoch 454/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 111.7959 - mae: 7.5817 - val_loss: 115.3941 - val_mae: 7.6411\n",
            "Epoch 455/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.4525 - mae: 7.6038 - val_loss: 115.6956 - val_mae: 7.6536\n",
            "Epoch 456/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 112.0858 - mae: 7.5808 - val_loss: 115.4169 - val_mae: 7.6417\n",
            "Epoch 457/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.2680 - mae: 7.5907 - val_loss: 115.2116 - val_mae: 7.6323\n",
            "Epoch 458/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 112.0598 - mae: 7.5774 - val_loss: 115.0658 - val_mae: 7.6281\n",
            "Epoch 459/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 111.8550 - mae: 7.5754 - val_loss: 115.3834 - val_mae: 7.6408\n",
            "Epoch 460/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 111.9167 - mae: 7.5909 - val_loss: 115.1036 - val_mae: 7.6290\n",
            "Epoch 461/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 111.9698 - mae: 7.5769 - val_loss: 115.3231 - val_mae: 7.6377\n",
            "Epoch 462/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 112.0301 - mae: 7.5900 - val_loss: 114.9082 - val_mae: 7.6219\n",
            "Epoch 463/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 111.8916 - mae: 7.5781 - val_loss: 114.8020 - val_mae: 7.6179\n",
            "Epoch 464/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 111.8504 - mae: 7.5702 - val_loss: 115.1736 - val_mae: 7.6319\n",
            "Epoch 465/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 111.5754 - mae: 7.5652 - val_loss: 114.8353 - val_mae: 7.6192\n",
            "Epoch 466/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 111.9411 - mae: 7.5773 - val_loss: 114.8288 - val_mae: 7.6185\n",
            "Epoch 467/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 111.4396 - mae: 7.5568 - val_loss: 115.0335 - val_mae: 7.6258\n",
            "Epoch 468/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 111.6039 - mae: 7.5722 - val_loss: 115.0101 - val_mae: 7.6252\n",
            "Epoch 469/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 111.4700 - mae: 7.5602 - val_loss: 114.8625 - val_mae: 7.6183\n",
            "Epoch 470/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 111.7378 - mae: 7.5709 - val_loss: 114.7709 - val_mae: 7.6145\n",
            "Epoch 471/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 111.0460 - mae: 7.5508 - val_loss: 114.7440 - val_mae: 7.6129\n",
            "Epoch 472/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 111.3801 - mae: 7.5557 - val_loss: 114.9300 - val_mae: 7.6210\n",
            "Epoch 473/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 111.2711 - mae: 7.5625 - val_loss: 114.3729 - val_mae: 7.5997\n",
            "Epoch 474/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 111.5805 - mae: 7.5668 - val_loss: 114.5466 - val_mae: 7.6064\n",
            "Epoch 475/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 111.3199 - mae: 7.5663 - val_loss: 114.4267 - val_mae: 7.6012\n",
            "Epoch 476/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 111.3059 - mae: 7.5582 - val_loss: 114.4700 - val_mae: 7.6043\n",
            "Epoch 477/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.9256 - mae: 7.5570 - val_loss: 114.2028 - val_mae: 7.5932\n",
            "Epoch 478/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 110.8995 - mae: 7.5373 - val_loss: 114.4819 - val_mae: 7.6038\n",
            "Epoch 479/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 111.2693 - mae: 7.5517 - val_loss: 114.2037 - val_mae: 7.5936\n",
            "Epoch 480/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.9343 - mae: 7.5454 - val_loss: 114.6707 - val_mae: 7.6120\n",
            "Epoch 481/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.8872 - mae: 7.5443 - val_loss: 114.0654 - val_mae: 7.5871\n",
            "Epoch 482/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.9730 - mae: 7.5374 - val_loss: 114.1503 - val_mae: 7.5906\n",
            "Epoch 483/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 111.0210 - mae: 7.5356 - val_loss: 114.8066 - val_mae: 7.6157\n",
            "Epoch 484/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 111.0898 - mae: 7.5391 - val_loss: 113.9273 - val_mae: 7.5823\n",
            "Epoch 485/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 110.8369 - mae: 7.5334 - val_loss: 114.1288 - val_mae: 7.5901\n",
            "Epoch 486/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.8980 - mae: 7.5372 - val_loss: 114.1787 - val_mae: 7.5912\n",
            "Epoch 487/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.7280 - mae: 7.5267 - val_loss: 113.7231 - val_mae: 7.5729\n",
            "Epoch 488/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.9613 - mae: 7.5458 - val_loss: 114.0870 - val_mae: 7.5865\n",
            "Epoch 489/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 110.8017 - mae: 7.5356 - val_loss: 114.1561 - val_mae: 7.5905\n",
            "Epoch 490/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 110.3619 - mae: 7.5175 - val_loss: 113.9446 - val_mae: 7.5819\n",
            "Epoch 491/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 110.6898 - mae: 7.5309 - val_loss: 113.6604 - val_mae: 7.5713\n",
            "Epoch 492/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.8313 - mae: 7.5387 - val_loss: 113.6889 - val_mae: 7.5717\n",
            "Epoch 493/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 110.5947 - mae: 7.5260 - val_loss: 113.8551 - val_mae: 7.5783\n",
            "Epoch 494/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 110.6662 - mae: 7.5285 - val_loss: 113.8361 - val_mae: 7.5776\n",
            "Epoch 495/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 110.6067 - mae: 7.5303 - val_loss: 113.4740 - val_mae: 7.5635\n",
            "Epoch 496/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.4702 - mae: 7.5231 - val_loss: 113.4852 - val_mae: 7.5637\n",
            "Epoch 497/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.5984 - mae: 7.5117 - val_loss: 113.8875 - val_mae: 7.5778\n",
            "Epoch 498/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.3797 - mae: 7.5197 - val_loss: 113.4313 - val_mae: 7.5621\n",
            "Epoch 499/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.6548 - mae: 7.5231 - val_loss: 113.4566 - val_mae: 7.5617\n",
            "Epoch 500/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 110.2110 - mae: 7.5154 - val_loss: 113.7084 - val_mae: 7.5712\n",
            "Epoch 501/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 110.0965 - mae: 7.5052 - val_loss: 113.5280 - val_mae: 7.5642\n",
            "Epoch 502/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 110.3215 - mae: 7.5255 - val_loss: 113.3162 - val_mae: 7.5556\n",
            "Epoch 503/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 110.3374 - mae: 7.5082 - val_loss: 113.3493 - val_mae: 7.5585\n",
            "Epoch 504/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 109.9466 - mae: 7.5094 - val_loss: 113.3945 - val_mae: 7.5589\n",
            "Epoch 505/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 110.0888 - mae: 7.5091 - val_loss: 113.2466 - val_mae: 7.5539\n",
            "Epoch 506/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 109.9059 - mae: 7.4895 - val_loss: 113.3050 - val_mae: 7.5563\n",
            "Epoch 507/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.0576 - mae: 7.5006 - val_loss: 113.4882 - val_mae: 7.5627\n",
            "Epoch 508/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.9574 - mae: 7.4918 - val_loss: 113.0857 - val_mae: 7.5463\n",
            "Epoch 509/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 110.2437 - mae: 7.5113 - val_loss: 112.9973 - val_mae: 7.5443\n",
            "Epoch 510/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.9656 - mae: 7.5194 - val_loss: 113.1716 - val_mae: 7.5499\n",
            "Epoch 511/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 109.8887 - mae: 7.5098 - val_loss: 112.9107 - val_mae: 7.5401\n",
            "Epoch 512/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 110.0649 - mae: 7.5094 - val_loss: 113.0157 - val_mae: 7.5437\n",
            "Epoch 513/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.6555 - mae: 7.4949 - val_loss: 113.0504 - val_mae: 7.5448\n",
            "Epoch 514/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.5513 - mae: 7.4832 - val_loss: 112.8140 - val_mae: 7.5371\n",
            "Epoch 515/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.4769 - mae: 7.4927 - val_loss: 113.0882 - val_mae: 7.5469\n",
            "Epoch 516/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 109.4293 - mae: 7.4815 - val_loss: 113.0666 - val_mae: 7.5454\n",
            "Epoch 517/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 109.5194 - mae: 7.4895 - val_loss: 112.9200 - val_mae: 7.5401\n",
            "Epoch 518/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.3748 - mae: 7.4769 - val_loss: 112.8593 - val_mae: 7.5375\n",
            "Epoch 519/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 109.4485 - mae: 7.4810 - val_loss: 112.9501 - val_mae: 7.5414\n",
            "Epoch 520/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.4822 - mae: 7.4889 - val_loss: 112.7473 - val_mae: 7.5333\n",
            "Epoch 521/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 109.3042 - mae: 7.4695 - val_loss: 113.0247 - val_mae: 7.5433\n",
            "Epoch 522/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 109.4934 - mae: 7.4880 - val_loss: 112.2006 - val_mae: 7.5121\n",
            "Epoch 523/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 109.2863 - mae: 7.4726 - val_loss: 112.4458 - val_mae: 7.5216\n",
            "Epoch 524/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.4575 - mae: 7.4884 - val_loss: 112.8166 - val_mae: 7.5338\n",
            "Epoch 525/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.2593 - mae: 7.4722 - val_loss: 112.6701 - val_mae: 7.5294\n",
            "Epoch 526/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 109.5597 - mae: 7.4890 - val_loss: 112.3016 - val_mae: 7.5166\n",
            "Epoch 527/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.6261 - mae: 7.4763 - val_loss: 112.2734 - val_mae: 7.5149\n",
            "Epoch 528/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 108.8514 - mae: 7.4561 - val_loss: 112.1493 - val_mae: 7.5100\n",
            "Epoch 529/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 109.1142 - mae: 7.4680 - val_loss: 112.1279 - val_mae: 7.5079\n",
            "Epoch 530/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 109.1909 - mae: 7.4731 - val_loss: 112.3819 - val_mae: 7.5184\n",
            "Epoch 531/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.7868 - mae: 7.4597 - val_loss: 112.1993 - val_mae: 7.5123\n",
            "Epoch 532/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.5874 - mae: 7.4441 - val_loss: 112.0226 - val_mae: 7.5055\n",
            "Epoch 533/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 108.7427 - mae: 7.4545 - val_loss: 112.1506 - val_mae: 7.5095\n",
            "Epoch 534/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 108.9353 - mae: 7.4593 - val_loss: 112.0835 - val_mae: 7.5077\n",
            "Epoch 535/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.7706 - mae: 7.4606 - val_loss: 112.0878 - val_mae: 7.5066\n",
            "Epoch 536/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 108.7180 - mae: 7.4483 - val_loss: 112.0622 - val_mae: 7.5065\n",
            "Epoch 537/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.9463 - mae: 7.4828 - val_loss: 112.1757 - val_mae: 7.5092\n",
            "Epoch 538/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.7872 - mae: 7.4652 - val_loss: 111.8957 - val_mae: 7.4998\n",
            "Epoch 539/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 108.8824 - mae: 7.4600 - val_loss: 111.8840 - val_mae: 7.4981\n",
            "Epoch 540/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 108.3141 - mae: 7.4387 - val_loss: 111.6930 - val_mae: 7.4916\n",
            "Epoch 541/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 109.1297 - mae: 7.4601 - val_loss: 111.9060 - val_mae: 7.4992\n",
            "Epoch 542/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.9608 - mae: 7.4573 - val_loss: 112.1637 - val_mae: 7.5085\n",
            "Epoch 543/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.5848 - mae: 7.4557 - val_loss: 111.8668 - val_mae: 7.4986\n",
            "Epoch 544/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 108.7383 - mae: 7.4626 - val_loss: 111.9648 - val_mae: 7.5025\n",
            "Epoch 545/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 108.5905 - mae: 7.4513 - val_loss: 111.6690 - val_mae: 7.4908\n",
            "Epoch 546/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.5727 - mae: 7.4620 - val_loss: 111.6196 - val_mae: 7.4888\n",
            "Epoch 547/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.1881 - mae: 7.4391 - val_loss: 111.7256 - val_mae: 7.4927\n",
            "Epoch 548/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.4914 - mae: 7.4385 - val_loss: 111.5384 - val_mae: 7.4847\n",
            "Epoch 549/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 108.4523 - mae: 7.4374 - val_loss: 111.9166 - val_mae: 7.4980\n",
            "Epoch 550/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 108.0752 - mae: 7.4440 - val_loss: 111.5385 - val_mae: 7.4846\n",
            "Epoch 551/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.2467 - mae: 7.4388 - val_loss: 111.4556 - val_mae: 7.4811\n",
            "Epoch 552/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.1261 - mae: 7.4274 - val_loss: 111.1454 - val_mae: 7.4713\n",
            "Epoch 553/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 108.0098 - mae: 7.4423 - val_loss: 111.4485 - val_mae: 7.4816\n",
            "Epoch 554/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.2278 - mae: 7.4334 - val_loss: 111.3932 - val_mae: 7.4797\n",
            "Epoch 555/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 107.7950 - mae: 7.4237 - val_loss: 111.4376 - val_mae: 7.4808\n",
            "Epoch 556/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 107.7986 - mae: 7.4098 - val_loss: 111.4888 - val_mae: 7.4818\n",
            "Epoch 557/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 108.3535 - mae: 7.4352 - val_loss: 111.0064 - val_mae: 7.4648\n",
            "Epoch 558/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.9396 - mae: 7.4256 - val_loss: 110.9883 - val_mae: 7.4635\n",
            "Epoch 559/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.6807 - mae: 7.4162 - val_loss: 111.4533 - val_mae: 7.4803\n",
            "Epoch 560/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 107.8497 - mae: 7.4207 - val_loss: 111.1367 - val_mae: 7.4693\n",
            "Epoch 561/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 107.8066 - mae: 7.4148 - val_loss: 111.1229 - val_mae: 7.4696\n",
            "Epoch 562/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.8722 - mae: 7.4189 - val_loss: 110.6226 - val_mae: 7.4511\n",
            "Epoch 563/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.8230 - mae: 7.4217 - val_loss: 110.5365 - val_mae: 7.4465\n",
            "Epoch 564/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.8770 - mae: 7.4161 - val_loss: 110.8223 - val_mae: 7.4565\n",
            "Epoch 565/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 107.4187 - mae: 7.4003 - val_loss: 110.8022 - val_mae: 7.4558\n",
            "Epoch 566/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 107.4840 - mae: 7.4121 - val_loss: 110.5194 - val_mae: 7.4468\n",
            "Epoch 567/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 107.6243 - mae: 7.4135 - val_loss: 110.9399 - val_mae: 7.4604\n",
            "Epoch 568/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.4975 - mae: 7.4145 - val_loss: 110.4578 - val_mae: 7.4442\n",
            "Epoch 569/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.7834 - mae: 7.4129 - val_loss: 110.5060 - val_mae: 7.4458\n",
            "Epoch 570/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.9209 - mae: 7.4089 - val_loss: 110.4653 - val_mae: 7.4429\n",
            "Epoch 571/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 107.6230 - mae: 7.4095 - val_loss: 110.7452 - val_mae: 7.4535\n",
            "Epoch 572/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 107.2708 - mae: 7.3957 - val_loss: 110.6533 - val_mae: 7.4499\n",
            "Epoch 573/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.4277 - mae: 7.3999 - val_loss: 110.5259 - val_mae: 7.4465\n",
            "Epoch 574/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.3640 - mae: 7.4079 - val_loss: 110.5592 - val_mae: 7.4455\n",
            "Epoch 575/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.4768 - mae: 7.4032 - val_loss: 110.4667 - val_mae: 7.4438\n",
            "Epoch 576/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 107.3984 - mae: 7.3940 - val_loss: 110.7788 - val_mae: 7.4538\n",
            "Epoch 577/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 107.1525 - mae: 7.3856 - val_loss: 110.2530 - val_mae: 7.4341\n",
            "Epoch 578/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.9964 - mae: 7.3705 - val_loss: 110.5166 - val_mae: 7.4437\n",
            "Epoch 579/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.5472 - mae: 7.4132 - val_loss: 110.4759 - val_mae: 7.4418\n",
            "Epoch 580/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.9808 - mae: 7.3871 - val_loss: 110.2552 - val_mae: 7.4340\n",
            "Epoch 581/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 107.0261 - mae: 7.3821 - val_loss: 110.4835 - val_mae: 7.4436\n",
            "Epoch 582/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 107.3253 - mae: 7.4037 - val_loss: 109.9660 - val_mae: 7.4246\n",
            "Epoch 583/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 107.0419 - mae: 7.3991 - val_loss: 110.1272 - val_mae: 7.4301\n",
            "Epoch 584/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 106.9084 - mae: 7.3824 - val_loss: 109.9488 - val_mae: 7.4222\n",
            "Epoch 585/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.3499 - mae: 7.3951 - val_loss: 110.1209 - val_mae: 7.4280\n",
            "Epoch 586/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.1412 - mae: 7.3986 - val_loss: 110.0637 - val_mae: 7.4262\n",
            "Epoch 587/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.1611 - mae: 7.3893 - val_loss: 109.8172 - val_mae: 7.4173\n",
            "Epoch 588/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 107.1384 - mae: 7.4003 - val_loss: 109.8252 - val_mae: 7.4183\n",
            "Epoch 589/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 106.6599 - mae: 7.3752 - val_loss: 110.0239 - val_mae: 7.4246\n",
            "Epoch 590/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 107.0873 - mae: 7.3941 - val_loss: 109.9788 - val_mae: 7.4233\n",
            "Epoch 591/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.5777 - mae: 7.3813 - val_loss: 109.7432 - val_mae: 7.4143\n",
            "Epoch 592/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.3964 - mae: 7.3764 - val_loss: 109.8217 - val_mae: 7.4182\n",
            "Epoch 593/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 106.6849 - mae: 7.3593 - val_loss: 109.8299 - val_mae: 7.4178\n",
            "Epoch 594/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 106.4546 - mae: 7.3735 - val_loss: 109.8464 - val_mae: 7.4181\n",
            "Epoch 595/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.6941 - mae: 7.3743 - val_loss: 109.6306 - val_mae: 7.4110\n",
            "Epoch 596/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.5682 - mae: 7.3703 - val_loss: 109.4322 - val_mae: 7.4032\n",
            "Epoch 597/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.7870 - mae: 7.3808 - val_loss: 109.4949 - val_mae: 7.4064\n",
            "Epoch 598/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.1120 - mae: 7.3523 - val_loss: 109.5769 - val_mae: 7.4079\n",
            "Epoch 599/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 106.6685 - mae: 7.3607 - val_loss: 109.2154 - val_mae: 7.3957\n",
            "Epoch 600/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 106.6964 - mae: 7.3742 - val_loss: 109.5581 - val_mae: 7.4070\n",
            "Epoch 601/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.2636 - mae: 7.3546 - val_loss: 109.1950 - val_mae: 7.3951\n",
            "Epoch 602/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.2476 - mae: 7.3531 - val_loss: 109.4583 - val_mae: 7.4043\n",
            "Epoch 603/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.3932 - mae: 7.3626 - val_loss: 109.3446 - val_mae: 7.4014\n",
            "Epoch 604/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 105.9101 - mae: 7.3571 - val_loss: 109.2687 - val_mae: 7.3957\n",
            "Epoch 605/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 106.2296 - mae: 7.3547 - val_loss: 109.5791 - val_mae: 7.4081\n",
            "Epoch 606/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.3323 - mae: 7.3579 - val_loss: 108.9849 - val_mae: 7.3872\n",
            "Epoch 607/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.2725 - mae: 7.3639 - val_loss: 109.1790 - val_mae: 7.3937\n",
            "Epoch 608/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.0317 - mae: 7.3492 - val_loss: 109.2963 - val_mae: 7.3981\n",
            "Epoch 609/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 106.1312 - mae: 7.3531 - val_loss: 109.0582 - val_mae: 7.3880\n",
            "Epoch 610/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 105.8386 - mae: 7.3373 - val_loss: 109.0241 - val_mae: 7.3868\n",
            "Epoch 611/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 106.1243 - mae: 7.3510 - val_loss: 109.1266 - val_mae: 7.3914\n",
            "Epoch 612/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.3280 - mae: 7.3615 - val_loss: 108.8839 - val_mae: 7.3809\n",
            "Epoch 613/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.9333 - mae: 7.3448 - val_loss: 109.1029 - val_mae: 7.3908\n",
            "Epoch 614/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.2046 - mae: 7.3550 - val_loss: 108.8510 - val_mae: 7.3805\n",
            "Epoch 615/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 106.0451 - mae: 7.3468 - val_loss: 109.1563 - val_mae: 7.3913\n",
            "Epoch 616/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 105.6502 - mae: 7.3522 - val_loss: 108.7926 - val_mae: 7.3777\n",
            "Epoch 617/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.7941 - mae: 7.3371 - val_loss: 108.9171 - val_mae: 7.3815\n",
            "Epoch 618/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.4496 - mae: 7.3290 - val_loss: 108.7151 - val_mae: 7.3744\n",
            "Epoch 619/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 106.1679 - mae: 7.3574 - val_loss: 108.4372 - val_mae: 7.3653\n",
            "Epoch 620/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.6211 - mae: 7.3423 - val_loss: 108.7602 - val_mae: 7.3762\n",
            "Epoch 621/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 105.6924 - mae: 7.3444 - val_loss: 108.8053 - val_mae: 7.3781\n",
            "Epoch 622/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.2787 - mae: 7.3270 - val_loss: 108.5815 - val_mae: 7.3703\n",
            "Epoch 623/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.5739 - mae: 7.3274 - val_loss: 108.3701 - val_mae: 7.3630\n",
            "Epoch 624/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.8358 - mae: 7.3433 - val_loss: 108.5173 - val_mae: 7.3670\n",
            "Epoch 625/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.2058 - mae: 7.3182 - val_loss: 108.6505 - val_mae: 7.3727\n",
            "Epoch 626/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 105.5355 - mae: 7.3410 - val_loss: 108.5374 - val_mae: 7.3685\n",
            "Epoch 627/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 105.2897 - mae: 7.3265 - val_loss: 108.2175 - val_mae: 7.3558\n",
            "Epoch 628/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.2922 - mae: 7.3225 - val_loss: 108.2698 - val_mae: 7.3590\n",
            "Epoch 629/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.5199 - mae: 7.3279 - val_loss: 108.3292 - val_mae: 7.3607\n",
            "Epoch 630/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 105.1993 - mae: 7.3299 - val_loss: 107.9992 - val_mae: 7.3489\n",
            "Epoch 631/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 105.7050 - mae: 7.3160 - val_loss: 108.2333 - val_mae: 7.3559\n",
            "Epoch 632/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 105.0570 - mae: 7.3269 - val_loss: 108.2984 - val_mae: 7.3583\n",
            "Epoch 633/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.2623 - mae: 7.3199 - val_loss: 108.3174 - val_mae: 7.3595\n",
            "Epoch 634/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 105.1140 - mae: 7.3111 - val_loss: 108.2287 - val_mae: 7.3565\n",
            "Epoch 635/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 105.2125 - mae: 7.3111 - val_loss: 108.4347 - val_mae: 7.3634\n",
            "Epoch 636/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 105.0677 - mae: 7.3134 - val_loss: 108.1741 - val_mae: 7.3534\n",
            "Epoch 637/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 105.1054 - mae: 7.3133 - val_loss: 108.1691 - val_mae: 7.3537\n",
            "Epoch 638/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 104.9148 - mae: 7.3070 - val_loss: 108.0504 - val_mae: 7.3501\n",
            "Epoch 639/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.9621 - mae: 7.3171 - val_loss: 107.9266 - val_mae: 7.3443\n",
            "Epoch 640/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.7279 - mae: 7.3128 - val_loss: 107.9488 - val_mae: 7.3460\n",
            "Epoch 641/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.9559 - mae: 7.3133 - val_loss: 107.9924 - val_mae: 7.3474\n",
            "Epoch 642/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 104.6623 - mae: 7.3006 - val_loss: 107.7719 - val_mae: 7.3389\n",
            "Epoch 643/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 104.6853 - mae: 7.3063 - val_loss: 108.0453 - val_mae: 7.3473\n",
            "Epoch 644/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 104.5857 - mae: 7.3004 - val_loss: 107.8143 - val_mae: 7.3395\n",
            "Epoch 645/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.8587 - mae: 7.3208 - val_loss: 107.9301 - val_mae: 7.3438\n",
            "Epoch 646/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.7928 - mae: 7.3091 - val_loss: 107.8976 - val_mae: 7.3436\n",
            "Epoch 647/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.7722 - mae: 7.2998 - val_loss: 108.0082 - val_mae: 7.3462\n",
            "Epoch 648/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 104.4181 - mae: 7.2916 - val_loss: 107.9328 - val_mae: 7.3444\n",
            "Epoch 649/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 104.1736 - mae: 7.2841 - val_loss: 107.5996 - val_mae: 7.3328\n",
            "Epoch 650/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.7228 - mae: 7.3017 - val_loss: 107.7126 - val_mae: 7.3353\n",
            "Epoch 651/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.2517 - mae: 7.2771 - val_loss: 107.7710 - val_mae: 7.3380\n",
            "Epoch 652/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.2958 - mae: 7.2943 - val_loss: 107.4711 - val_mae: 7.3264\n",
            "Epoch 653/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 104.5475 - mae: 7.3022 - val_loss: 107.4874 - val_mae: 7.3280\n",
            "Epoch 654/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 104.1852 - mae: 7.2908 - val_loss: 107.5914 - val_mae: 7.3319\n",
            "Epoch 655/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 104.3535 - mae: 7.2891 - val_loss: 107.3972 - val_mae: 7.3246\n",
            "Epoch 656/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.4454 - mae: 7.2985 - val_loss: 107.1518 - val_mae: 7.3144\n",
            "Epoch 657/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.2129 - mae: 7.2744 - val_loss: 107.5066 - val_mae: 7.3283\n",
            "Epoch 658/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.0513 - mae: 7.2889 - val_loss: 107.5172 - val_mae: 7.3271\n",
            "Epoch 659/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 104.4300 - mae: 7.2982 - val_loss: 107.2590 - val_mae: 7.3190\n",
            "Epoch 660/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 104.1284 - mae: 7.2812 - val_loss: 107.2128 - val_mae: 7.3168\n",
            "Epoch 661/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.3495 - mae: 7.2851 - val_loss: 107.2108 - val_mae: 7.3179\n",
            "Epoch 662/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.2120 - mae: 7.2898 - val_loss: 106.9555 - val_mae: 7.3094\n",
            "Epoch 663/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.0841 - mae: 7.2770 - val_loss: 107.1708 - val_mae: 7.3157\n",
            "Epoch 664/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 103.9156 - mae: 7.2671 - val_loss: 106.9033 - val_mae: 7.3074\n",
            "Epoch 665/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 104.5435 - mae: 7.3029 - val_loss: 107.3300 - val_mae: 7.3203\n",
            "Epoch 666/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 104.2231 - mae: 7.2843 - val_loss: 107.0135 - val_mae: 7.3112\n",
            "Epoch 667/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.0398 - mae: 7.2791 - val_loss: 107.1483 - val_mae: 7.3148\n",
            "Epoch 668/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.8007 - mae: 7.2605 - val_loss: 107.0763 - val_mae: 7.3105\n",
            "Epoch 669/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 103.9321 - mae: 7.2634 - val_loss: 107.0011 - val_mae: 7.3084\n",
            "Epoch 670/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 103.5900 - mae: 7.2546 - val_loss: 107.0978 - val_mae: 7.3138\n",
            "Epoch 671/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 104.3157 - mae: 7.2760 - val_loss: 107.1391 - val_mae: 7.3139\n",
            "Epoch 672/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 104.0020 - mae: 7.2738 - val_loss: 106.6768 - val_mae: 7.2974\n",
            "Epoch 673/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.8328 - mae: 7.2707 - val_loss: 106.8641 - val_mae: 7.3040\n",
            "Epoch 674/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.8121 - mae: 7.2894 - val_loss: 106.4837 - val_mae: 7.2917\n",
            "Epoch 675/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.3027 - mae: 7.2532 - val_loss: 106.7453 - val_mae: 7.2998\n",
            "Epoch 676/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 103.7364 - mae: 7.2669 - val_loss: 106.7177 - val_mae: 7.2989\n",
            "Epoch 677/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 103.3841 - mae: 7.2580 - val_loss: 106.6674 - val_mae: 7.2957\n",
            "Epoch 678/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.7031 - mae: 7.2658 - val_loss: 106.7195 - val_mae: 7.2979\n",
            "Epoch 679/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.8429 - mae: 7.2667 - val_loss: 106.2720 - val_mae: 7.2820\n",
            "Epoch 680/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.2672 - mae: 7.2397 - val_loss: 106.3599 - val_mae: 7.2855\n",
            "Epoch 681/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 103.5000 - mae: 7.2574 - val_loss: 106.8792 - val_mae: 7.3030\n",
            "Epoch 682/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 103.3225 - mae: 7.2478 - val_loss: 106.2690 - val_mae: 7.2821\n",
            "Epoch 683/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 103.4065 - mae: 7.2559 - val_loss: 106.3090 - val_mae: 7.2836\n",
            "Epoch 684/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 103.3359 - mae: 7.2434 - val_loss: 106.2055 - val_mae: 7.2797\n",
            "Epoch 685/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.1958 - mae: 7.2448 - val_loss: 106.3040 - val_mae: 7.2827\n",
            "Epoch 686/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.7345 - mae: 7.2424 - val_loss: 105.9761 - val_mae: 7.2719\n",
            "Epoch 687/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 103.2096 - mae: 7.2366 - val_loss: 106.4835 - val_mae: 7.2883\n",
            "Epoch 688/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 103.3721 - mae: 7.2527 - val_loss: 106.2257 - val_mae: 7.2819\n",
            "Epoch 689/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.7722 - mae: 7.2346 - val_loss: 106.0274 - val_mae: 7.2736\n",
            "Epoch 690/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.1734 - mae: 7.2511 - val_loss: 106.2342 - val_mae: 7.2808\n",
            "Epoch 691/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.1031 - mae: 7.2473 - val_loss: 105.9794 - val_mae: 7.2702\n",
            "Epoch 692/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 103.0027 - mae: 7.2297 - val_loss: 106.1423 - val_mae: 7.2772\n",
            "Epoch 693/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 103.1240 - mae: 7.2375 - val_loss: 105.7316 - val_mae: 7.2627\n",
            "Epoch 694/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 103.0268 - mae: 7.2564 - val_loss: 105.8853 - val_mae: 7.2679\n",
            "Epoch 695/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.8097 - mae: 7.2245 - val_loss: 105.9314 - val_mae: 7.2690\n",
            "Epoch 696/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 103.2068 - mae: 7.2504 - val_loss: 105.9061 - val_mae: 7.2695\n",
            "Epoch 697/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 103.0279 - mae: 7.2292 - val_loss: 105.8633 - val_mae: 7.2659\n",
            "Epoch 698/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 102.8055 - mae: 7.2280 - val_loss: 106.0039 - val_mae: 7.2711\n",
            "Epoch 699/10000\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 102.6440 - mae: 7.2230 - val_loss: 106.1994 - val_mae: 7.2789\n",
            "Epoch 700/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 102.9210 - mae: 7.2351 - val_loss: 105.7910 - val_mae: 7.2643\n",
            "Epoch 701/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.5540 - mae: 7.2153 - val_loss: 106.0046 - val_mae: 7.2725\n",
            "Epoch 702/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.8442 - mae: 7.2275 - val_loss: 105.7681 - val_mae: 7.2622\n",
            "Epoch 703/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 102.5674 - mae: 7.2155 - val_loss: 105.8653 - val_mae: 7.2667\n",
            "Epoch 704/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 102.1658 - mae: 7.2087 - val_loss: 105.5460 - val_mae: 7.2555\n",
            "Epoch 705/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 102.5250 - mae: 7.2133 - val_loss: 105.6643 - val_mae: 7.2591\n",
            "Epoch 706/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 103.0547 - mae: 7.2360 - val_loss: 105.6358 - val_mae: 7.2592\n",
            "Epoch 707/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 102.3475 - mae: 7.2148 - val_loss: 105.7495 - val_mae: 7.2618\n",
            "Epoch 708/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.5872 - mae: 7.2231 - val_loss: 105.2062 - val_mae: 7.2437\n",
            "Epoch 709/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 102.5980 - mae: 7.2129 - val_loss: 105.2422 - val_mae: 7.2453\n",
            "Epoch 710/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 102.3384 - mae: 7.2080 - val_loss: 105.3464 - val_mae: 7.2486\n",
            "Epoch 711/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 102.5579 - mae: 7.2127 - val_loss: 105.5589 - val_mae: 7.2541\n",
            "Epoch 712/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 102.1013 - mae: 7.2031 - val_loss: 105.5924 - val_mae: 7.2568\n",
            "Epoch 713/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.2648 - mae: 7.2032 - val_loss: 105.3793 - val_mae: 7.2491\n",
            "Epoch 714/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.4446 - mae: 7.2110 - val_loss: 105.4273 - val_mae: 7.2515\n",
            "Epoch 715/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 102.4295 - mae: 7.2178 - val_loss: 105.4747 - val_mae: 7.2500\n",
            "Epoch 716/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 102.7370 - mae: 7.2201 - val_loss: 105.2228 - val_mae: 7.2432\n",
            "Epoch 717/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 101.9822 - mae: 7.1995 - val_loss: 105.0256 - val_mae: 7.2362\n",
            "Epoch 718/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.4154 - mae: 7.2112 - val_loss: 104.9107 - val_mae: 7.2331\n",
            "Epoch 719/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 102.2020 - mae: 7.2022 - val_loss: 105.2083 - val_mae: 7.2427\n",
            "Epoch 720/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.8259 - mae: 7.1870 - val_loss: 105.2288 - val_mae: 7.2432\n",
            "Epoch 721/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 102.1886 - mae: 7.2024 - val_loss: 105.2539 - val_mae: 7.2443\n",
            "Epoch 722/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 102.4723 - mae: 7.2283 - val_loss: 105.0528 - val_mae: 7.2369\n",
            "Epoch 723/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 102.1823 - mae: 7.1997 - val_loss: 104.7819 - val_mae: 7.2275\n",
            "Epoch 724/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 101.9666 - mae: 7.2003 - val_loss: 104.9390 - val_mae: 7.2330\n",
            "Epoch 725/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.8808 - mae: 7.2057 - val_loss: 105.0001 - val_mae: 7.2356\n",
            "Epoch 726/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 102.0759 - mae: 7.2093 - val_loss: 105.0881 - val_mae: 7.2373\n",
            "Epoch 727/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 101.9802 - mae: 7.2075 - val_loss: 105.1034 - val_mae: 7.2377\n",
            "Epoch 728/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 102.0082 - mae: 7.1967 - val_loss: 104.9398 - val_mae: 7.2320\n",
            "Epoch 729/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 101.7995 - mae: 7.1910 - val_loss: 104.9488 - val_mae: 7.2324\n",
            "Epoch 730/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.6908 - mae: 7.1863 - val_loss: 104.8433 - val_mae: 7.2293\n",
            "Epoch 731/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 101.6627 - mae: 7.1921 - val_loss: 104.6016 - val_mae: 7.2210\n",
            "Epoch 732/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 101.8052 - mae: 7.1948 - val_loss: 104.5101 - val_mae: 7.2181\n",
            "Epoch 733/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 101.5677 - mae: 7.1765 - val_loss: 104.7277 - val_mae: 7.2248\n",
            "Epoch 734/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.4292 - mae: 7.1773 - val_loss: 104.7209 - val_mae: 7.2255\n",
            "Epoch 735/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.3841 - mae: 7.1838 - val_loss: 104.4267 - val_mae: 7.2150\n",
            "Epoch 736/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 101.6982 - mae: 7.1943 - val_loss: 104.8747 - val_mae: 7.2311\n",
            "Epoch 737/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.2389 - mae: 7.1773 - val_loss: 104.5555 - val_mae: 7.2186\n",
            "Epoch 738/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 101.3843 - mae: 7.1750 - val_loss: 104.2415 - val_mae: 7.2082\n",
            "Epoch 739/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 101.1788 - mae: 7.1857 - val_loss: 104.4587 - val_mae: 7.2164\n",
            "Epoch 740/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 101.1162 - mae: 7.1639 - val_loss: 104.3462 - val_mae: 7.2110\n",
            "Epoch 741/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.1295 - mae: 7.1587 - val_loss: 104.4854 - val_mae: 7.2163\n",
            "Epoch 742/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.2622 - mae: 7.1759 - val_loss: 104.3503 - val_mae: 7.2136\n",
            "Epoch 743/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 101.8145 - mae: 7.1951 - val_loss: 104.1731 - val_mae: 7.2064\n",
            "Epoch 744/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 101.6938 - mae: 7.1804 - val_loss: 104.3647 - val_mae: 7.2116\n",
            "Epoch 745/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.5269 - mae: 7.2023 - val_loss: 104.4645 - val_mae: 7.2146\n",
            "Epoch 746/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.5686 - mae: 7.1644 - val_loss: 104.0853 - val_mae: 7.2025\n",
            "Epoch 747/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 101.3587 - mae: 7.1734 - val_loss: 103.9543 - val_mae: 7.1983\n",
            "Epoch 748/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.0255 - mae: 7.1669 - val_loss: 104.1019 - val_mae: 7.2028\n",
            "Epoch 749/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 101.0806 - mae: 7.1636 - val_loss: 103.9162 - val_mae: 7.1959\n",
            "Epoch 750/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 101.4870 - mae: 7.1827 - val_loss: 103.8589 - val_mae: 7.1954\n",
            "Epoch 751/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 100.5954 - mae: 7.1410 - val_loss: 103.9513 - val_mae: 7.1962\n",
            "Epoch 752/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.3357 - mae: 7.1795 - val_loss: 104.2239 - val_mae: 7.2059\n",
            "Epoch 753/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.9703 - mae: 7.1548 - val_loss: 103.8673 - val_mae: 7.1954\n",
            "Epoch 754/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.5282 - mae: 7.1475 - val_loss: 103.8196 - val_mae: 7.1921\n",
            "Epoch 755/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 101.0656 - mae: 7.1668 - val_loss: 104.1782 - val_mae: 7.2038\n",
            "Epoch 756/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 100.7586 - mae: 7.1535 - val_loss: 103.8253 - val_mae: 7.1935\n",
            "Epoch 757/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 101.1536 - mae: 7.1772 - val_loss: 104.0077 - val_mae: 7.1986\n",
            "Epoch 758/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.7430 - mae: 7.1496 - val_loss: 103.6781 - val_mae: 7.1880\n",
            "Epoch 759/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.5467 - mae: 7.1379 - val_loss: 103.7548 - val_mae: 7.1904\n",
            "Epoch 760/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 100.7756 - mae: 7.1480 - val_loss: 103.8653 - val_mae: 7.1930\n",
            "Epoch 761/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 100.7784 - mae: 7.1436 - val_loss: 103.9601 - val_mae: 7.1957\n",
            "Epoch 762/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 100.4871 - mae: 7.1465 - val_loss: 103.8066 - val_mae: 7.1912\n",
            "Epoch 763/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.7335 - mae: 7.1539 - val_loss: 103.5011 - val_mae: 7.1808\n",
            "Epoch 764/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.3050 - mae: 7.1396 - val_loss: 103.5674 - val_mae: 7.1848\n",
            "Epoch 765/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.8731 - mae: 7.1553 - val_loss: 103.3457 - val_mae: 7.1772\n",
            "Epoch 766/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 100.5312 - mae: 7.1548 - val_loss: 103.5861 - val_mae: 7.1848\n",
            "Epoch 767/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 100.5286 - mae: 7.1455 - val_loss: 103.5204 - val_mae: 7.1817\n",
            "Epoch 768/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.5580 - mae: 7.1375 - val_loss: 103.5183 - val_mae: 7.1818\n",
            "Epoch 769/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.2914 - mae: 7.1391 - val_loss: 103.4417 - val_mae: 7.1803\n",
            "Epoch 770/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.1807 - mae: 7.1209 - val_loss: 103.3636 - val_mae: 7.1758\n",
            "Epoch 771/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 100.5275 - mae: 7.1323 - val_loss: 103.6211 - val_mae: 7.1840\n",
            "Epoch 772/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 100.3027 - mae: 7.1465 - val_loss: 103.3789 - val_mae: 7.1758\n",
            "Epoch 773/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 100.0429 - mae: 7.1299 - val_loss: 103.3851 - val_mae: 7.1772\n",
            "Epoch 774/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 100.4798 - mae: 7.1504 - val_loss: 103.4561 - val_mae: 7.1805\n",
            "Epoch 775/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.7503 - mae: 7.1475 - val_loss: 102.9350 - val_mae: 7.1619\n",
            "Epoch 776/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.5896 - mae: 7.1471 - val_loss: 103.4569 - val_mae: 7.1787\n",
            "Epoch 777/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 99.8653 - mae: 7.1229 - val_loss: 103.3473 - val_mae: 7.1745\n",
            "Epoch 778/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 99.8613 - mae: 7.1291 - val_loss: 103.1157 - val_mae: 7.1668\n",
            "Epoch 779/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.3511 - mae: 7.1390 - val_loss: 103.2842 - val_mae: 7.1735\n",
            "Epoch 780/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 99.8857 - mae: 7.1195 - val_loss: 103.2838 - val_mae: 7.1734\n",
            "Epoch 781/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.2816 - mae: 7.1424 - val_loss: 102.7359 - val_mae: 7.1560\n",
            "Epoch 782/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.4514 - mae: 7.1514 - val_loss: 103.1948 - val_mae: 7.1703\n",
            "Epoch 783/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 100.0168 - mae: 7.1228 - val_loss: 103.2013 - val_mae: 7.1711\n",
            "Epoch 784/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 100.3230 - mae: 7.1351 - val_loss: 102.8844 - val_mae: 7.1602\n",
            "Epoch 785/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 100.1892 - mae: 7.1295 - val_loss: 102.9126 - val_mae: 7.1605\n",
            "Epoch 786/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 99.8286 - mae: 7.1050 - val_loss: 102.6862 - val_mae: 7.1536\n",
            "Epoch 787/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.4928 - mae: 7.1121 - val_loss: 102.9166 - val_mae: 7.1607\n",
            "Epoch 788/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 99.6854 - mae: 7.1184 - val_loss: 102.4662 - val_mae: 7.1467\n",
            "Epoch 789/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 99.9155 - mae: 7.1254 - val_loss: 102.7917 - val_mae: 7.1556\n",
            "Epoch 790/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.9903 - mae: 7.1365 - val_loss: 102.6644 - val_mae: 7.1516\n",
            "Epoch 791/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.6136 - mae: 7.1215 - val_loss: 102.5664 - val_mae: 7.1489\n",
            "Epoch 792/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 99.4126 - mae: 7.1035 - val_loss: 102.6702 - val_mae: 7.1515\n",
            "Epoch 793/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 100.0636 - mae: 7.1119 - val_loss: 102.7109 - val_mae: 7.1544\n",
            "Epoch 794/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 100.3070 - mae: 7.1285 - val_loss: 102.3798 - val_mae: 7.1439\n",
            "Epoch 795/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 99.8337 - mae: 7.1206 - val_loss: 102.6223 - val_mae: 7.1507\n",
            "Epoch 796/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.4508 - mae: 7.1079 - val_loss: 102.6088 - val_mae: 7.1505\n",
            "Epoch 797/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 99.8190 - mae: 7.1200 - val_loss: 102.5448 - val_mae: 7.1477\n",
            "Epoch 798/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.4770 - mae: 7.0996 - val_loss: 102.3541 - val_mae: 7.1419\n",
            "Epoch 799/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.3572 - mae: 7.0964 - val_loss: 102.2806 - val_mae: 7.1381\n",
            "Epoch 800/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 99.3570 - mae: 7.1186 - val_loss: 102.5699 - val_mae: 7.1487\n",
            "Epoch 801/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 99.4753 - mae: 7.1124 - val_loss: 102.2814 - val_mae: 7.1398\n",
            "Epoch 802/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.3949 - mae: 7.1150 - val_loss: 102.5805 - val_mae: 7.1481\n",
            "Epoch 803/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.2445 - mae: 7.0903 - val_loss: 102.2546 - val_mae: 7.1372\n",
            "Epoch 804/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.5552 - mae: 7.1141 - val_loss: 102.2602 - val_mae: 7.1378\n",
            "Epoch 805/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.4517 - mae: 7.1089 - val_loss: 102.1924 - val_mae: 7.1353\n",
            "Epoch 806/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 99.4928 - mae: 7.1074 - val_loss: 102.2022 - val_mae: 7.1358\n",
            "Epoch 807/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 99.4145 - mae: 7.1120 - val_loss: 102.3328 - val_mae: 7.1404\n",
            "Epoch 808/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.3281 - mae: 7.1062 - val_loss: 102.2113 - val_mae: 7.1355\n",
            "Epoch 809/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 99.2263 - mae: 7.0987 - val_loss: 101.9681 - val_mae: 7.1274\n",
            "Epoch 810/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.5122 - mae: 7.1123 - val_loss: 101.9574 - val_mae: 7.1281\n",
            "Epoch 811/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 99.1680 - mae: 7.0973 - val_loss: 102.1281 - val_mae: 7.1330\n",
            "Epoch 812/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 99.1168 - mae: 7.1064 - val_loss: 101.9536 - val_mae: 7.1269\n",
            "Epoch 813/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 98.8158 - mae: 7.0903 - val_loss: 101.6950 - val_mae: 7.1199\n",
            "Epoch 814/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 98.9228 - mae: 7.0900 - val_loss: 102.1250 - val_mae: 7.1314\n",
            "Epoch 815/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 99.2283 - mae: 7.0974 - val_loss: 102.1273 - val_mae: 7.1331\n",
            "Epoch 816/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 99.0767 - mae: 7.0908 - val_loss: 101.8471 - val_mae: 7.1244\n",
            "Epoch 817/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 98.8876 - mae: 7.0853 - val_loss: 101.9217 - val_mae: 7.1281\n",
            "Epoch 818/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 99.2263 - mae: 7.0896 - val_loss: 101.7251 - val_mae: 7.1200\n",
            "Epoch 819/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.9243 - mae: 7.0817 - val_loss: 101.5819 - val_mae: 7.1153\n",
            "Epoch 820/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.8709 - mae: 7.0874 - val_loss: 101.7749 - val_mae: 7.1212\n",
            "Epoch 821/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 99.2189 - mae: 7.0917 - val_loss: 101.5270 - val_mae: 7.1119\n",
            "Epoch 822/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 98.9582 - mae: 7.0943 - val_loss: 101.9482 - val_mae: 7.1277\n",
            "Epoch 823/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.4987 - mae: 7.0741 - val_loss: 101.6613 - val_mae: 7.1174\n",
            "Epoch 824/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.7553 - mae: 7.0937 - val_loss: 101.6952 - val_mae: 7.1182\n",
            "Epoch 825/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.8381 - mae: 7.0839 - val_loss: 101.6928 - val_mae: 7.1181\n",
            "Epoch 826/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 98.5162 - mae: 7.0748 - val_loss: 101.4791 - val_mae: 7.1110\n",
            "Epoch 827/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 98.6588 - mae: 7.0799 - val_loss: 101.3620 - val_mae: 7.1082\n",
            "Epoch 828/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.3708 - mae: 7.0682 - val_loss: 101.3875 - val_mae: 7.1088\n",
            "Epoch 829/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.5570 - mae: 7.0799 - val_loss: 101.5669 - val_mae: 7.1142\n",
            "Epoch 830/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 98.5902 - mae: 7.0656 - val_loss: 101.4072 - val_mae: 7.1094\n",
            "Epoch 831/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 98.4795 - mae: 7.0817 - val_loss: 101.6532 - val_mae: 7.1157\n",
            "Epoch 832/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 98.5647 - mae: 7.0803 - val_loss: 101.1695 - val_mae: 7.1010\n",
            "Epoch 833/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 98.2355 - mae: 7.0798 - val_loss: 101.3590 - val_mae: 7.1075\n",
            "Epoch 834/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.1317 - mae: 7.0731 - val_loss: 101.6102 - val_mae: 7.1153\n",
            "Epoch 835/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.7155 - mae: 7.1024 - val_loss: 101.3686 - val_mae: 7.1075\n",
            "Epoch 836/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 98.4971 - mae: 7.0772 - val_loss: 101.2609 - val_mae: 7.1027\n",
            "Epoch 837/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 98.0399 - mae: 7.0595 - val_loss: 101.0948 - val_mae: 7.0974\n",
            "Epoch 838/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 97.8478 - mae: 7.0608 - val_loss: 101.1466 - val_mae: 7.1005\n",
            "Epoch 839/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 98.3622 - mae: 7.0796 - val_loss: 101.1416 - val_mae: 7.1000\n",
            "Epoch 840/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.3344 - mae: 7.0612 - val_loss: 101.1290 - val_mae: 7.0986\n",
            "Epoch 841/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 98.3305 - mae: 7.0727 - val_loss: 101.1084 - val_mae: 7.0990\n",
            "Epoch 842/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.1012 - mae: 7.0605 - val_loss: 101.0849 - val_mae: 7.0964\n",
            "Epoch 843/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 98.2627 - mae: 7.0584 - val_loss: 101.1139 - val_mae: 7.0990\n",
            "Epoch 844/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 98.2660 - mae: 7.0622 - val_loss: 101.0531 - val_mae: 7.0981\n",
            "Epoch 845/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.1993 - mae: 7.0626 - val_loss: 100.9286 - val_mae: 7.0925\n",
            "Epoch 846/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.7233 - mae: 7.0526 - val_loss: 100.8381 - val_mae: 7.0899\n",
            "Epoch 847/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.3785 - mae: 7.0640 - val_loss: 100.8471 - val_mae: 7.0900\n",
            "Epoch 848/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.3065 - mae: 7.0694 - val_loss: 100.7886 - val_mae: 7.0881\n",
            "Epoch 849/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 98.1922 - mae: 7.0544 - val_loss: 100.6572 - val_mae: 7.0826\n",
            "Epoch 850/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 98.1988 - mae: 7.0551 - val_loss: 100.6267 - val_mae: 7.0817\n",
            "Epoch 851/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 98.2109 - mae: 7.0682 - val_loss: 100.7955 - val_mae: 7.0874\n",
            "Epoch 852/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.7483 - mae: 7.0587 - val_loss: 100.5896 - val_mae: 7.0821\n",
            "Epoch 853/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.7230 - mae: 7.0468 - val_loss: 100.7454 - val_mae: 7.0861\n",
            "Epoch 854/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 98.2801 - mae: 7.0684 - val_loss: 100.7307 - val_mae: 7.0870\n",
            "Epoch 855/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 97.4370 - mae: 7.0280 - val_loss: 100.6026 - val_mae: 7.0811\n",
            "Epoch 856/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.6837 - mae: 7.0452 - val_loss: 100.8684 - val_mae: 7.0887\n",
            "Epoch 857/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.3521 - mae: 7.0229 - val_loss: 100.3978 - val_mae: 7.0760\n",
            "Epoch 858/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.4388 - mae: 7.0334 - val_loss: 100.7124 - val_mae: 7.0855\n",
            "Epoch 859/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.4200 - mae: 7.0316 - val_loss: 100.6457 - val_mae: 7.0826\n",
            "Epoch 860/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 97.4211 - mae: 7.0358 - val_loss: 100.1947 - val_mae: 7.0693\n",
            "Epoch 861/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 97.3943 - mae: 7.0283 - val_loss: 100.4444 - val_mae: 7.0759\n",
            "Epoch 862/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 97.4822 - mae: 7.0311 - val_loss: 100.6900 - val_mae: 7.0831\n",
            "Epoch 863/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 97.5402 - mae: 7.0404 - val_loss: 100.5349 - val_mae: 7.0796\n",
            "Epoch 864/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 97.1767 - mae: 7.0321 - val_loss: 100.3624 - val_mae: 7.0733\n",
            "Epoch 865/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 97.7215 - mae: 7.0302 - val_loss: 100.3298 - val_mae: 7.0726\n",
            "Epoch 866/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 97.5097 - mae: 7.0304 - val_loss: 100.2107 - val_mae: 7.0691\n",
            "Epoch 867/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.2929 - mae: 7.0220 - val_loss: 100.1320 - val_mae: 7.0654\n",
            "Epoch 868/10000\n",
            "500/500 [==============================] - 3s 5ms/step - loss: 97.5573 - mae: 7.0434 - val_loss: 100.1677 - val_mae: 7.0668\n",
            "Epoch 869/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.6688 - mae: 7.0500 - val_loss: 100.1675 - val_mae: 7.0690\n",
            "Epoch 870/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.9988 - mae: 7.0279 - val_loss: 100.1439 - val_mae: 7.0656\n",
            "Epoch 871/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 97.5031 - mae: 7.0507 - val_loss: 100.2049 - val_mae: 7.0683\n",
            "Epoch 872/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.1287 - mae: 7.0307 - val_loss: 100.0922 - val_mae: 7.0640\n",
            "Epoch 873/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.2626 - mae: 7.0389 - val_loss: 100.1046 - val_mae: 7.0650\n",
            "Epoch 874/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.9166 - mae: 7.0191 - val_loss: 99.8445 - val_mae: 7.0572\n",
            "Epoch 875/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 96.8796 - mae: 7.0280 - val_loss: 99.8382 - val_mae: 7.0555\n",
            "Epoch 876/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 97.1833 - mae: 7.0449 - val_loss: 99.8791 - val_mae: 7.0572\n",
            "Epoch 877/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 97.3934 - mae: 7.0334 - val_loss: 99.9323 - val_mae: 7.0595\n",
            "Epoch 878/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.8725 - mae: 7.0287 - val_loss: 100.1002 - val_mae: 7.0634\n",
            "Epoch 879/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.4722 - mae: 7.0395 - val_loss: 99.8635 - val_mae: 7.0567\n",
            "Epoch 880/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.8375 - mae: 7.0189 - val_loss: 99.8683 - val_mae: 7.0570\n",
            "Epoch 881/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.5287 - mae: 7.0099 - val_loss: 100.0659 - val_mae: 7.0629\n",
            "Epoch 882/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 97.3791 - mae: 7.0341 - val_loss: 99.8279 - val_mae: 7.0555\n",
            "Epoch 883/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.7149 - mae: 7.0187 - val_loss: 99.6772 - val_mae: 7.0504\n",
            "Epoch 884/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.4723 - mae: 7.0492 - val_loss: 99.8920 - val_mae: 7.0574\n",
            "Epoch 885/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 97.1044 - mae: 7.0164 - val_loss: 99.5630 - val_mae: 7.0468\n",
            "Epoch 886/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.7746 - mae: 7.0189 - val_loss: 99.8025 - val_mae: 7.0536\n",
            "Epoch 887/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.6532 - mae: 7.0007 - val_loss: 99.6687 - val_mae: 7.0485\n",
            "Epoch 888/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.9062 - mae: 7.0254 - val_loss: 99.7691 - val_mae: 7.0529\n",
            "Epoch 889/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.5416 - mae: 7.0011 - val_loss: 99.6626 - val_mae: 7.0504\n",
            "Epoch 890/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.8451 - mae: 7.0251 - val_loss: 99.6222 - val_mae: 7.0477\n",
            "Epoch 891/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.9500 - mae: 7.0199 - val_loss: 99.6241 - val_mae: 7.0485\n",
            "Epoch 892/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 96.9140 - mae: 7.0162 - val_loss: 99.5496 - val_mae: 7.0453\n",
            "Epoch 893/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 96.3988 - mae: 6.9973 - val_loss: 99.1985 - val_mae: 7.0364\n",
            "Epoch 894/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 96.5798 - mae: 7.0130 - val_loss: 99.5039 - val_mae: 7.0458\n",
            "Epoch 895/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.5303 - mae: 7.0083 - val_loss: 99.5326 - val_mae: 7.0452\n",
            "Epoch 896/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.2258 - mae: 6.9951 - val_loss: 99.1139 - val_mae: 7.0332\n",
            "Epoch 897/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.6954 - mae: 7.0143 - val_loss: 99.5406 - val_mae: 7.0456\n",
            "Epoch 898/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.2475 - mae: 7.0042 - val_loss: 99.1999 - val_mae: 7.0357\n",
            "Epoch 899/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 96.5246 - mae: 7.0162 - val_loss: 99.2013 - val_mae: 7.0351\n",
            "Epoch 900/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 96.4814 - mae: 7.0075 - val_loss: 99.2987 - val_mae: 7.0379\n",
            "Epoch 901/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.4449 - mae: 7.0049 - val_loss: 99.3935 - val_mae: 7.0402\n",
            "Epoch 902/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.2208 - mae: 6.9971 - val_loss: 98.9406 - val_mae: 7.0278\n",
            "Epoch 903/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.6894 - mae: 7.0057 - val_loss: 99.2346 - val_mae: 7.0362\n",
            "Epoch 904/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 96.3170 - mae: 7.0118 - val_loss: 99.0297 - val_mae: 7.0287\n",
            "Epoch 905/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 96.2196 - mae: 7.0040 - val_loss: 99.0952 - val_mae: 7.0316\n",
            "Epoch 906/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.9571 - mae: 6.9820 - val_loss: 98.9554 - val_mae: 7.0274\n",
            "Epoch 907/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.2275 - mae: 6.9856 - val_loss: 98.9863 - val_mae: 7.0282\n",
            "Epoch 908/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.2407 - mae: 7.0067 - val_loss: 99.1281 - val_mae: 7.0317\n",
            "Epoch 909/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 96.0975 - mae: 6.9966 - val_loss: 99.1918 - val_mae: 7.0342\n",
            "Epoch 910/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.7899 - mae: 6.9864 - val_loss: 99.0270 - val_mae: 7.0284\n",
            "Epoch 911/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 96.3962 - mae: 7.0048 - val_loss: 98.8857 - val_mae: 7.0248\n",
            "Epoch 912/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.2296 - mae: 6.9867 - val_loss: 98.9777 - val_mae: 7.0279\n",
            "Epoch 913/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.7660 - mae: 6.9827 - val_loss: 99.1857 - val_mae: 7.0320\n",
            "Epoch 914/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.8422 - mae: 6.9930 - val_loss: 98.6621 - val_mae: 7.0195\n",
            "Epoch 915/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.3241 - mae: 7.0003 - val_loss: 98.7423 - val_mae: 7.0203\n",
            "Epoch 916/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.9830 - mae: 6.9857 - val_loss: 99.0170 - val_mae: 7.0278\n",
            "Epoch 917/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 96.3505 - mae: 7.0042 - val_loss: 98.8862 - val_mae: 7.0246\n",
            "Epoch 918/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.0115 - mae: 6.9919 - val_loss: 98.8052 - val_mae: 7.0224\n",
            "Epoch 919/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.1521 - mae: 6.9916 - val_loss: 98.6353 - val_mae: 7.0185\n",
            "Epoch 920/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 95.7715 - mae: 6.9870 - val_loss: 98.3897 - val_mae: 7.0101\n",
            "Epoch 921/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.1312 - mae: 6.9811 - val_loss: 98.6566 - val_mae: 7.0182\n",
            "Epoch 922/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 96.0032 - mae: 6.9812 - val_loss: 98.8258 - val_mae: 7.0224\n",
            "Epoch 923/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 96.0093 - mae: 6.9906 - val_loss: 98.3845 - val_mae: 7.0090\n",
            "Epoch 924/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.8811 - mae: 6.9876 - val_loss: 98.4947 - val_mae: 7.0132\n",
            "Epoch 925/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.7711 - mae: 6.9713 - val_loss: 98.6097 - val_mae: 7.0156\n",
            "Epoch 926/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.1052 - mae: 6.9889 - val_loss: 98.6461 - val_mae: 7.0168\n",
            "Epoch 927/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.8867 - mae: 6.9714 - val_loss: 98.6950 - val_mae: 7.0176\n",
            "Epoch 928/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.0859 - mae: 6.9937 - val_loss: 98.5032 - val_mae: 7.0115\n",
            "Epoch 929/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.3423 - mae: 6.9678 - val_loss: 98.5039 - val_mae: 7.0115\n",
            "Epoch 930/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.9878 - mae: 7.0016 - val_loss: 98.2033 - val_mae: 7.0045\n",
            "Epoch 931/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.5170 - mae: 6.9670 - val_loss: 98.5097 - val_mae: 7.0117\n",
            "Epoch 932/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.4726 - mae: 6.9659 - val_loss: 98.2894 - val_mae: 7.0056\n",
            "Epoch 933/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 96.0123 - mae: 6.9906 - val_loss: 98.2139 - val_mae: 7.0028\n",
            "Epoch 934/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.0474 - mae: 6.9612 - val_loss: 98.0793 - val_mae: 6.9994\n",
            "Epoch 935/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.5612 - mae: 6.9746 - val_loss: 98.4031 - val_mae: 7.0081\n",
            "Epoch 936/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.1076 - mae: 6.9496 - val_loss: 98.1396 - val_mae: 7.0009\n",
            "Epoch 937/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 95.4122 - mae: 6.9664 - val_loss: 98.3362 - val_mae: 7.0057\n",
            "Epoch 938/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.4415 - mae: 6.9658 - val_loss: 98.4749 - val_mae: 7.0105\n",
            "Epoch 939/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 95.1490 - mae: 6.9575 - val_loss: 97.7533 - val_mae: 6.9893\n",
            "Epoch 940/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.5476 - mae: 6.9775 - val_loss: 97.8092 - val_mae: 6.9913\n",
            "Epoch 941/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.6476 - mae: 6.9844 - val_loss: 98.2487 - val_mae: 7.0029\n",
            "Epoch 942/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.0770 - mae: 6.9498 - val_loss: 98.0076 - val_mae: 6.9978\n",
            "Epoch 943/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 94.7376 - mae: 6.9355 - val_loss: 97.8599 - val_mae: 6.9914\n",
            "Epoch 944/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.0787 - mae: 6.9707 - val_loss: 98.1429 - val_mae: 7.0000\n",
            "Epoch 945/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 95.0808 - mae: 6.9536 - val_loss: 97.7655 - val_mae: 6.9898\n",
            "Epoch 946/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.0573 - mae: 6.9483 - val_loss: 97.8651 - val_mae: 6.9929\n",
            "Epoch 947/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.6069 - mae: 6.9960 - val_loss: 97.7688 - val_mae: 6.9896\n",
            "Epoch 948/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 95.3464 - mae: 6.9645 - val_loss: 97.8124 - val_mae: 6.9899\n",
            "Epoch 949/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.0769 - mae: 6.9524 - val_loss: 97.9872 - val_mae: 6.9940\n",
            "Epoch 950/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 95.0536 - mae: 6.9581 - val_loss: 97.7749 - val_mae: 6.9888\n",
            "Epoch 951/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.3065 - mae: 6.9726 - val_loss: 98.1829 - val_mae: 6.9998\n",
            "Epoch 952/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.1245 - mae: 6.9570 - val_loss: 97.6770 - val_mae: 6.9871\n",
            "Epoch 953/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.6329 - mae: 6.9474 - val_loss: 97.5644 - val_mae: 6.9830\n",
            "Epoch 954/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 95.0971 - mae: 6.9520 - val_loss: 97.4730 - val_mae: 6.9792\n",
            "Epoch 955/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 94.9877 - mae: 6.9608 - val_loss: 97.3898 - val_mae: 6.9778\n",
            "Epoch 956/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 94.6042 - mae: 6.9535 - val_loss: 97.6715 - val_mae: 6.9860\n",
            "Epoch 957/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.0628 - mae: 6.9491 - val_loss: 97.6193 - val_mae: 6.9835\n",
            "Epoch 958/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.6200 - mae: 6.9481 - val_loss: 97.4817 - val_mae: 6.9806\n",
            "Epoch 959/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.7288 - mae: 6.9423 - val_loss: 97.4008 - val_mae: 6.9786\n",
            "Epoch 960/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 95.0216 - mae: 6.9606 - val_loss: 97.5666 - val_mae: 6.9822\n",
            "Epoch 961/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 94.8627 - mae: 6.9647 - val_loss: 97.3302 - val_mae: 6.9759\n",
            "Epoch 962/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 94.9237 - mae: 6.9567 - val_loss: 97.6390 - val_mae: 6.9827\n",
            "Epoch 963/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.3349 - mae: 6.9429 - val_loss: 97.1929 - val_mae: 6.9715\n",
            "Epoch 964/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 95.1102 - mae: 6.9672 - val_loss: 97.5063 - val_mae: 6.9811\n",
            "Epoch 965/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 94.5522 - mae: 6.9431 - val_loss: 97.4682 - val_mae: 6.9784\n",
            "Epoch 966/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 95.0847 - mae: 6.9638 - val_loss: 97.3590 - val_mae: 6.9770\n",
            "Epoch 967/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 94.7793 - mae: 6.9557 - val_loss: 97.4818 - val_mae: 6.9798\n",
            "Epoch 968/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.6650 - mae: 6.9375 - val_loss: 97.3392 - val_mae: 6.9763\n",
            "Epoch 969/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.3825 - mae: 6.9316 - val_loss: 97.0558 - val_mae: 6.9670\n",
            "Epoch 970/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.7082 - mae: 6.9453 - val_loss: 97.3403 - val_mae: 6.9744\n",
            "Epoch 971/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 94.6027 - mae: 6.9523 - val_loss: 97.0017 - val_mae: 6.9657\n",
            "Epoch 972/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 94.2056 - mae: 6.9162 - val_loss: 97.3378 - val_mae: 6.9752\n",
            "Epoch 973/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 94.4112 - mae: 6.9366 - val_loss: 97.0868 - val_mae: 6.9693\n",
            "Epoch 974/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 94.7624 - mae: 6.9637 - val_loss: 97.1254 - val_mae: 6.9691\n",
            "Epoch 975/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 94.5433 - mae: 6.9482 - val_loss: 97.0499 - val_mae: 6.9669\n",
            "Epoch 976/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.5278 - mae: 6.9354 - val_loss: 97.0445 - val_mae: 6.9657\n",
            "Epoch 977/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 94.2165 - mae: 6.9265 - val_loss: 96.7976 - val_mae: 6.9599\n",
            "Epoch 978/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 94.3171 - mae: 6.9317 - val_loss: 97.2402 - val_mae: 6.9709\n",
            "Epoch 979/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.9687 - mae: 6.9254 - val_loss: 96.8623 - val_mae: 6.9620\n",
            "Epoch 980/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.1109 - mae: 6.9255 - val_loss: 96.8595 - val_mae: 6.9611\n",
            "Epoch 981/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.3840 - mae: 6.9278 - val_loss: 96.7052 - val_mae: 6.9576\n",
            "Epoch 982/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 94.1694 - mae: 6.9371 - val_loss: 96.7679 - val_mae: 6.9584\n",
            "Epoch 983/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 94.0643 - mae: 6.9137 - val_loss: 97.2202 - val_mae: 6.9706\n",
            "Epoch 984/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 94.2672 - mae: 6.9297 - val_loss: 96.8749 - val_mae: 6.9616\n",
            "Epoch 985/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.2056 - mae: 6.9338 - val_loss: 96.8461 - val_mae: 6.9597\n",
            "Epoch 986/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.9418 - mae: 6.9302 - val_loss: 96.7432 - val_mae: 6.9582\n",
            "Epoch 987/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.0538 - mae: 6.9272 - val_loss: 96.7013 - val_mae: 6.9571\n",
            "Epoch 988/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.9074 - mae: 6.9116 - val_loss: 96.6444 - val_mae: 6.9545\n",
            "Epoch 989/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 93.9415 - mae: 6.9301 - val_loss: 96.6411 - val_mae: 6.9543\n",
            "Epoch 990/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 94.0699 - mae: 6.9303 - val_loss: 96.8147 - val_mae: 6.9579\n",
            "Epoch 991/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.9220 - mae: 6.9263 - val_loss: 96.6796 - val_mae: 6.9562\n",
            "Epoch 992/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.0644 - mae: 6.9256 - val_loss: 96.6356 - val_mae: 6.9538\n",
            "Epoch 993/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 94.1866 - mae: 6.9249 - val_loss: 96.5404 - val_mae: 6.9513\n",
            "Epoch 994/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.8532 - mae: 6.9178 - val_loss: 96.3064 - val_mae: 6.9438\n",
            "Epoch 995/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.9488 - mae: 6.9220 - val_loss: 96.5476 - val_mae: 6.9502\n",
            "Epoch 996/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.8692 - mae: 6.9190 - val_loss: 96.6019 - val_mae: 6.9530\n",
            "Epoch 997/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.6811 - mae: 6.9073 - val_loss: 96.2340 - val_mae: 6.9421\n",
            "Epoch 998/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.4099 - mae: 6.9138 - val_loss: 96.4897 - val_mae: 6.9485\n",
            "Epoch 999/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 93.7824 - mae: 6.9085 - val_loss: 96.3805 - val_mae: 6.9464\n",
            "Epoch 1000/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 93.3989 - mae: 6.8953 - val_loss: 96.9217 - val_mae: 6.9605\n",
            "Epoch 1001/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 94.1478 - mae: 6.9246 - val_loss: 96.6074 - val_mae: 6.9515\n",
            "Epoch 1002/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.4331 - mae: 6.9092 - val_loss: 96.1952 - val_mae: 6.9402\n",
            "Epoch 1003/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.5535 - mae: 6.9035 - val_loss: 96.1346 - val_mae: 6.9388\n",
            "Epoch 1004/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.6677 - mae: 6.9160 - val_loss: 96.1354 - val_mae: 6.9388\n",
            "Epoch 1005/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.6979 - mae: 6.9223 - val_loss: 96.2013 - val_mae: 6.9416\n",
            "Epoch 1006/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.9719 - mae: 6.8969 - val_loss: 96.2395 - val_mae: 6.9423\n",
            "Epoch 1007/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 93.2698 - mae: 6.9063 - val_loss: 96.0037 - val_mae: 6.9349\n",
            "Epoch 1008/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.7819 - mae: 6.9210 - val_loss: 96.3191 - val_mae: 6.9441\n",
            "Epoch 1009/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.5675 - mae: 6.9073 - val_loss: 95.9672 - val_mae: 6.9334\n",
            "Epoch 1010/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.6973 - mae: 6.9119 - val_loss: 96.1791 - val_mae: 6.9399\n",
            "Epoch 1011/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.5184 - mae: 6.9179 - val_loss: 95.9726 - val_mae: 6.9352\n",
            "Epoch 1012/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 93.0994 - mae: 6.9017 - val_loss: 96.0583 - val_mae: 6.9372\n",
            "Epoch 1013/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.0040 - mae: 6.8899 - val_loss: 96.2357 - val_mae: 6.9412\n",
            "Epoch 1014/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.1891 - mae: 6.8975 - val_loss: 95.8224 - val_mae: 6.9286\n",
            "Epoch 1015/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.1994 - mae: 6.9070 - val_loss: 96.0376 - val_mae: 6.9364\n",
            "Epoch 1016/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 93.5774 - mae: 6.9103 - val_loss: 96.0363 - val_mae: 6.9332\n",
            "Epoch 1017/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 93.3289 - mae: 6.9145 - val_loss: 96.1099 - val_mae: 6.9370\n",
            "Epoch 1018/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.1513 - mae: 6.8983 - val_loss: 96.0508 - val_mae: 6.9357\n",
            "Epoch 1019/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.4965 - mae: 6.9216 - val_loss: 95.7383 - val_mae: 6.9270\n",
            "Epoch 1020/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.3209 - mae: 6.9081 - val_loss: 95.7389 - val_mae: 6.9271\n",
            "Epoch 1021/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.4184 - mae: 6.9050 - val_loss: 95.9620 - val_mae: 6.9311\n",
            "Epoch 1022/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 93.0819 - mae: 6.8877 - val_loss: 95.9401 - val_mae: 6.9322\n",
            "Epoch 1023/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.3128 - mae: 6.9039 - val_loss: 95.7164 - val_mae: 6.9272\n",
            "Epoch 1024/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.9677 - mae: 6.8761 - val_loss: 95.8689 - val_mae: 6.9301\n",
            "Epoch 1025/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.4446 - mae: 6.9076 - val_loss: 95.7427 - val_mae: 6.9270\n",
            "Epoch 1026/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.5035 - mae: 6.9143 - val_loss: 95.6173 - val_mae: 6.9235\n",
            "Epoch 1027/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.1755 - mae: 6.9103 - val_loss: 95.9009 - val_mae: 6.9301\n",
            "Epoch 1028/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.0960 - mae: 6.8981 - val_loss: 95.4955 - val_mae: 6.9193\n",
            "Epoch 1029/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.1067 - mae: 6.8958 - val_loss: 95.4150 - val_mae: 6.9171\n",
            "Epoch 1030/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 93.0942 - mae: 6.8928 - val_loss: 95.5353 - val_mae: 6.9202\n",
            "Epoch 1031/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.4279 - mae: 6.8839 - val_loss: 95.4635 - val_mae: 6.9191\n",
            "Epoch 1032/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.9967 - mae: 6.9012 - val_loss: 95.8241 - val_mae: 6.9267\n",
            "Epoch 1033/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 93.1428 - mae: 6.9018 - val_loss: 95.4005 - val_mae: 6.9164\n",
            "Epoch 1034/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 92.9481 - mae: 6.8935 - val_loss: 95.5871 - val_mae: 6.9231\n",
            "Epoch 1035/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 93.0008 - mae: 6.9027 - val_loss: 95.7089 - val_mae: 6.9243\n",
            "Epoch 1036/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.4041 - mae: 6.8836 - val_loss: 95.6647 - val_mae: 6.9223\n",
            "Epoch 1037/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.6776 - mae: 6.8792 - val_loss: 95.7057 - val_mae: 6.9225\n",
            "Epoch 1038/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.6425 - mae: 6.8855 - val_loss: 95.4186 - val_mae: 6.9163\n",
            "Epoch 1039/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.6833 - mae: 6.8945 - val_loss: 95.1328 - val_mae: 6.9088\n",
            "Epoch 1040/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.7679 - mae: 6.8878 - val_loss: 95.4879 - val_mae: 6.9181\n",
            "Epoch 1041/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.9536 - mae: 6.8911 - val_loss: 95.1701 - val_mae: 6.9090\n",
            "Epoch 1042/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 92.7150 - mae: 6.9001 - val_loss: 95.3452 - val_mae: 6.9153\n",
            "Epoch 1043/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.5535 - mae: 6.8794 - val_loss: 95.1926 - val_mae: 6.9095\n",
            "Epoch 1044/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 92.6111 - mae: 6.8769 - val_loss: 94.9979 - val_mae: 6.9050\n",
            "Epoch 1045/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.5935 - mae: 6.8795 - val_loss: 95.0184 - val_mae: 6.9042\n",
            "Epoch 1046/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 92.3390 - mae: 6.8742 - val_loss: 95.0141 - val_mae: 6.9038\n",
            "Epoch 1047/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.3801 - mae: 6.8726 - val_loss: 95.0316 - val_mae: 6.9050\n",
            "Epoch 1048/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.3051 - mae: 6.8661 - val_loss: 95.0271 - val_mae: 6.9054\n",
            "Epoch 1049/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.4355 - mae: 6.8591 - val_loss: 95.2203 - val_mae: 6.9105\n",
            "Epoch 1050/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.2769 - mae: 6.8757 - val_loss: 95.0467 - val_mae: 6.9049\n",
            "Epoch 1051/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.5408 - mae: 6.8702 - val_loss: 94.8606 - val_mae: 6.9014\n",
            "Epoch 1052/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.2713 - mae: 6.8700 - val_loss: 95.1876 - val_mae: 6.9098\n",
            "Epoch 1053/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.4094 - mae: 6.8788 - val_loss: 94.7278 - val_mae: 6.8961\n",
            "Epoch 1054/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.3786 - mae: 6.8734 - val_loss: 94.7990 - val_mae: 6.8990\n",
            "Epoch 1055/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 92.1334 - mae: 6.8630 - val_loss: 95.1010 - val_mae: 6.9061\n",
            "Epoch 1056/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.6292 - mae: 6.8899 - val_loss: 94.9212 - val_mae: 6.9016\n",
            "Epoch 1057/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 91.9652 - mae: 6.8619 - val_loss: 94.7310 - val_mae: 6.8959\n",
            "Epoch 1058/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.9426 - mae: 6.8581 - val_loss: 94.7078 - val_mae: 6.8958\n",
            "Epoch 1059/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.0699 - mae: 6.8512 - val_loss: 95.1815 - val_mae: 6.9085\n",
            "Epoch 1060/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.1155 - mae: 6.8477 - val_loss: 95.1133 - val_mae: 6.9041\n",
            "Epoch 1061/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 92.5128 - mae: 6.8722 - val_loss: 94.8974 - val_mae: 6.9013\n",
            "Epoch 1062/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 92.3587 - mae: 6.8702 - val_loss: 94.8349 - val_mae: 6.8991\n",
            "Epoch 1063/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 92.0847 - mae: 6.8588 - val_loss: 94.5453 - val_mae: 6.8907\n",
            "Epoch 1064/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.8221 - mae: 6.8539 - val_loss: 94.6392 - val_mae: 6.8923\n",
            "Epoch 1065/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.4509 - mae: 6.8833 - val_loss: 94.7749 - val_mae: 6.8968\n",
            "Epoch 1066/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.7635 - mae: 6.8564 - val_loss: 94.6415 - val_mae: 6.8920\n",
            "Epoch 1067/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 91.8380 - mae: 6.8641 - val_loss: 94.4958 - val_mae: 6.8888\n",
            "Epoch 1068/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 91.7121 - mae: 6.8482 - val_loss: 94.6825 - val_mae: 6.8938\n",
            "Epoch 1069/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 91.8293 - mae: 6.8496 - val_loss: 94.7291 - val_mae: 6.8952\n",
            "Epoch 1070/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.9494 - mae: 6.8639 - val_loss: 94.4919 - val_mae: 6.8903\n",
            "Epoch 1071/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.0694 - mae: 6.8544 - val_loss: 94.5779 - val_mae: 6.8924\n",
            "Epoch 1072/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.7327 - mae: 6.8425 - val_loss: 94.5997 - val_mae: 6.8901\n",
            "Epoch 1073/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.0292 - mae: 6.8525 - val_loss: 94.4613 - val_mae: 6.8893\n",
            "Epoch 1074/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 92.0253 - mae: 6.8605 - val_loss: 94.2919 - val_mae: 6.8842\n",
            "Epoch 1075/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.7086 - mae: 6.8497 - val_loss: 94.6370 - val_mae: 6.8917\n",
            "Epoch 1076/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 92.1299 - mae: 6.8674 - val_loss: 94.7147 - val_mae: 6.8939\n",
            "Epoch 1077/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.4640 - mae: 6.8516 - val_loss: 94.2934 - val_mae: 6.8837\n",
            "Epoch 1078/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 91.5535 - mae: 6.8354 - val_loss: 94.3306 - val_mae: 6.8845\n",
            "Epoch 1079/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 91.6704 - mae: 6.8460 - val_loss: 94.1627 - val_mae: 6.8797\n",
            "Epoch 1080/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 91.7378 - mae: 6.8525 - val_loss: 94.2669 - val_mae: 6.8821\n",
            "Epoch 1081/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.7840 - mae: 6.8452 - val_loss: 94.2634 - val_mae: 6.8830\n",
            "Epoch 1082/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.7514 - mae: 6.8525 - val_loss: 94.3779 - val_mae: 6.8850\n",
            "Epoch 1083/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 91.6987 - mae: 6.8500 - val_loss: 94.0164 - val_mae: 6.8761\n",
            "Epoch 1084/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 91.4047 - mae: 6.8586 - val_loss: 94.1214 - val_mae: 6.8776\n",
            "Epoch 1085/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 91.7680 - mae: 6.8617 - val_loss: 93.9622 - val_mae: 6.8744\n",
            "Epoch 1086/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 91.9737 - mae: 6.8652 - val_loss: 94.3837 - val_mae: 6.8836\n",
            "Epoch 1087/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 91.4726 - mae: 6.8534 - val_loss: 94.0978 - val_mae: 6.8759\n",
            "Epoch 1088/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.5694 - mae: 6.8456 - val_loss: 94.3543 - val_mae: 6.8849\n",
            "Epoch 1089/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.5018 - mae: 6.8480 - val_loss: 93.9919 - val_mae: 6.8746\n",
            "Epoch 1090/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 91.4580 - mae: 6.8440 - val_loss: 93.9488 - val_mae: 6.8741\n",
            "Epoch 1091/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 91.7832 - mae: 6.8389 - val_loss: 93.9851 - val_mae: 6.8729\n",
            "Epoch 1092/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 91.0798 - mae: 6.8260 - val_loss: 93.9527 - val_mae: 6.8720\n",
            "Epoch 1093/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.3049 - mae: 6.8542 - val_loss: 94.2481 - val_mae: 6.8805\n",
            "Epoch 1094/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.4589 - mae: 6.8532 - val_loss: 93.9632 - val_mae: 6.8733\n",
            "Epoch 1095/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.3057 - mae: 6.8398 - val_loss: 93.9287 - val_mae: 6.8710\n",
            "Epoch 1096/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 91.1775 - mae: 6.8226 - val_loss: 93.8874 - val_mae: 6.8723\n",
            "Epoch 1097/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 90.9021 - mae: 6.8272 - val_loss: 93.8472 - val_mae: 6.8689\n",
            "Epoch 1098/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 91.0826 - mae: 6.8347 - val_loss: 93.6885 - val_mae: 6.8664\n",
            "Epoch 1099/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.2511 - mae: 6.8466 - val_loss: 93.8746 - val_mae: 6.8700\n",
            "Epoch 1100/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.4061 - mae: 6.8509 - val_loss: 93.9695 - val_mae: 6.8737\n",
            "Epoch 1101/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 91.1887 - mae: 6.8271 - val_loss: 93.6449 - val_mae: 6.8654\n",
            "Epoch 1102/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.7250 - mae: 6.8156 - val_loss: 93.7002 - val_mae: 6.8666\n",
            "Epoch 1103/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 91.3175 - mae: 6.8432 - val_loss: 93.7819 - val_mae: 6.8657\n",
            "Epoch 1104/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 91.2675 - mae: 6.8478 - val_loss: 93.6439 - val_mae: 6.8646\n",
            "Epoch 1105/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.1399 - mae: 6.8307 - val_loss: 93.6790 - val_mae: 6.8649\n",
            "Epoch 1106/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.9058 - mae: 6.8316 - val_loss: 93.8816 - val_mae: 6.8699\n",
            "Epoch 1107/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.8455 - mae: 6.8173 - val_loss: 93.6989 - val_mae: 6.8650\n",
            "Epoch 1108/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 90.7411 - mae: 6.8205 - val_loss: 93.5327 - val_mae: 6.8621\n",
            "Epoch 1109/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 90.6128 - mae: 6.8164 - val_loss: 93.3296 - val_mae: 6.8549\n",
            "Epoch 1110/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.9565 - mae: 6.8309 - val_loss: 93.5936 - val_mae: 6.8624\n",
            "Epoch 1111/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.8804 - mae: 6.8250 - val_loss: 93.7766 - val_mae: 6.8667\n",
            "Epoch 1112/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 90.7687 - mae: 6.8219 - val_loss: 93.7848 - val_mae: 6.8675\n",
            "Epoch 1113/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.9575 - mae: 6.8298 - val_loss: 93.5101 - val_mae: 6.8610\n",
            "Epoch 1114/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.4911 - mae: 6.8103 - val_loss: 93.4889 - val_mae: 6.8595\n",
            "Epoch 1115/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.7499 - mae: 6.8232 - val_loss: 93.5895 - val_mae: 6.8618\n",
            "Epoch 1116/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.3409 - mae: 6.8444 - val_loss: 93.4389 - val_mae: 6.8574\n",
            "Epoch 1117/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.8837 - mae: 6.8300 - val_loss: 93.6177 - val_mae: 6.8593\n",
            "Epoch 1118/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.6068 - mae: 6.8241 - val_loss: 93.2843 - val_mae: 6.8539\n",
            "Epoch 1119/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.6893 - mae: 6.8174 - val_loss: 93.5747 - val_mae: 6.8620\n",
            "Epoch 1120/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 91.0208 - mae: 6.8258 - val_loss: 93.4459 - val_mae: 6.8577\n",
            "Epoch 1121/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.8995 - mae: 6.8260 - val_loss: 93.4099 - val_mae: 6.8574\n",
            "Epoch 1122/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.7073 - mae: 6.8214 - val_loss: 93.2180 - val_mae: 6.8522\n",
            "Epoch 1123/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.9021 - mae: 6.8212 - val_loss: 93.1322 - val_mae: 6.8494\n",
            "Epoch 1124/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.8849 - mae: 6.8265 - val_loss: 93.0655 - val_mae: 6.8490\n",
            "Epoch 1125/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.6774 - mae: 6.8313 - val_loss: 93.2356 - val_mae: 6.8520\n",
            "Epoch 1126/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.3767 - mae: 6.8180 - val_loss: 92.8733 - val_mae: 6.8432\n",
            "Epoch 1127/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 91.1181 - mae: 6.8409 - val_loss: 93.2272 - val_mae: 6.8529\n",
            "Epoch 1128/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.4707 - mae: 6.8217 - val_loss: 93.0462 - val_mae: 6.8487\n",
            "Epoch 1129/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.6089 - mae: 6.8235 - val_loss: 93.0330 - val_mae: 6.8464\n",
            "Epoch 1130/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.7891 - mae: 6.8294 - val_loss: 93.1944 - val_mae: 6.8500\n",
            "Epoch 1131/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.6332 - mae: 6.8149 - val_loss: 93.0678 - val_mae: 6.8470\n",
            "Epoch 1132/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.4906 - mae: 6.8149 - val_loss: 93.2944 - val_mae: 6.8523\n",
            "Epoch 1133/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.8435 - mae: 6.8285 - val_loss: 92.9884 - val_mae: 6.8464\n",
            "Epoch 1134/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.7524 - mae: 6.8306 - val_loss: 93.1062 - val_mae: 6.8480\n",
            "Epoch 1135/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.4133 - mae: 6.7985 - val_loss: 93.0037 - val_mae: 6.8453\n",
            "Epoch 1136/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.5706 - mae: 6.8219 - val_loss: 93.0439 - val_mae: 6.8462\n",
            "Epoch 1137/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 90.2754 - mae: 6.8099 - val_loss: 93.1614 - val_mae: 6.8500\n",
            "Epoch 1138/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.1307 - mae: 6.8068 - val_loss: 92.4149 - val_mae: 6.8323\n",
            "Epoch 1139/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.9724 - mae: 6.8017 - val_loss: 92.8504 - val_mae: 6.8419\n",
            "Epoch 1140/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 90.2548 - mae: 6.8034 - val_loss: 92.7153 - val_mae: 6.8390\n",
            "Epoch 1141/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.2984 - mae: 6.8131 - val_loss: 92.8366 - val_mae: 6.8398\n",
            "Epoch 1142/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.4386 - mae: 6.8002 - val_loss: 92.9094 - val_mae: 6.8434\n",
            "Epoch 1143/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.0305 - mae: 6.7859 - val_loss: 92.8176 - val_mae: 6.8407\n",
            "Epoch 1144/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.1097 - mae: 6.8037 - val_loss: 92.7134 - val_mae: 6.8388\n",
            "Epoch 1145/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.9746 - mae: 6.7910 - val_loss: 92.6646 - val_mae: 6.8385\n",
            "Epoch 1146/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.9304 - mae: 6.7953 - val_loss: 92.8082 - val_mae: 6.8395\n",
            "Epoch 1147/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.1264 - mae: 6.7983 - val_loss: 92.8535 - val_mae: 6.8410\n",
            "Epoch 1148/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 90.3314 - mae: 6.8028 - val_loss: 92.4507 - val_mae: 6.8298\n",
            "Epoch 1149/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.0688 - mae: 6.8023 - val_loss: 92.3147 - val_mae: 6.8278\n",
            "Epoch 1150/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.1991 - mae: 6.8088 - val_loss: 92.5552 - val_mae: 6.8331\n",
            "Epoch 1151/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.1665 - mae: 6.8214 - val_loss: 92.3831 - val_mae: 6.8294\n",
            "Epoch 1152/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.0578 - mae: 6.7852 - val_loss: 92.5454 - val_mae: 6.8315\n",
            "Epoch 1153/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.6210 - mae: 6.7903 - val_loss: 92.5790 - val_mae: 6.8324\n",
            "Epoch 1154/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 90.1854 - mae: 6.8070 - val_loss: 92.4389 - val_mae: 6.8299\n",
            "Epoch 1155/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.1547 - mae: 6.8072 - val_loss: 92.3187 - val_mae: 6.8280\n",
            "Epoch 1156/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.9674 - mae: 6.7950 - val_loss: 92.3902 - val_mae: 6.8284\n",
            "Epoch 1157/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.6109 - mae: 6.7913 - val_loss: 92.3160 - val_mae: 6.8264\n",
            "Epoch 1158/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.4897 - mae: 6.7842 - val_loss: 92.3410 - val_mae: 6.8275\n",
            "Epoch 1159/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.7179 - mae: 6.8040 - val_loss: 92.3096 - val_mae: 6.8270\n",
            "Epoch 1160/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 90.4186 - mae: 6.8170 - val_loss: 92.3633 - val_mae: 6.8281\n",
            "Epoch 1161/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.3834 - mae: 6.7705 - val_loss: 92.3045 - val_mae: 6.8248\n",
            "Epoch 1162/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 90.3435 - mae: 6.8186 - val_loss: 92.3554 - val_mae: 6.8284\n",
            "Epoch 1163/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.6143 - mae: 6.7743 - val_loss: 92.3592 - val_mae: 6.8274\n",
            "Epoch 1164/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 89.8281 - mae: 6.7902 - val_loss: 92.1731 - val_mae: 6.8230\n",
            "Epoch 1165/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 89.6472 - mae: 6.7738 - val_loss: 92.2352 - val_mae: 6.8244\n",
            "Epoch 1166/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 89.5622 - mae: 6.7824 - val_loss: 92.1936 - val_mae: 6.8224\n",
            "Epoch 1167/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.9715 - mae: 6.8188 - val_loss: 92.1223 - val_mae: 6.8216\n",
            "Epoch 1168/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.4369 - mae: 6.7919 - val_loss: 92.3841 - val_mae: 6.8271\n",
            "Epoch 1169/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.9228 - mae: 6.7985 - val_loss: 92.1674 - val_mae: 6.8213\n",
            "Epoch 1170/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 89.6275 - mae: 6.7984 - val_loss: 92.1859 - val_mae: 6.8230\n",
            "Epoch 1171/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.8896 - mae: 6.7836 - val_loss: 92.3764 - val_mae: 6.8272\n",
            "Epoch 1172/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.4077 - mae: 6.7802 - val_loss: 92.2349 - val_mae: 6.8235\n",
            "Epoch 1173/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.6607 - mae: 6.7908 - val_loss: 91.7315 - val_mae: 6.8111\n",
            "Epoch 1174/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.4159 - mae: 6.7863 - val_loss: 91.9942 - val_mae: 6.8168\n",
            "Epoch 1175/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 89.1816 - mae: 6.7826 - val_loss: 92.0891 - val_mae: 6.8190\n",
            "Epoch 1176/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 90.1192 - mae: 6.8015 - val_loss: 91.8917 - val_mae: 6.8157\n",
            "Epoch 1177/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 89.8697 - mae: 6.8131 - val_loss: 92.1473 - val_mae: 6.8207\n",
            "Epoch 1178/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.5926 - mae: 6.8094 - val_loss: 92.0135 - val_mae: 6.8186\n",
            "Epoch 1179/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.8815 - mae: 6.7928 - val_loss: 91.9372 - val_mae: 6.8174\n",
            "Epoch 1180/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 89.6948 - mae: 6.8061 - val_loss: 91.9659 - val_mae: 6.8182\n",
            "Epoch 1181/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 89.4662 - mae: 6.7919 - val_loss: 92.0053 - val_mae: 6.8152\n",
            "Epoch 1182/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.1738 - mae: 6.7757 - val_loss: 91.8914 - val_mae: 6.8151\n",
            "Epoch 1183/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.5342 - mae: 6.7892 - val_loss: 91.7182 - val_mae: 6.8111\n",
            "Epoch 1184/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.3658 - mae: 6.7800 - val_loss: 92.0701 - val_mae: 6.8178\n",
            "Epoch 1185/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.0428 - mae: 6.7582 - val_loss: 91.6921 - val_mae: 6.8105\n",
            "Epoch 1186/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 89.1413 - mae: 6.7941 - val_loss: 91.5478 - val_mae: 6.8061\n",
            "Epoch 1187/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.7969 - mae: 6.7677 - val_loss: 91.7148 - val_mae: 6.8106\n",
            "Epoch 1188/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 89.5173 - mae: 6.7910 - val_loss: 91.8242 - val_mae: 6.8118\n",
            "Epoch 1189/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.0831 - mae: 6.7710 - val_loss: 91.6699 - val_mae: 6.8083\n",
            "Epoch 1190/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.1762 - mae: 6.7815 - val_loss: 91.5219 - val_mae: 6.8047\n",
            "Epoch 1191/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 89.4347 - mae: 6.7770 - val_loss: 91.4398 - val_mae: 6.8038\n",
            "Epoch 1192/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 89.1225 - mae: 6.7757 - val_loss: 91.4925 - val_mae: 6.8042\n",
            "Epoch 1193/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 89.4443 - mae: 6.7909 - val_loss: 91.7459 - val_mae: 6.8110\n",
            "Epoch 1194/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.3516 - mae: 6.7803 - val_loss: 91.6166 - val_mae: 6.8070\n",
            "Epoch 1195/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.0599 - mae: 6.7718 - val_loss: 91.3773 - val_mae: 6.8001\n",
            "Epoch 1196/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.3050 - mae: 6.7822 - val_loss: 91.4682 - val_mae: 6.8026\n",
            "Epoch 1197/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.1953 - mae: 6.7618 - val_loss: 91.2858 - val_mae: 6.7984\n",
            "Epoch 1198/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 88.8806 - mae: 6.7622 - val_loss: 91.6425 - val_mae: 6.8058\n",
            "Epoch 1199/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.3765 - mae: 6.8039 - val_loss: 91.3231 - val_mae: 6.8001\n",
            "Epoch 1200/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.9717 - mae: 6.7661 - val_loss: 91.5452 - val_mae: 6.8052\n",
            "Epoch 1201/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.5805 - mae: 6.7464 - val_loss: 91.1989 - val_mae: 6.7970\n",
            "Epoch 1202/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.9444 - mae: 6.7717 - val_loss: 91.4258 - val_mae: 6.8021\n",
            "Epoch 1203/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.5906 - mae: 6.7532 - val_loss: 91.5664 - val_mae: 6.8047\n",
            "Epoch 1204/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.9973 - mae: 6.7837 - val_loss: 91.5220 - val_mae: 6.8038\n",
            "Epoch 1205/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 88.9298 - mae: 6.7716 - val_loss: 91.5935 - val_mae: 6.8065\n",
            "Epoch 1206/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 88.7600 - mae: 6.7497 - val_loss: 91.1209 - val_mae: 6.7942\n",
            "Epoch 1207/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.6834 - mae: 6.7650 - val_loss: 91.2761 - val_mae: 6.7971\n",
            "Epoch 1208/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.6085 - mae: 6.7687 - val_loss: 91.3255 - val_mae: 6.7999\n",
            "Epoch 1209/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.8065 - mae: 6.7633 - val_loss: 91.1869 - val_mae: 6.7964\n",
            "Epoch 1210/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.6225 - mae: 6.7624 - val_loss: 91.1608 - val_mae: 6.7963\n",
            "Epoch 1211/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 88.5469 - mae: 6.7620 - val_loss: 91.2121 - val_mae: 6.7952\n",
            "Epoch 1212/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.6302 - mae: 6.7697 - val_loss: 91.1448 - val_mae: 6.7946\n",
            "Epoch 1213/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 89.0000 - mae: 6.7905 - val_loss: 91.0836 - val_mae: 6.7943\n",
            "Epoch 1214/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.4149 - mae: 6.7552 - val_loss: 91.2402 - val_mae: 6.7965\n",
            "Epoch 1215/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 88.7502 - mae: 6.7739 - val_loss: 90.9559 - val_mae: 6.7899\n",
            "Epoch 1216/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.7335 - mae: 6.7671 - val_loss: 91.1989 - val_mae: 6.7945\n",
            "Epoch 1217/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.4699 - mae: 6.7636 - val_loss: 91.2286 - val_mae: 6.7956\n",
            "Epoch 1218/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.9988 - mae: 6.7867 - val_loss: 90.8585 - val_mae: 6.7872\n",
            "Epoch 1219/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.5122 - mae: 6.7571 - val_loss: 90.8852 - val_mae: 6.7886\n",
            "Epoch 1220/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.8062 - mae: 6.7659 - val_loss: 91.3211 - val_mae: 6.7983\n",
            "Epoch 1221/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 88.5023 - mae: 6.7579 - val_loss: 91.0174 - val_mae: 6.7901\n",
            "Epoch 1222/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 89.0052 - mae: 6.7752 - val_loss: 90.8131 - val_mae: 6.7855\n",
            "Epoch 1223/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 88.5784 - mae: 6.7719 - val_loss: 91.1553 - val_mae: 6.7938\n",
            "Epoch 1224/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.3660 - mae: 6.7587 - val_loss: 90.7956 - val_mae: 6.7861\n",
            "Epoch 1225/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.4733 - mae: 6.7580 - val_loss: 90.9907 - val_mae: 6.7892\n",
            "Epoch 1226/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 88.4407 - mae: 6.7566 - val_loss: 91.0151 - val_mae: 6.7891\n",
            "Epoch 1227/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 88.3167 - mae: 6.7542 - val_loss: 90.7808 - val_mae: 6.7848\n",
            "Epoch 1228/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.2503 - mae: 6.7484 - val_loss: 90.6101 - val_mae: 6.7815\n",
            "Epoch 1229/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.5119 - mae: 6.7618 - val_loss: 90.5762 - val_mae: 6.7799\n",
            "Epoch 1230/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.9028 - mae: 6.7335 - val_loss: 90.8985 - val_mae: 6.7867\n",
            "Epoch 1231/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.2468 - mae: 6.7461 - val_loss: 90.8246 - val_mae: 6.7859\n",
            "Epoch 1232/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 88.6853 - mae: 6.7667 - val_loss: 90.6149 - val_mae: 6.7823\n",
            "Epoch 1233/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.2624 - mae: 6.7571 - val_loss: 90.5244 - val_mae: 6.7792\n",
            "Epoch 1234/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 88.0987 - mae: 6.7533 - val_loss: 90.7160 - val_mae: 6.7826\n",
            "Epoch 1235/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.2937 - mae: 6.7474 - val_loss: 90.5175 - val_mae: 6.7791\n",
            "Epoch 1236/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.9668 - mae: 6.7460 - val_loss: 90.8490 - val_mae: 6.7868\n",
            "Epoch 1237/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.3052 - mae: 6.7519 - val_loss: 90.6693 - val_mae: 6.7830\n",
            "Epoch 1238/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.3314 - mae: 6.7575 - val_loss: 90.7743 - val_mae: 6.7835\n",
            "Epoch 1239/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 88.0721 - mae: 6.7488 - val_loss: 90.8186 - val_mae: 6.7838\n",
            "Epoch 1240/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.2181 - mae: 6.7500 - val_loss: 90.7260 - val_mae: 6.7830\n",
            "Epoch 1241/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.0354 - mae: 6.7548 - val_loss: 90.6018 - val_mae: 6.7795\n",
            "Epoch 1242/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 88.2845 - mae: 6.7479 - val_loss: 90.4337 - val_mae: 6.7751\n",
            "Epoch 1243/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.8684 - mae: 6.7355 - val_loss: 90.7241 - val_mae: 6.7821\n",
            "Epoch 1244/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.1032 - mae: 6.7508 - val_loss: 90.4312 - val_mae: 6.7755\n",
            "Epoch 1245/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.8045 - mae: 6.7192 - val_loss: 90.2656 - val_mae: 6.7717\n",
            "Epoch 1246/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.7628 - mae: 6.7300 - val_loss: 90.2614 - val_mae: 6.7713\n",
            "Epoch 1247/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.8706 - mae: 6.7458 - val_loss: 90.2644 - val_mae: 6.7707\n",
            "Epoch 1248/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.8435 - mae: 6.7365 - val_loss: 90.1420 - val_mae: 6.7684\n",
            "Epoch 1249/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 88.0498 - mae: 6.7482 - val_loss: 90.2268 - val_mae: 6.7701\n",
            "Epoch 1250/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.9225 - mae: 6.7254 - val_loss: 90.3071 - val_mae: 6.7713\n",
            "Epoch 1251/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 87.9093 - mae: 6.7351 - val_loss: 90.3254 - val_mae: 6.7727\n",
            "Epoch 1252/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.7200 - mae: 6.7360 - val_loss: 90.3201 - val_mae: 6.7724\n",
            "Epoch 1253/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.7778 - mae: 6.7375 - val_loss: 90.1636 - val_mae: 6.7674\n",
            "Epoch 1254/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.4686 - mae: 6.7197 - val_loss: 90.2564 - val_mae: 6.7708\n",
            "Epoch 1255/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.6500 - mae: 6.7294 - val_loss: 90.0048 - val_mae: 6.7648\n",
            "Epoch 1256/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.6189 - mae: 6.7389 - val_loss: 90.0211 - val_mae: 6.7649\n",
            "Epoch 1257/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.6772 - mae: 6.7292 - val_loss: 90.1778 - val_mae: 6.7684\n",
            "Epoch 1258/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.7551 - mae: 6.7423 - val_loss: 90.2296 - val_mae: 6.7687\n",
            "Epoch 1259/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.9186 - mae: 6.7433 - val_loss: 90.3307 - val_mae: 6.7710\n",
            "Epoch 1260/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.8397 - mae: 6.7489 - val_loss: 90.2620 - val_mae: 6.7697\n",
            "Epoch 1261/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 87.6720 - mae: 6.7200 - val_loss: 89.9903 - val_mae: 6.7637\n",
            "Epoch 1262/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.9443 - mae: 6.7511 - val_loss: 90.3273 - val_mae: 6.7700\n",
            "Epoch 1263/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.8120 - mae: 6.7428 - val_loss: 90.1717 - val_mae: 6.7680\n",
            "Epoch 1264/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.8011 - mae: 6.7322 - val_loss: 90.0602 - val_mae: 6.7662\n",
            "Epoch 1265/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.8584 - mae: 6.7315 - val_loss: 89.9266 - val_mae: 6.7628\n",
            "Epoch 1266/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.4077 - mae: 6.7387 - val_loss: 89.8333 - val_mae: 6.7596\n",
            "Epoch 1267/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.4042 - mae: 6.7281 - val_loss: 89.8617 - val_mae: 6.7599\n",
            "Epoch 1268/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.2596 - mae: 6.7093 - val_loss: 90.0922 - val_mae: 6.7653\n",
            "Epoch 1269/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.0766 - mae: 6.7098 - val_loss: 89.7648 - val_mae: 6.7601\n",
            "Epoch 1270/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.2610 - mae: 6.7244 - val_loss: 89.8932 - val_mae: 6.7609\n",
            "Epoch 1271/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.9189 - mae: 6.7017 - val_loss: 90.0251 - val_mae: 6.7627\n",
            "Epoch 1272/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.1356 - mae: 6.7198 - val_loss: 90.0202 - val_mae: 6.7656\n",
            "Epoch 1273/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.4821 - mae: 6.7297 - val_loss: 90.1408 - val_mae: 6.7651\n",
            "Epoch 1274/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 87.2928 - mae: 6.7160 - val_loss: 89.8219 - val_mae: 6.7589\n",
            "Epoch 1275/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.0530 - mae: 6.7237 - val_loss: 89.6638 - val_mae: 6.7556\n",
            "Epoch 1276/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.3716 - mae: 6.7123 - val_loss: 89.7573 - val_mae: 6.7569\n",
            "Epoch 1277/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.2394 - mae: 6.7275 - val_loss: 89.7187 - val_mae: 6.7551\n",
            "Epoch 1278/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.3709 - mae: 6.7370 - val_loss: 89.7712 - val_mae: 6.7581\n",
            "Epoch 1279/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.4684 - mae: 6.7303 - val_loss: 89.5331 - val_mae: 6.7526\n",
            "Epoch 1280/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.4219 - mae: 6.7362 - val_loss: 89.9106 - val_mae: 6.7595\n",
            "Epoch 1281/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.3567 - mae: 6.7380 - val_loss: 89.5644 - val_mae: 6.7535\n",
            "Epoch 1282/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.1624 - mae: 6.7093 - val_loss: 89.8014 - val_mae: 6.7583\n",
            "Epoch 1283/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.0521 - mae: 6.7297 - val_loss: 89.4952 - val_mae: 6.7508\n",
            "Epoch 1284/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.2605 - mae: 6.7260 - val_loss: 89.6532 - val_mae: 6.7540\n",
            "Epoch 1285/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.2779 - mae: 6.7300 - val_loss: 89.7858 - val_mae: 6.7583\n",
            "Epoch 1286/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.3224 - mae: 6.7195 - val_loss: 89.8838 - val_mae: 6.7571\n",
            "Epoch 1287/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.0209 - mae: 6.7352 - val_loss: 89.5126 - val_mae: 6.7504\n",
            "Epoch 1288/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 87.0924 - mae: 6.7226 - val_loss: 89.5127 - val_mae: 6.7501\n",
            "Epoch 1289/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.1664 - mae: 6.7141 - val_loss: 89.6933 - val_mae: 6.7552\n",
            "Epoch 1290/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.0588 - mae: 6.7263 - val_loss: 89.6056 - val_mae: 6.7531\n",
            "Epoch 1291/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 87.2628 - mae: 6.7237 - val_loss: 89.2783 - val_mae: 6.7469\n",
            "Epoch 1292/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.8386 - mae: 6.7033 - val_loss: 89.4384 - val_mae: 6.7503\n",
            "Epoch 1293/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.2252 - mae: 6.7157 - val_loss: 89.2599 - val_mae: 6.7448\n",
            "Epoch 1294/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 86.9212 - mae: 6.7234 - val_loss: 89.3308 - val_mae: 6.7458\n",
            "Epoch 1295/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.4152 - mae: 6.7380 - val_loss: 89.2706 - val_mae: 6.7460\n",
            "Epoch 1296/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 87.3290 - mae: 6.7206 - val_loss: 89.6065 - val_mae: 6.7523\n",
            "Epoch 1297/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.7997 - mae: 6.7169 - val_loss: 89.1127 - val_mae: 6.7412\n",
            "Epoch 1298/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.1179 - mae: 6.7210 - val_loss: 89.5015 - val_mae: 6.7508\n",
            "Epoch 1299/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 86.6347 - mae: 6.6960 - val_loss: 89.3354 - val_mae: 6.7476\n",
            "Epoch 1300/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.0735 - mae: 6.7230 - val_loss: 89.1616 - val_mae: 6.7415\n",
            "Epoch 1301/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.3122 - mae: 6.7309 - val_loss: 89.3136 - val_mae: 6.7453\n",
            "Epoch 1302/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.6119 - mae: 6.7097 - val_loss: 89.2449 - val_mae: 6.7426\n",
            "Epoch 1303/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.6916 - mae: 6.7177 - val_loss: 89.2880 - val_mae: 6.7435\n",
            "Epoch 1304/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.9551 - mae: 6.7024 - val_loss: 89.0991 - val_mae: 6.7404\n",
            "Epoch 1305/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.7150 - mae: 6.7125 - val_loss: 89.2977 - val_mae: 6.7451\n",
            "Epoch 1306/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 87.0253 - mae: 6.7139 - val_loss: 89.2256 - val_mae: 6.7437\n",
            "Epoch 1307/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.8906 - mae: 6.7073 - val_loss: 89.0898 - val_mae: 6.7414\n",
            "Epoch 1308/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 87.1534 - mae: 6.7381 - val_loss: 89.2830 - val_mae: 6.7454\n",
            "Epoch 1309/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 87.0361 - mae: 6.7274 - val_loss: 89.0879 - val_mae: 6.7395\n",
            "Epoch 1310/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.9027 - mae: 6.7173 - val_loss: 89.1468 - val_mae: 6.7418\n",
            "Epoch 1311/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.9730 - mae: 6.7351 - val_loss: 89.2201 - val_mae: 6.7423\n",
            "Epoch 1312/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.9067 - mae: 6.7125 - val_loss: 88.9539 - val_mae: 6.7380\n",
            "Epoch 1313/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.6954 - mae: 6.7166 - val_loss: 88.8953 - val_mae: 6.7353\n",
            "Epoch 1314/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 86.6902 - mae: 6.7126 - val_loss: 89.0045 - val_mae: 6.7374\n",
            "Epoch 1315/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.1944 - mae: 6.6808 - val_loss: 88.9069 - val_mae: 6.7361\n",
            "Epoch 1316/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.6497 - mae: 6.7130 - val_loss: 88.6545 - val_mae: 6.7292\n",
            "Epoch 1317/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 86.4157 - mae: 6.7118 - val_loss: 88.7975 - val_mae: 6.7314\n",
            "Epoch 1318/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.4496 - mae: 6.7004 - val_loss: 88.7475 - val_mae: 6.7308\n",
            "Epoch 1319/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 86.5527 - mae: 6.7026 - val_loss: 88.8140 - val_mae: 6.7331\n",
            "Epoch 1320/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.3050 - mae: 6.6959 - val_loss: 89.0012 - val_mae: 6.7386\n",
            "Epoch 1321/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.4565 - mae: 6.7104 - val_loss: 88.8135 - val_mae: 6.7329\n",
            "Epoch 1322/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.5932 - mae: 6.7136 - val_loss: 88.8917 - val_mae: 6.7353\n",
            "Epoch 1323/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 86.5328 - mae: 6.6965 - val_loss: 88.7162 - val_mae: 6.7299\n",
            "Epoch 1324/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.5272 - mae: 6.7093 - val_loss: 88.8090 - val_mae: 6.7324\n",
            "Epoch 1325/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 86.5921 - mae: 6.7231 - val_loss: 88.6195 - val_mae: 6.7274\n",
            "Epoch 1326/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.2917 - mae: 6.6839 - val_loss: 89.0121 - val_mae: 6.7354\n",
            "Epoch 1327/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.5819 - mae: 6.7198 - val_loss: 88.6678 - val_mae: 6.7289\n",
            "Epoch 1328/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.2906 - mae: 6.6914 - val_loss: 88.6497 - val_mae: 6.7288\n",
            "Epoch 1329/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.5069 - mae: 6.7089 - val_loss: 88.9058 - val_mae: 6.7341\n",
            "Epoch 1330/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.9551 - mae: 6.7058 - val_loss: 88.6744 - val_mae: 6.7286\n",
            "Epoch 1331/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 86.4338 - mae: 6.7115 - val_loss: 88.5525 - val_mae: 6.7277\n",
            "Epoch 1332/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.3906 - mae: 6.7027 - val_loss: 88.6238 - val_mae: 6.7286\n",
            "Epoch 1333/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.2544 - mae: 6.6954 - val_loss: 88.5624 - val_mae: 6.7268\n",
            "Epoch 1334/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 86.0650 - mae: 6.7015 - val_loss: 88.3784 - val_mae: 6.7235\n",
            "Epoch 1335/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 86.2937 - mae: 6.6997 - val_loss: 88.8376 - val_mae: 6.7327\n",
            "Epoch 1336/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.9483 - mae: 6.6891 - val_loss: 88.5781 - val_mae: 6.7279\n",
            "Epoch 1337/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 85.9935 - mae: 6.6851 - val_loss: 88.6472 - val_mae: 6.7285\n",
            "Epoch 1338/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.1894 - mae: 6.6963 - val_loss: 88.6040 - val_mae: 6.7270\n",
            "Epoch 1339/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.0794 - mae: 6.7079 - val_loss: 88.6393 - val_mae: 6.7275\n",
            "Epoch 1340/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 85.9315 - mae: 6.6879 - val_loss: 88.2471 - val_mae: 6.7192\n",
            "Epoch 1341/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.0995 - mae: 6.6897 - val_loss: 88.5817 - val_mae: 6.7270\n",
            "Epoch 1342/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.1447 - mae: 6.7107 - val_loss: 88.5476 - val_mae: 6.7258\n",
            "Epoch 1343/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.0032 - mae: 6.6879 - val_loss: 88.5524 - val_mae: 6.7269\n",
            "Epoch 1344/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.0771 - mae: 6.6917 - val_loss: 88.6392 - val_mae: 6.7291\n",
            "Epoch 1345/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.8466 - mae: 6.6768 - val_loss: 88.4516 - val_mae: 6.7242\n",
            "Epoch 1346/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.9162 - mae: 6.6966 - val_loss: 88.1155 - val_mae: 6.7162\n",
            "Epoch 1347/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.6636 - mae: 6.6649 - val_loss: 88.4041 - val_mae: 6.7218\n",
            "Epoch 1348/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.2627 - mae: 6.7093 - val_loss: 88.0791 - val_mae: 6.7159\n",
            "Epoch 1349/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.4747 - mae: 6.7070 - val_loss: 88.4376 - val_mae: 6.7222\n",
            "Epoch 1350/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.0290 - mae: 6.7022 - val_loss: 88.1663 - val_mae: 6.7183\n",
            "Epoch 1351/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.7197 - mae: 6.6868 - val_loss: 88.3352 - val_mae: 6.7210\n",
            "Epoch 1352/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.7390 - mae: 6.6890 - val_loss: 88.0363 - val_mae: 6.7144\n",
            "Epoch 1353/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.8298 - mae: 6.6834 - val_loss: 88.1696 - val_mae: 6.7172\n",
            "Epoch 1354/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 85.7878 - mae: 6.6893 - val_loss: 88.2873 - val_mae: 6.7190\n",
            "Epoch 1355/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.8094 - mae: 6.6981 - val_loss: 88.5097 - val_mae: 6.7225\n",
            "Epoch 1356/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.4494 - mae: 6.6687 - val_loss: 88.0480 - val_mae: 6.7139\n",
            "Epoch 1357/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 85.4640 - mae: 6.6666 - val_loss: 88.0091 - val_mae: 6.7141\n",
            "Epoch 1358/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.9767 - mae: 6.6932 - val_loss: 88.1546 - val_mae: 6.7160\n",
            "Epoch 1359/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.6169 - mae: 6.6790 - val_loss: 88.0859 - val_mae: 6.7150\n",
            "Epoch 1360/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.9190 - mae: 6.6930 - val_loss: 88.3731 - val_mae: 6.7190\n",
            "Epoch 1361/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 86.1256 - mae: 6.6890 - val_loss: 87.9001 - val_mae: 6.7105\n",
            "Epoch 1362/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.7409 - mae: 6.6762 - val_loss: 88.0703 - val_mae: 6.7152\n",
            "Epoch 1363/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.6474 - mae: 6.6853 - val_loss: 88.3006 - val_mae: 6.7212\n",
            "Epoch 1364/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.5038 - mae: 6.6900 - val_loss: 87.9155 - val_mae: 6.7109\n",
            "Epoch 1365/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.4678 - mae: 6.6784 - val_loss: 88.0103 - val_mae: 6.7119\n",
            "Epoch 1366/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.8676 - mae: 6.6953 - val_loss: 88.0546 - val_mae: 6.7142\n",
            "Epoch 1367/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.8290 - mae: 6.6856 - val_loss: 87.8965 - val_mae: 6.7104\n",
            "Epoch 1368/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.5584 - mae: 6.6774 - val_loss: 87.8583 - val_mae: 6.7111\n",
            "Epoch 1369/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.6706 - mae: 6.6783 - val_loss: 87.9015 - val_mae: 6.7113\n",
            "Epoch 1370/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.7071 - mae: 6.6846 - val_loss: 87.9419 - val_mae: 6.7121\n",
            "Epoch 1371/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 86.0144 - mae: 6.6992 - val_loss: 87.7075 - val_mae: 6.7060\n",
            "Epoch 1372/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 85.7202 - mae: 6.6808 - val_loss: 88.0166 - val_mae: 6.7130\n",
            "Epoch 1373/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.7460 - mae: 6.6875 - val_loss: 87.9465 - val_mae: 6.7126\n",
            "Epoch 1374/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.4524 - mae: 6.6712 - val_loss: 87.6762 - val_mae: 6.7050\n",
            "Epoch 1375/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.4397 - mae: 6.6687 - val_loss: 87.7781 - val_mae: 6.7067\n",
            "Epoch 1376/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.4032 - mae: 6.6945 - val_loss: 87.9663 - val_mae: 6.7118\n",
            "Epoch 1377/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.6250 - mae: 6.6866 - val_loss: 87.8492 - val_mae: 6.7090\n",
            "Epoch 1378/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.6027 - mae: 6.6909 - val_loss: 87.4836 - val_mae: 6.7012\n",
            "Epoch 1379/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.2235 - mae: 6.6681 - val_loss: 87.6321 - val_mae: 6.7054\n",
            "Epoch 1380/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.6393 - mae: 6.6770 - val_loss: 87.6235 - val_mae: 6.7050\n",
            "Epoch 1381/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 86.1001 - mae: 6.6988 - val_loss: 87.7783 - val_mae: 6.7059\n",
            "Epoch 1382/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.2611 - mae: 6.6641 - val_loss: 87.5860 - val_mae: 6.7034\n",
            "Epoch 1383/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.2665 - mae: 6.6599 - val_loss: 87.5858 - val_mae: 6.7010\n",
            "Epoch 1384/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.7136 - mae: 6.6623 - val_loss: 87.5797 - val_mae: 6.7024\n",
            "Epoch 1385/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.8383 - mae: 6.6936 - val_loss: 87.4507 - val_mae: 6.7002\n",
            "Epoch 1386/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 85.7306 - mae: 6.6908 - val_loss: 87.6594 - val_mae: 6.7050\n",
            "Epoch 1387/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.9500 - mae: 6.6618 - val_loss: 87.6062 - val_mae: 6.7040\n",
            "Epoch 1388/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.0920 - mae: 6.6626 - val_loss: 87.6706 - val_mae: 6.7060\n",
            "Epoch 1389/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.7816 - mae: 6.6470 - val_loss: 87.5404 - val_mae: 6.7022\n",
            "Epoch 1390/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.1267 - mae: 6.6648 - val_loss: 87.5152 - val_mae: 6.7013\n",
            "Epoch 1391/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.3687 - mae: 6.6720 - val_loss: 87.6390 - val_mae: 6.7034\n",
            "Epoch 1392/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.4855 - mae: 6.6800 - val_loss: 87.4175 - val_mae: 6.6984\n",
            "Epoch 1393/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.1485 - mae: 6.6541 - val_loss: 87.4270 - val_mae: 6.6985\n",
            "Epoch 1394/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.7342 - mae: 6.6533 - val_loss: 87.3967 - val_mae: 6.6986\n",
            "Epoch 1395/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.9298 - mae: 6.6549 - val_loss: 87.3624 - val_mae: 6.6965\n",
            "Epoch 1396/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 85.0964 - mae: 6.6712 - val_loss: 87.3637 - val_mae: 6.6973\n",
            "Epoch 1397/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.5171 - mae: 6.6876 - val_loss: 87.4252 - val_mae: 6.7002\n",
            "Epoch 1398/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.0032 - mae: 6.6716 - val_loss: 87.5104 - val_mae: 6.6998\n",
            "Epoch 1399/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 85.0506 - mae: 6.6654 - val_loss: 87.6338 - val_mae: 6.7030\n",
            "Epoch 1400/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.7900 - mae: 6.6699 - val_loss: 87.2455 - val_mae: 6.6946\n",
            "Epoch 1401/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 85.3986 - mae: 6.6993 - val_loss: 87.2542 - val_mae: 6.6952\n",
            "Epoch 1402/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.2448 - mae: 6.6640 - val_loss: 87.1812 - val_mae: 6.6934\n",
            "Epoch 1403/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.9588 - mae: 6.6640 - val_loss: 87.2636 - val_mae: 6.6954\n",
            "Epoch 1404/10000\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 84.9699 - mae: 6.6650 - val_loss: 87.3890 - val_mae: 6.6982\n",
            "Epoch 1405/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.8942 - mae: 6.6536 - val_loss: 87.3526 - val_mae: 6.6977\n",
            "Epoch 1406/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.1441 - mae: 6.6608 - val_loss: 87.2877 - val_mae: 6.6959\n",
            "Epoch 1407/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.8526 - mae: 6.6605 - val_loss: 87.0466 - val_mae: 6.6890\n",
            "Epoch 1408/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.2358 - mae: 6.6785 - val_loss: 87.5775 - val_mae: 6.7005\n",
            "Epoch 1409/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.7017 - mae: 6.6671 - val_loss: 87.1875 - val_mae: 6.6942\n",
            "Epoch 1410/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.6870 - mae: 6.6704 - val_loss: 87.0078 - val_mae: 6.6917\n",
            "Epoch 1411/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.9042 - mae: 6.6466 - val_loss: 87.1498 - val_mae: 6.6922\n",
            "Epoch 1412/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 84.7361 - mae: 6.6652 - val_loss: 87.2156 - val_mae: 6.6940\n",
            "Epoch 1413/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 84.5646 - mae: 6.6593 - val_loss: 87.0977 - val_mae: 6.6914\n",
            "Epoch 1414/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.1859 - mae: 6.6693 - val_loss: 87.1387 - val_mae: 6.6922\n",
            "Epoch 1415/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 84.9717 - mae: 6.6778 - val_loss: 86.7522 - val_mae: 6.6834\n",
            "Epoch 1416/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.5125 - mae: 6.6367 - val_loss: 86.9058 - val_mae: 6.6884\n",
            "Epoch 1417/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.9547 - mae: 6.6655 - val_loss: 86.9837 - val_mae: 6.6892\n",
            "Epoch 1418/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.7797 - mae: 6.6573 - val_loss: 86.9923 - val_mae: 6.6893\n",
            "Epoch 1419/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.3787 - mae: 6.6405 - val_loss: 87.1536 - val_mae: 6.6913\n",
            "Epoch 1420/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 84.9938 - mae: 6.6685 - val_loss: 87.3126 - val_mae: 6.6946\n",
            "Epoch 1421/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.7764 - mae: 6.6710 - val_loss: 86.9452 - val_mae: 6.6865\n",
            "Epoch 1422/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.3812 - mae: 6.6669 - val_loss: 86.8830 - val_mae: 6.6858\n",
            "Epoch 1423/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.3755 - mae: 6.6483 - val_loss: 86.8980 - val_mae: 6.6872\n",
            "Epoch 1424/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 84.4067 - mae: 6.6405 - val_loss: 86.8859 - val_mae: 6.6865\n",
            "Epoch 1425/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 85.0172 - mae: 6.6648 - val_loss: 86.9014 - val_mae: 6.6857\n",
            "Epoch 1426/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 84.7377 - mae: 6.6719 - val_loss: 86.7625 - val_mae: 6.6839\n",
            "Epoch 1427/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 85.0092 - mae: 6.6790 - val_loss: 86.8342 - val_mae: 6.6857\n",
            "Epoch 1428/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.4925 - mae: 6.6434 - val_loss: 87.0806 - val_mae: 6.6894\n",
            "Epoch 1429/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.5932 - mae: 6.6555 - val_loss: 86.8202 - val_mae: 6.6839\n",
            "Epoch 1430/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.2784 - mae: 6.6512 - val_loss: 86.5420 - val_mae: 6.6799\n",
            "Epoch 1431/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.4271 - mae: 6.6626 - val_loss: 86.8655 - val_mae: 6.6849\n",
            "Epoch 1432/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.5515 - mae: 6.6582 - val_loss: 86.8240 - val_mae: 6.6856\n",
            "Epoch 1433/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.9933 - mae: 6.6366 - val_loss: 86.6204 - val_mae: 6.6794\n",
            "Epoch 1434/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.4102 - mae: 6.6519 - val_loss: 86.8054 - val_mae: 6.6843\n",
            "Epoch 1435/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.4493 - mae: 6.6411 - val_loss: 86.6891 - val_mae: 6.6811\n",
            "Epoch 1436/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 84.7051 - mae: 6.6625 - val_loss: 86.7483 - val_mae: 6.6823\n",
            "Epoch 1437/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.4376 - mae: 6.6507 - val_loss: 86.7226 - val_mae: 6.6823\n",
            "Epoch 1438/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.2204 - mae: 6.6421 - val_loss: 86.5667 - val_mae: 6.6800\n",
            "Epoch 1439/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.5857 - mae: 6.6601 - val_loss: 86.6143 - val_mae: 6.6806\n",
            "Epoch 1440/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 84.0438 - mae: 6.6484 - val_loss: 86.4763 - val_mae: 6.6786\n",
            "Epoch 1441/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.9997 - mae: 6.6311 - val_loss: 86.8001 - val_mae: 6.6838\n",
            "Epoch 1442/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 84.2007 - mae: 6.6442 - val_loss: 86.7768 - val_mae: 6.6828\n",
            "Epoch 1443/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.7444 - mae: 6.6435 - val_loss: 86.4168 - val_mae: 6.6756\n",
            "Epoch 1444/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.0605 - mae: 6.6359 - val_loss: 86.4368 - val_mae: 6.6772\n",
            "Epoch 1445/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.9551 - mae: 6.6391 - val_loss: 86.5251 - val_mae: 6.6785\n",
            "Epoch 1446/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.9679 - mae: 6.6358 - val_loss: 86.6345 - val_mae: 6.6806\n",
            "Epoch 1447/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.9055 - mae: 6.6323 - val_loss: 86.4763 - val_mae: 6.6758\n",
            "Epoch 1448/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.5094 - mae: 6.6584 - val_loss: 86.6517 - val_mae: 6.6816\n",
            "Epoch 1449/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.1742 - mae: 6.6449 - val_loss: 86.3484 - val_mae: 6.6746\n",
            "Epoch 1450/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.4001 - mae: 6.6470 - val_loss: 86.4080 - val_mae: 6.6763\n",
            "Epoch 1451/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.2756 - mae: 6.6575 - val_loss: 86.5804 - val_mae: 6.6794\n",
            "Epoch 1452/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.5032 - mae: 6.6241 - val_loss: 86.2854 - val_mae: 6.6733\n",
            "Epoch 1453/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.4636 - mae: 6.6590 - val_loss: 86.4675 - val_mae: 6.6759\n",
            "Epoch 1454/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.0244 - mae: 6.6548 - val_loss: 86.1420 - val_mae: 6.6701\n",
            "Epoch 1455/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 84.1074 - mae: 6.6371 - val_loss: 86.3676 - val_mae: 6.6749\n",
            "Epoch 1456/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.1461 - mae: 6.6550 - val_loss: 86.3170 - val_mae: 6.6730\n",
            "Epoch 1457/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.9185 - mae: 6.6371 - val_loss: 86.1601 - val_mae: 6.6707\n",
            "Epoch 1458/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 84.3192 - mae: 6.6545 - val_loss: 86.3984 - val_mae: 6.6766\n",
            "Epoch 1459/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 83.9747 - mae: 6.6493 - val_loss: 86.3116 - val_mae: 6.6742\n",
            "Epoch 1460/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 84.2835 - mae: 6.6607 - val_loss: 86.3958 - val_mae: 6.6766\n",
            "Epoch 1461/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.8584 - mae: 6.6511 - val_loss: 86.2488 - val_mae: 6.6728\n",
            "Epoch 1462/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.7266 - mae: 6.6318 - val_loss: 86.2052 - val_mae: 6.6723\n",
            "Epoch 1463/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.9470 - mae: 6.6537 - val_loss: 86.4383 - val_mae: 6.6761\n",
            "Epoch 1464/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 84.3755 - mae: 6.6612 - val_loss: 86.2255 - val_mae: 6.6717\n",
            "Epoch 1465/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 84.3840 - mae: 6.6640 - val_loss: 86.0527 - val_mae: 6.6691\n",
            "Epoch 1466/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.9679 - mae: 6.6275 - val_loss: 85.9818 - val_mae: 6.6684\n",
            "Epoch 1467/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.7903 - mae: 6.6343 - val_loss: 86.1676 - val_mae: 6.6710\n",
            "Epoch 1468/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.0516 - mae: 6.6433 - val_loss: 86.2492 - val_mae: 6.6723\n",
            "Epoch 1469/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.4858 - mae: 6.6331 - val_loss: 86.0814 - val_mae: 6.6687\n",
            "Epoch 1470/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 84.3951 - mae: 6.6542 - val_loss: 85.9838 - val_mae: 6.6679\n",
            "Epoch 1471/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 83.7763 - mae: 6.6362 - val_loss: 85.9958 - val_mae: 6.6672\n",
            "Epoch 1472/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.8524 - mae: 6.6390 - val_loss: 85.9065 - val_mae: 6.6649\n",
            "Epoch 1473/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.6500 - mae: 6.6308 - val_loss: 85.8554 - val_mae: 6.6649\n",
            "Epoch 1474/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 83.4892 - mae: 6.6438 - val_loss: 85.9957 - val_mae: 6.6651\n",
            "Epoch 1475/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 84.3458 - mae: 6.6591 - val_loss: 85.8644 - val_mae: 6.6646\n",
            "Epoch 1476/10000\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 83.1645 - mae: 6.6074 - val_loss: 85.8708 - val_mae: 6.6649\n",
            "Epoch 1477/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.8798 - mae: 6.6439 - val_loss: 85.9830 - val_mae: 6.6673\n",
            "Epoch 1478/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.9765 - mae: 6.5973 - val_loss: 85.9734 - val_mae: 6.6668\n",
            "Epoch 1479/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.6598 - mae: 6.6393 - val_loss: 85.7285 - val_mae: 6.6604\n",
            "Epoch 1480/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.7613 - mae: 6.6452 - val_loss: 85.9420 - val_mae: 6.6657\n",
            "Epoch 1481/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 83.8868 - mae: 6.6334 - val_loss: 86.0999 - val_mae: 6.6673\n",
            "Epoch 1482/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.8773 - mae: 6.6269 - val_loss: 85.7300 - val_mae: 6.6611\n",
            "Epoch 1483/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.7775 - mae: 6.6368 - val_loss: 85.8895 - val_mae: 6.6641\n",
            "Epoch 1484/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.6490 - mae: 6.6314 - val_loss: 85.8676 - val_mae: 6.6652\n",
            "Epoch 1485/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 83.5804 - mae: 6.6252 - val_loss: 85.8371 - val_mae: 6.6640\n",
            "Epoch 1486/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.9748 - mae: 6.6626 - val_loss: 85.6441 - val_mae: 6.6611\n",
            "Epoch 1487/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 83.7337 - mae: 6.6360 - val_loss: 85.9313 - val_mae: 6.6633\n",
            "Epoch 1488/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.6436 - mae: 6.6398 - val_loss: 85.8852 - val_mae: 6.6651\n",
            "Epoch 1489/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.5922 - mae: 6.6344 - val_loss: 85.9113 - val_mae: 6.6642\n",
            "Epoch 1490/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 83.6938 - mae: 6.6450 - val_loss: 85.6540 - val_mae: 6.6596\n",
            "Epoch 1491/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.5554 - mae: 6.6244 - val_loss: 85.7651 - val_mae: 6.6624\n",
            "Epoch 1492/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.7068 - mae: 6.6229 - val_loss: 85.6605 - val_mae: 6.6605\n",
            "Epoch 1493/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 83.6236 - mae: 6.6334 - val_loss: 85.4717 - val_mae: 6.6563\n",
            "Epoch 1494/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.5042 - mae: 6.6309 - val_loss: 85.4996 - val_mae: 6.6558\n",
            "Epoch 1495/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 83.4384 - mae: 6.6249 - val_loss: 85.7520 - val_mae: 6.6623\n",
            "Epoch 1496/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 83.9711 - mae: 6.6381 - val_loss: 85.7643 - val_mae: 6.6628\n",
            "Epoch 1497/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.4735 - mae: 6.6406 - val_loss: 85.7628 - val_mae: 6.6605\n",
            "Epoch 1498/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 83.1428 - mae: 6.6269 - val_loss: 85.5862 - val_mae: 6.6587\n",
            "Epoch 1499/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.4174 - mae: 6.6469 - val_loss: 85.5984 - val_mae: 6.6588\n",
            "Epoch 1500/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.9672 - mae: 6.6460 - val_loss: 85.5165 - val_mae: 6.6552\n",
            "Epoch 1501/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.3975 - mae: 6.6316 - val_loss: 85.4647 - val_mae: 6.6566\n",
            "Epoch 1502/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.5003 - mae: 6.6225 - val_loss: 85.5918 - val_mae: 6.6587\n",
            "Epoch 1503/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.5292 - mae: 6.6450 - val_loss: 85.5344 - val_mae: 6.6558\n",
            "Epoch 1504/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 83.2145 - mae: 6.6073 - val_loss: 85.6060 - val_mae: 6.6585\n",
            "Epoch 1505/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.0905 - mae: 6.6214 - val_loss: 85.3993 - val_mae: 6.6549\n",
            "Epoch 1506/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 83.5928 - mae: 6.6406 - val_loss: 85.2430 - val_mae: 6.6520\n",
            "Epoch 1507/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 83.3988 - mae: 6.6339 - val_loss: 85.4398 - val_mae: 6.6556\n",
            "Epoch 1508/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.5830 - mae: 6.6409 - val_loss: 85.3750 - val_mae: 6.6540\n",
            "Epoch 1509/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 83.2795 - mae: 6.6417 - val_loss: 85.3029 - val_mae: 6.6525\n",
            "Epoch 1510/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 83.1581 - mae: 6.6180 - val_loss: 85.2673 - val_mae: 6.6528\n",
            "Epoch 1511/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.2136 - mae: 6.6298 - val_loss: 85.1352 - val_mae: 6.6512\n",
            "Epoch 1512/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 83.2642 - mae: 6.6272 - val_loss: 85.3879 - val_mae: 6.6533\n",
            "Epoch 1513/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 82.9952 - mae: 6.6174 - val_loss: 85.6228 - val_mae: 6.6586\n",
            "Epoch 1514/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.2288 - mae: 6.6418 - val_loss: 85.1751 - val_mae: 6.6502\n",
            "Epoch 1515/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 82.9533 - mae: 6.6243 - val_loss: 85.4374 - val_mae: 6.6529\n",
            "Epoch 1516/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.5797 - mae: 6.6418 - val_loss: 85.0745 - val_mae: 6.6474\n",
            "Epoch 1517/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.0504 - mae: 6.6171 - val_loss: 85.3225 - val_mae: 6.6519\n",
            "Epoch 1518/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.3391 - mae: 6.6301 - val_loss: 85.3328 - val_mae: 6.6521\n",
            "Epoch 1519/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.2114 - mae: 6.6347 - val_loss: 85.1922 - val_mae: 6.6491\n",
            "Epoch 1520/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.1446 - mae: 6.6267 - val_loss: 85.1389 - val_mae: 6.6493\n",
            "Epoch 1521/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.6361 - mae: 6.6505 - val_loss: 85.1377 - val_mae: 6.6498\n",
            "Epoch 1522/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.4843 - mae: 6.6448 - val_loss: 85.1641 - val_mae: 6.6497\n",
            "Epoch 1523/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.0787 - mae: 6.6261 - val_loss: 85.0925 - val_mae: 6.6497\n",
            "Epoch 1524/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.7814 - mae: 6.6185 - val_loss: 85.1462 - val_mae: 6.6495\n",
            "Epoch 1525/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 83.1385 - mae: 6.6158 - val_loss: 85.1330 - val_mae: 6.6500\n",
            "Epoch 1526/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 83.0984 - mae: 6.6207 - val_loss: 85.2005 - val_mae: 6.6495\n",
            "Epoch 1527/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.2096 - mae: 6.6313 - val_loss: 85.1362 - val_mae: 6.6490\n",
            "Epoch 1528/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.7305 - mae: 6.6041 - val_loss: 85.1099 - val_mae: 6.6479\n",
            "Epoch 1529/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.8365 - mae: 6.6304 - val_loss: 85.0340 - val_mae: 6.6473\n",
            "Epoch 1530/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.1993 - mae: 6.6248 - val_loss: 85.0472 - val_mae: 6.6475\n",
            "Epoch 1531/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.8404 - mae: 6.6222 - val_loss: 84.8725 - val_mae: 6.6445\n",
            "Epoch 1532/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.4207 - mae: 6.6084 - val_loss: 85.1100 - val_mae: 6.6490\n",
            "Epoch 1533/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.3597 - mae: 6.6459 - val_loss: 85.1627 - val_mae: 6.6487\n",
            "Epoch 1534/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.5747 - mae: 6.6013 - val_loss: 85.0241 - val_mae: 6.6481\n",
            "Epoch 1535/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.8556 - mae: 6.6154 - val_loss: 85.1920 - val_mae: 6.6486\n",
            "Epoch 1536/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 83.0024 - mae: 6.6292 - val_loss: 85.0138 - val_mae: 6.6465\n",
            "Epoch 1537/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.7476 - mae: 6.6140 - val_loss: 84.9249 - val_mae: 6.6445\n",
            "Epoch 1538/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.6796 - mae: 6.6193 - val_loss: 85.0898 - val_mae: 6.6463\n",
            "Epoch 1539/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.8260 - mae: 6.6131 - val_loss: 84.9813 - val_mae: 6.6454\n",
            "Epoch 1540/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 82.8580 - mae: 6.6295 - val_loss: 85.1591 - val_mae: 6.6490\n",
            "Epoch 1541/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.5196 - mae: 6.6055 - val_loss: 84.9028 - val_mae: 6.6456\n",
            "Epoch 1542/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.7522 - mae: 6.6144 - val_loss: 84.7606 - val_mae: 6.6416\n",
            "Epoch 1543/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 83.0196 - mae: 6.6303 - val_loss: 84.7865 - val_mae: 6.6431\n",
            "Epoch 1544/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.3743 - mae: 6.6007 - val_loss: 84.9503 - val_mae: 6.6441\n",
            "Epoch 1545/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.7668 - mae: 6.6227 - val_loss: 84.8429 - val_mae: 6.6427\n",
            "Epoch 1546/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.5049 - mae: 6.6163 - val_loss: 84.8356 - val_mae: 6.6423\n",
            "Epoch 1547/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.4260 - mae: 6.6205 - val_loss: 84.7187 - val_mae: 6.6409\n",
            "Epoch 1548/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 82.7633 - mae: 6.6077 - val_loss: 84.8662 - val_mae: 6.6425\n",
            "Epoch 1549/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.9644 - mae: 6.6319 - val_loss: 84.7145 - val_mae: 6.6407\n",
            "Epoch 1550/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.5404 - mae: 6.6058 - val_loss: 84.7753 - val_mae: 6.6424\n",
            "Epoch 1551/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 82.5966 - mae: 6.6011 - val_loss: 84.8038 - val_mae: 6.6404\n",
            "Epoch 1552/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.6703 - mae: 6.6286 - val_loss: 84.6959 - val_mae: 6.6403\n",
            "Epoch 1553/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.6648 - mae: 6.6150 - val_loss: 84.5999 - val_mae: 6.6394\n",
            "Epoch 1554/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 83.0030 - mae: 6.6429 - val_loss: 84.5830 - val_mae: 6.6382\n",
            "Epoch 1555/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.8543 - mae: 6.6178 - val_loss: 84.7812 - val_mae: 6.6396\n",
            "Epoch 1556/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.5488 - mae: 6.6006 - val_loss: 84.7199 - val_mae: 6.6407\n",
            "Epoch 1557/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 82.6756 - mae: 6.6239 - val_loss: 84.5744 - val_mae: 6.6378\n",
            "Epoch 1558/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.7425 - mae: 6.6184 - val_loss: 84.3787 - val_mae: 6.6353\n",
            "Epoch 1559/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.5792 - mae: 6.6059 - val_loss: 84.8557 - val_mae: 6.6421\n",
            "Epoch 1560/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.7312 - mae: 6.6260 - val_loss: 84.7990 - val_mae: 6.6413\n",
            "Epoch 1561/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.8203 - mae: 6.6284 - val_loss: 84.5907 - val_mae: 6.6375\n",
            "Epoch 1562/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.0492 - mae: 6.5882 - val_loss: 84.4981 - val_mae: 6.6352\n",
            "Epoch 1563/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 82.9347 - mae: 6.6240 - val_loss: 84.6446 - val_mae: 6.6398\n",
            "Epoch 1564/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.0350 - mae: 6.5979 - val_loss: 84.4757 - val_mae: 6.6362\n",
            "Epoch 1565/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 82.0751 - mae: 6.6073 - val_loss: 84.7390 - val_mae: 6.6389\n",
            "Epoch 1566/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.4391 - mae: 6.6142 - val_loss: 84.6149 - val_mae: 6.6381\n",
            "Epoch 1567/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.4027 - mae: 6.6240 - val_loss: 84.4420 - val_mae: 6.6352\n",
            "Epoch 1568/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 82.0846 - mae: 6.5996 - val_loss: 84.6428 - val_mae: 6.6372\n",
            "Epoch 1569/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.1411 - mae: 6.5882 - val_loss: 84.4314 - val_mae: 6.6352\n",
            "Epoch 1570/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.2405 - mae: 6.5946 - val_loss: 84.4563 - val_mae: 6.6357\n",
            "Epoch 1571/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.2898 - mae: 6.6124 - val_loss: 84.5873 - val_mae: 6.6390\n",
            "Epoch 1572/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.2333 - mae: 6.5978 - val_loss: 84.2190 - val_mae: 6.6308\n",
            "Epoch 1573/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.3668 - mae: 6.6055 - val_loss: 84.0591 - val_mae: 6.6284\n",
            "Epoch 1574/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.9065 - mae: 6.5893 - val_loss: 84.2459 - val_mae: 6.6328\n",
            "Epoch 1575/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.1135 - mae: 6.5881 - val_loss: 84.3317 - val_mae: 6.6319\n",
            "Epoch 1576/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 82.5081 - mae: 6.6149 - val_loss: 84.4053 - val_mae: 6.6360\n",
            "Epoch 1577/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.3216 - mae: 6.6245 - val_loss: 84.3828 - val_mae: 6.6335\n",
            "Epoch 1578/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.1461 - mae: 6.5938 - val_loss: 84.1834 - val_mae: 6.6324\n",
            "Epoch 1579/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.9659 - mae: 6.5869 - val_loss: 84.3230 - val_mae: 6.6317\n",
            "Epoch 1580/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 82.1633 - mae: 6.6154 - val_loss: 84.3395 - val_mae: 6.6317\n",
            "Epoch 1581/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 82.4677 - mae: 6.6018 - val_loss: 84.2536 - val_mae: 6.6308\n",
            "Epoch 1582/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 81.7601 - mae: 6.5860 - val_loss: 84.4007 - val_mae: 6.6338\n",
            "Epoch 1583/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.2839 - mae: 6.5956 - val_loss: 83.9567 - val_mae: 6.6272\n",
            "Epoch 1584/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 82.3441 - mae: 6.6171 - val_loss: 84.2574 - val_mae: 6.6308\n",
            "Epoch 1585/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.3772 - mae: 6.6258 - val_loss: 84.0982 - val_mae: 6.6282\n",
            "Epoch 1586/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.3569 - mae: 6.6084 - val_loss: 84.1166 - val_mae: 6.6286\n",
            "Epoch 1587/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.5952 - mae: 6.5834 - val_loss: 84.2810 - val_mae: 6.6320\n",
            "Epoch 1588/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.9804 - mae: 6.5926 - val_loss: 84.0923 - val_mae: 6.6282\n",
            "Epoch 1589/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.0988 - mae: 6.6006 - val_loss: 84.1299 - val_mae: 6.6292\n",
            "Epoch 1590/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.1305 - mae: 6.6038 - val_loss: 84.1647 - val_mae: 6.6302\n",
            "Epoch 1591/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.1324 - mae: 6.5941 - val_loss: 84.0687 - val_mae: 6.6280\n",
            "Epoch 1592/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 81.9349 - mae: 6.6034 - val_loss: 84.0658 - val_mae: 6.6280\n",
            "Epoch 1593/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 82.2212 - mae: 6.6066 - val_loss: 84.0402 - val_mae: 6.6272\n",
            "Epoch 1594/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.9148 - mae: 6.5927 - val_loss: 84.1586 - val_mae: 6.6286\n",
            "Epoch 1595/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.0115 - mae: 6.6116 - val_loss: 84.0991 - val_mae: 6.6278\n",
            "Epoch 1596/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.1592 - mae: 6.5987 - val_loss: 84.2215 - val_mae: 6.6299\n",
            "Epoch 1597/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.9424 - mae: 6.6094 - val_loss: 84.0602 - val_mae: 6.6264\n",
            "Epoch 1598/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.8850 - mae: 6.5887 - val_loss: 83.9441 - val_mae: 6.6261\n",
            "Epoch 1599/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 82.0141 - mae: 6.6090 - val_loss: 84.1863 - val_mae: 6.6295\n",
            "Epoch 1600/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.0455 - mae: 6.5959 - val_loss: 84.2580 - val_mae: 6.6311\n",
            "Epoch 1601/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.0110 - mae: 6.5956 - val_loss: 84.1931 - val_mae: 6.6285\n",
            "Epoch 1602/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.4979 - mae: 6.5899 - val_loss: 83.9452 - val_mae: 6.6249\n",
            "Epoch 1603/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.7824 - mae: 6.5824 - val_loss: 84.1402 - val_mae: 6.6288\n",
            "Epoch 1604/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.2894 - mae: 6.5819 - val_loss: 84.0757 - val_mae: 6.6269\n",
            "Epoch 1605/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.6675 - mae: 6.6059 - val_loss: 83.8805 - val_mae: 6.6248\n",
            "Epoch 1606/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.6520 - mae: 6.5944 - val_loss: 83.8294 - val_mae: 6.6244\n",
            "Epoch 1607/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.4979 - mae: 6.5714 - val_loss: 84.0250 - val_mae: 6.6269\n",
            "Epoch 1608/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.4633 - mae: 6.5800 - val_loss: 83.9984 - val_mae: 6.6267\n",
            "Epoch 1609/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 82.0335 - mae: 6.6210 - val_loss: 83.8558 - val_mae: 6.6244\n",
            "Epoch 1610/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.2987 - mae: 6.5704 - val_loss: 83.9786 - val_mae: 6.6270\n",
            "Epoch 1611/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.5810 - mae: 6.5865 - val_loss: 83.6557 - val_mae: 6.6210\n",
            "Epoch 1612/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.7827 - mae: 6.5891 - val_loss: 83.8821 - val_mae: 6.6240\n",
            "Epoch 1613/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.6820 - mae: 6.5821 - val_loss: 83.9487 - val_mae: 6.6235\n",
            "Epoch 1614/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.8634 - mae: 6.5968 - val_loss: 83.7089 - val_mae: 6.6213\n",
            "Epoch 1615/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.4414 - mae: 6.5827 - val_loss: 83.9133 - val_mae: 6.6233\n",
            "Epoch 1616/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.8061 - mae: 6.5901 - val_loss: 83.7703 - val_mae: 6.6214\n",
            "Epoch 1617/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.4621 - mae: 6.5858 - val_loss: 83.7750 - val_mae: 6.6222\n",
            "Epoch 1618/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.4152 - mae: 6.5889 - val_loss: 83.8588 - val_mae: 6.6233\n",
            "Epoch 1619/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.7047 - mae: 6.5920 - val_loss: 83.8785 - val_mae: 6.6237\n",
            "Epoch 1620/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.3825 - mae: 6.5773 - val_loss: 83.9051 - val_mae: 6.6239\n",
            "Epoch 1621/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 82.1439 - mae: 6.6022 - val_loss: 83.8316 - val_mae: 6.6221\n",
            "Epoch 1622/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.5375 - mae: 6.5864 - val_loss: 83.7694 - val_mae: 6.6218\n",
            "Epoch 1623/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.6364 - mae: 6.5967 - val_loss: 83.6985 - val_mae: 6.6223\n",
            "Epoch 1624/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.5899 - mae: 6.5880 - val_loss: 83.6716 - val_mae: 6.6213\n",
            "Epoch 1625/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.9946 - mae: 6.5962 - val_loss: 83.7634 - val_mae: 6.6216\n",
            "Epoch 1626/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.5141 - mae: 6.5948 - val_loss: 83.5223 - val_mae: 6.6180\n",
            "Epoch 1627/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.5145 - mae: 6.5904 - val_loss: 83.4899 - val_mae: 6.6187\n",
            "Epoch 1628/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.7540 - mae: 6.6044 - val_loss: 83.6175 - val_mae: 6.6204\n",
            "Epoch 1629/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.4387 - mae: 6.5662 - val_loss: 83.6804 - val_mae: 6.6210\n",
            "Epoch 1630/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 81.5204 - mae: 6.5894 - val_loss: 83.7853 - val_mae: 6.6215\n",
            "Epoch 1631/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.2639 - mae: 6.5835 - val_loss: 83.5627 - val_mae: 6.6186\n",
            "Epoch 1632/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.3730 - mae: 6.5831 - val_loss: 83.5797 - val_mae: 6.6189\n",
            "Epoch 1633/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.3152 - mae: 6.5790 - val_loss: 83.6912 - val_mae: 6.6207\n",
            "Epoch 1634/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.5835 - mae: 6.5946 - val_loss: 83.4722 - val_mae: 6.6160\n",
            "Epoch 1635/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.9254 - mae: 6.5668 - val_loss: 83.3454 - val_mae: 6.6148\n",
            "Epoch 1636/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.1840 - mae: 6.5804 - val_loss: 83.4167 - val_mae: 6.6157\n",
            "Epoch 1637/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.1079 - mae: 6.5727 - val_loss: 83.3174 - val_mae: 6.6130\n",
            "Epoch 1638/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.8595 - mae: 6.6058 - val_loss: 83.3955 - val_mae: 6.6169\n",
            "Epoch 1639/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.2430 - mae: 6.5757 - val_loss: 83.5327 - val_mae: 6.6161\n",
            "Epoch 1640/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.2540 - mae: 6.5889 - val_loss: 83.3134 - val_mae: 6.6145\n",
            "Epoch 1641/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 81.6274 - mae: 6.6119 - val_loss: 83.5247 - val_mae: 6.6159\n",
            "Epoch 1642/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.0926 - mae: 6.5823 - val_loss: 83.3466 - val_mae: 6.6154\n",
            "Epoch 1643/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.6897 - mae: 6.6007 - val_loss: 83.3884 - val_mae: 6.6157\n",
            "Epoch 1644/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.7486 - mae: 6.6068 - val_loss: 83.4167 - val_mae: 6.6162\n",
            "Epoch 1645/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.3320 - mae: 6.5989 - val_loss: 83.3595 - val_mae: 6.6152\n",
            "Epoch 1646/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 81.0653 - mae: 6.5940 - val_loss: 83.3923 - val_mae: 6.6161\n",
            "Epoch 1647/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 81.0822 - mae: 6.5750 - val_loss: 83.4497 - val_mae: 6.6153\n",
            "Epoch 1648/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.3250 - mae: 6.5909 - val_loss: 83.3703 - val_mae: 6.6144\n",
            "Epoch 1649/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.1696 - mae: 6.5839 - val_loss: 83.2468 - val_mae: 6.6122\n",
            "Epoch 1650/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.9492 - mae: 6.5803 - val_loss: 83.4337 - val_mae: 6.6156\n",
            "Epoch 1651/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 81.5051 - mae: 6.5999 - val_loss: 83.2389 - val_mae: 6.6142\n",
            "Epoch 1652/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.4189 - mae: 6.6013 - val_loss: 83.2322 - val_mae: 6.6126\n",
            "Epoch 1653/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.3080 - mae: 6.5912 - val_loss: 83.3526 - val_mae: 6.6134\n",
            "Epoch 1654/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.2757 - mae: 6.5754 - val_loss: 83.3986 - val_mae: 6.6156\n",
            "Epoch 1655/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.5471 - mae: 6.6032 - val_loss: 83.1336 - val_mae: 6.6124\n",
            "Epoch 1656/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.1998 - mae: 6.5755 - val_loss: 83.2028 - val_mae: 6.6117\n",
            "Epoch 1657/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.2658 - mae: 6.5886 - val_loss: 83.3210 - val_mae: 6.6136\n",
            "Epoch 1658/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.1128 - mae: 6.5830 - val_loss: 83.1374 - val_mae: 6.6115\n",
            "Epoch 1659/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.9974 - mae: 6.5817 - val_loss: 83.1648 - val_mae: 6.6119\n",
            "Epoch 1660/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.2549 - mae: 6.5959 - val_loss: 83.2911 - val_mae: 6.6125\n",
            "Epoch 1661/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.4756 - mae: 6.6051 - val_loss: 83.1552 - val_mae: 6.6112\n",
            "Epoch 1662/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 80.7238 - mae: 6.5603 - val_loss: 83.1884 - val_mae: 6.6131\n",
            "Epoch 1663/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.0936 - mae: 6.5831 - val_loss: 83.0855 - val_mae: 6.6101\n",
            "Epoch 1664/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.9210 - mae: 6.5751 - val_loss: 83.0674 - val_mae: 6.6101\n",
            "Epoch 1665/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.6368 - mae: 6.5596 - val_loss: 83.1481 - val_mae: 6.6111\n",
            "Epoch 1666/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.1459 - mae: 6.5953 - val_loss: 83.0333 - val_mae: 6.6079\n",
            "Epoch 1667/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 81.3276 - mae: 6.5986 - val_loss: 83.2406 - val_mae: 6.6135\n",
            "Epoch 1668/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 81.2083 - mae: 6.5718 - val_loss: 82.7981 - val_mae: 6.6057\n",
            "Epoch 1669/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.9204 - mae: 6.5783 - val_loss: 83.2489 - val_mae: 6.6114\n",
            "Epoch 1670/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.5907 - mae: 6.5538 - val_loss: 82.8581 - val_mae: 6.6061\n",
            "Epoch 1671/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 81.1691 - mae: 6.5813 - val_loss: 83.0855 - val_mae: 6.6109\n",
            "Epoch 1672/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 81.2190 - mae: 6.6049 - val_loss: 82.8755 - val_mae: 6.6064\n",
            "Epoch 1673/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.9670 - mae: 6.5862 - val_loss: 82.9767 - val_mae: 6.6083\n",
            "Epoch 1674/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.9071 - mae: 6.5704 - val_loss: 82.9633 - val_mae: 6.6072\n",
            "Epoch 1675/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.6793 - mae: 6.5680 - val_loss: 82.8417 - val_mae: 6.6062\n",
            "Epoch 1676/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.8155 - mae: 6.5590 - val_loss: 82.8517 - val_mae: 6.6068\n",
            "Epoch 1677/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.9781 - mae: 6.5903 - val_loss: 82.7964 - val_mae: 6.6049\n",
            "Epoch 1678/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.9701 - mae: 6.5739 - val_loss: 83.0653 - val_mae: 6.6089\n",
            "Epoch 1679/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.5852 - mae: 6.5740 - val_loss: 82.9444 - val_mae: 6.6076\n",
            "Epoch 1680/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.9751 - mae: 6.5913 - val_loss: 82.7128 - val_mae: 6.6039\n",
            "Epoch 1681/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 81.0223 - mae: 6.5808 - val_loss: 82.9865 - val_mae: 6.6088\n",
            "Epoch 1682/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.8170 - mae: 6.5852 - val_loss: 82.8678 - val_mae: 6.6066\n",
            "Epoch 1683/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.7270 - mae: 6.5746 - val_loss: 82.9497 - val_mae: 6.6060\n",
            "Epoch 1684/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.7216 - mae: 6.5751 - val_loss: 82.5895 - val_mae: 6.6023\n",
            "Epoch 1685/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 80.5927 - mae: 6.5689 - val_loss: 82.7361 - val_mae: 6.6048\n",
            "Epoch 1686/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.8239 - mae: 6.5696 - val_loss: 82.8667 - val_mae: 6.6067\n",
            "Epoch 1687/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.8749 - mae: 6.5935 - val_loss: 82.7619 - val_mae: 6.6038\n",
            "Epoch 1688/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.7471 - mae: 6.5806 - val_loss: 82.7619 - val_mae: 6.6040\n",
            "Epoch 1689/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.9975 - mae: 6.5790 - val_loss: 82.7083 - val_mae: 6.6043\n",
            "Epoch 1690/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.2794 - mae: 6.5665 - val_loss: 82.5823 - val_mae: 6.6020\n",
            "Epoch 1691/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.6554 - mae: 6.5839 - val_loss: 82.7106 - val_mae: 6.6042\n",
            "Epoch 1692/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.6449 - mae: 6.5717 - val_loss: 82.8168 - val_mae: 6.6037\n",
            "Epoch 1693/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.7976 - mae: 6.5773 - val_loss: 82.6754 - val_mae: 6.6030\n",
            "Epoch 1694/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.4395 - mae: 6.5690 - val_loss: 82.5045 - val_mae: 6.6015\n",
            "Epoch 1695/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.6850 - mae: 6.5691 - val_loss: 82.6228 - val_mae: 6.6037\n",
            "Epoch 1696/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 80.5573 - mae: 6.5585 - val_loss: 82.7949 - val_mae: 6.6038\n",
            "Epoch 1697/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.5829 - mae: 6.5737 - val_loss: 82.4470 - val_mae: 6.5990\n",
            "Epoch 1698/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.3912 - mae: 6.5795 - val_loss: 82.5382 - val_mae: 6.6008\n",
            "Epoch 1699/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.1239 - mae: 6.5622 - val_loss: 82.7252 - val_mae: 6.6015\n",
            "Epoch 1700/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.9609 - mae: 6.5650 - val_loss: 82.5085 - val_mae: 6.6019\n",
            "Epoch 1701/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.4215 - mae: 6.5708 - val_loss: 82.5922 - val_mae: 6.6009\n",
            "Epoch 1702/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.4989 - mae: 6.5627 - val_loss: 82.5501 - val_mae: 6.6010\n",
            "Epoch 1703/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.6251 - mae: 6.5805 - val_loss: 82.6158 - val_mae: 6.6015\n",
            "Epoch 1704/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.2567 - mae: 6.5628 - val_loss: 82.5710 - val_mae: 6.6011\n",
            "Epoch 1705/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.9637 - mae: 6.5565 - val_loss: 82.4748 - val_mae: 6.6006\n",
            "Epoch 1706/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.4200 - mae: 6.5722 - val_loss: 82.5873 - val_mae: 6.6031\n",
            "Epoch 1707/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.5399 - mae: 6.5848 - val_loss: 82.5413 - val_mae: 6.6027\n",
            "Epoch 1708/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 80.3905 - mae: 6.5835 - val_loss: 82.4712 - val_mae: 6.5989\n",
            "Epoch 1709/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.9822 - mae: 6.5577 - val_loss: 82.4350 - val_mae: 6.5995\n",
            "Epoch 1710/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.4753 - mae: 6.5614 - val_loss: 82.5170 - val_mae: 6.5993\n",
            "Epoch 1711/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.3396 - mae: 6.5703 - val_loss: 82.4404 - val_mae: 6.5995\n",
            "Epoch 1712/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.3092 - mae: 6.5641 - val_loss: 82.3474 - val_mae: 6.5964\n",
            "Epoch 1713/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.4398 - mae: 6.5842 - val_loss: 82.6170 - val_mae: 6.6019\n",
            "Epoch 1714/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.1256 - mae: 6.5605 - val_loss: 82.4055 - val_mae: 6.5999\n",
            "Epoch 1715/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 80.0756 - mae: 6.5540 - val_loss: 82.4096 - val_mae: 6.5980\n",
            "Epoch 1716/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.1719 - mae: 6.5541 - val_loss: 82.3015 - val_mae: 6.5975\n",
            "Epoch 1717/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.6683 - mae: 6.5910 - val_loss: 82.3809 - val_mae: 6.5981\n",
            "Epoch 1718/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.2373 - mae: 6.5634 - val_loss: 82.3492 - val_mae: 6.5990\n",
            "Epoch 1719/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.1637 - mae: 6.5595 - val_loss: 82.2514 - val_mae: 6.5957\n",
            "Epoch 1720/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.6765 - mae: 6.5775 - val_loss: 82.5717 - val_mae: 6.6011\n",
            "Epoch 1721/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.5883 - mae: 6.5797 - val_loss: 82.4381 - val_mae: 6.5969\n",
            "Epoch 1722/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.4575 - mae: 6.5631 - val_loss: 82.1641 - val_mae: 6.5954\n",
            "Epoch 1723/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.3120 - mae: 6.5836 - val_loss: 82.4217 - val_mae: 6.5983\n",
            "Epoch 1724/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.4774 - mae: 6.5762 - val_loss: 82.2086 - val_mae: 6.5967\n",
            "Epoch 1725/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.4132 - mae: 6.5758 - val_loss: 82.2919 - val_mae: 6.5970\n",
            "Epoch 1726/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.3238 - mae: 6.5518 - val_loss: 82.3805 - val_mae: 6.5968\n",
            "Epoch 1727/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.0392 - mae: 6.5594 - val_loss: 82.2924 - val_mae: 6.5970\n",
            "Epoch 1728/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.2117 - mae: 6.5581 - val_loss: 82.2033 - val_mae: 6.5972\n",
            "Epoch 1729/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 80.2092 - mae: 6.5763 - val_loss: 82.2909 - val_mae: 6.5968\n",
            "Epoch 1730/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.7165 - mae: 6.5795 - val_loss: 82.2882 - val_mae: 6.5971\n",
            "Epoch 1731/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.3984 - mae: 6.5734 - val_loss: 82.2413 - val_mae: 6.5973\n",
            "Epoch 1732/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.2028 - mae: 6.5611 - val_loss: 82.1992 - val_mae: 6.5963\n",
            "Epoch 1733/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.6764 - mae: 6.5538 - val_loss: 82.1896 - val_mae: 6.5953\n",
            "Epoch 1734/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.3473 - mae: 6.5657 - val_loss: 82.1573 - val_mae: 6.5961\n",
            "Epoch 1735/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.4949 - mae: 6.5765 - val_loss: 81.8160 - val_mae: 6.5912\n",
            "Epoch 1736/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.1458 - mae: 6.5662 - val_loss: 82.2080 - val_mae: 6.5927\n",
            "Epoch 1737/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.9901 - mae: 6.5724 - val_loss: 82.2897 - val_mae: 6.5968\n",
            "Epoch 1738/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.6354 - mae: 6.5394 - val_loss: 82.0820 - val_mae: 6.5948\n",
            "Epoch 1739/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.0560 - mae: 6.5758 - val_loss: 82.1018 - val_mae: 6.5952\n",
            "Epoch 1740/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.2195 - mae: 6.5598 - val_loss: 81.9917 - val_mae: 6.5935\n",
            "Epoch 1741/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.0008 - mae: 6.5539 - val_loss: 82.1905 - val_mae: 6.5949\n",
            "Epoch 1742/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.0119 - mae: 6.5725 - val_loss: 82.1809 - val_mae: 6.5954\n",
            "Epoch 1743/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 80.0587 - mae: 6.5795 - val_loss: 82.0009 - val_mae: 6.5923\n",
            "Epoch 1744/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.1191 - mae: 6.5635 - val_loss: 81.9678 - val_mae: 6.5951\n",
            "Epoch 1745/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.9563 - mae: 6.5617 - val_loss: 81.8584 - val_mae: 6.5931\n",
            "Epoch 1746/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.4894 - mae: 6.5487 - val_loss: 81.9217 - val_mae: 6.5921\n",
            "Epoch 1747/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.1653 - mae: 6.5718 - val_loss: 82.0072 - val_mae: 6.5920\n",
            "Epoch 1748/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.8557 - mae: 6.5633 - val_loss: 82.0340 - val_mae: 6.5915\n",
            "Epoch 1749/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.6843 - mae: 6.5635 - val_loss: 81.9074 - val_mae: 6.5923\n",
            "Epoch 1750/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.4586 - mae: 6.5833 - val_loss: 82.1019 - val_mae: 6.5942\n",
            "Epoch 1751/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.7794 - mae: 6.5590 - val_loss: 81.9792 - val_mae: 6.5932\n",
            "Epoch 1752/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.5985 - mae: 6.5585 - val_loss: 81.8999 - val_mae: 6.5930\n",
            "Epoch 1753/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.1351 - mae: 6.5684 - val_loss: 81.7461 - val_mae: 6.5899\n",
            "Epoch 1754/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.8301 - mae: 6.5554 - val_loss: 81.9640 - val_mae: 6.5922\n",
            "Epoch 1755/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.8241 - mae: 6.5632 - val_loss: 81.8604 - val_mae: 6.5909\n",
            "Epoch 1756/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.5534 - mae: 6.5468 - val_loss: 81.8138 - val_mae: 6.5892\n",
            "Epoch 1757/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.6794 - mae: 6.5475 - val_loss: 81.7636 - val_mae: 6.5891\n",
            "Epoch 1758/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.2098 - mae: 6.5802 - val_loss: 81.7751 - val_mae: 6.5907\n",
            "Epoch 1759/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.8406 - mae: 6.5710 - val_loss: 81.7837 - val_mae: 6.5901\n",
            "Epoch 1760/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.7396 - mae: 6.5462 - val_loss: 81.7893 - val_mae: 6.5903\n",
            "Epoch 1761/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.2606 - mae: 6.5456 - val_loss: 81.7135 - val_mae: 6.5885\n",
            "Epoch 1762/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.9445 - mae: 6.5473 - val_loss: 81.7837 - val_mae: 6.5901\n",
            "Epoch 1763/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.8849 - mae: 6.5536 - val_loss: 81.7790 - val_mae: 6.5892\n",
            "Epoch 1764/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.5689 - mae: 6.5598 - val_loss: 81.5884 - val_mae: 6.5865\n",
            "Epoch 1765/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 80.0226 - mae: 6.5583 - val_loss: 81.6451 - val_mae: 6.5879\n",
            "Epoch 1766/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.9175 - mae: 6.5554 - val_loss: 81.8312 - val_mae: 6.5908\n",
            "Epoch 1767/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.9850 - mae: 6.5615 - val_loss: 81.6916 - val_mae: 6.5897\n",
            "Epoch 1768/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.1893 - mae: 6.5776 - val_loss: 81.6993 - val_mae: 6.5889\n",
            "Epoch 1769/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 80.0069 - mae: 6.5673 - val_loss: 81.6957 - val_mae: 6.5901\n",
            "Epoch 1770/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.9186 - mae: 6.5613 - val_loss: 81.7915 - val_mae: 6.5908\n",
            "Epoch 1771/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.3116 - mae: 6.5524 - val_loss: 81.6087 - val_mae: 6.5863\n",
            "Epoch 1772/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.6633 - mae: 6.5682 - val_loss: 81.6114 - val_mae: 6.5855\n",
            "Epoch 1773/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.6141 - mae: 6.5518 - val_loss: 81.8417 - val_mae: 6.5904\n",
            "Epoch 1774/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.7607 - mae: 6.5580 - val_loss: 81.6446 - val_mae: 6.5862\n",
            "Epoch 1775/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.4873 - mae: 6.5512 - val_loss: 81.5706 - val_mae: 6.5869\n",
            "Epoch 1776/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.6170 - mae: 6.5644 - val_loss: 81.5941 - val_mae: 6.5862\n",
            "Epoch 1777/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.5132 - mae: 6.5474 - val_loss: 81.4399 - val_mae: 6.5855\n",
            "Epoch 1778/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 80.2088 - mae: 6.5941 - val_loss: 81.6286 - val_mae: 6.5872\n",
            "Epoch 1779/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.3054 - mae: 6.5376 - val_loss: 81.6426 - val_mae: 6.5869\n",
            "Epoch 1780/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.6672 - mae: 6.5699 - val_loss: 81.7397 - val_mae: 6.5875\n",
            "Epoch 1781/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.8377 - mae: 6.5558 - val_loss: 81.4873 - val_mae: 6.5856\n",
            "Epoch 1782/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.5276 - mae: 6.5462 - val_loss: 81.4642 - val_mae: 6.5844\n",
            "Epoch 1783/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.1759 - mae: 6.5350 - val_loss: 81.6869 - val_mae: 6.5865\n",
            "Epoch 1784/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.1694 - mae: 6.5470 - val_loss: 81.4255 - val_mae: 6.5846\n",
            "Epoch 1785/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.2477 - mae: 6.5395 - val_loss: 81.3203 - val_mae: 6.5847\n",
            "Epoch 1786/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.3178 - mae: 6.5504 - val_loss: 81.5947 - val_mae: 6.5870\n",
            "Epoch 1787/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.3072 - mae: 6.5453 - val_loss: 81.3833 - val_mae: 6.5850\n",
            "Epoch 1788/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.8162 - mae: 6.5706 - val_loss: 81.4024 - val_mae: 6.5832\n",
            "Epoch 1789/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.4945 - mae: 6.5476 - val_loss: 81.5233 - val_mae: 6.5870\n",
            "Epoch 1790/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.6296 - mae: 6.5565 - val_loss: 81.4322 - val_mae: 6.5857\n",
            "Epoch 1791/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.3825 - mae: 6.5611 - val_loss: 81.6453 - val_mae: 6.5872\n",
            "Epoch 1792/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.5394 - mae: 6.5550 - val_loss: 81.3499 - val_mae: 6.5843\n",
            "Epoch 1793/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.5220 - mae: 6.5579 - val_loss: 81.3674 - val_mae: 6.5837\n",
            "Epoch 1794/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.4769 - mae: 6.5613 - val_loss: 81.5003 - val_mae: 6.5867\n",
            "Epoch 1795/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.8606 - mae: 6.5263 - val_loss: 81.3425 - val_mae: 6.5825\n",
            "Epoch 1796/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.3289 - mae: 6.5416 - val_loss: 81.2794 - val_mae: 6.5814\n",
            "Epoch 1797/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.2298 - mae: 6.5464 - val_loss: 81.1993 - val_mae: 6.5800\n",
            "Epoch 1798/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.1473 - mae: 6.5502 - val_loss: 81.1826 - val_mae: 6.5820\n",
            "Epoch 1799/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.0454 - mae: 6.5378 - val_loss: 81.3034 - val_mae: 6.5828\n",
            "Epoch 1800/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.4626 - mae: 6.5718 - val_loss: 81.3836 - val_mae: 6.5819\n",
            "Epoch 1801/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.2497 - mae: 6.5494 - val_loss: 81.3051 - val_mae: 6.5817\n",
            "Epoch 1802/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.4953 - mae: 6.5622 - val_loss: 81.3413 - val_mae: 6.5831\n",
            "Epoch 1803/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.5572 - mae: 6.5547 - val_loss: 81.4319 - val_mae: 6.5850\n",
            "Epoch 1804/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.5278 - mae: 6.5603 - val_loss: 81.3411 - val_mae: 6.5830\n",
            "Epoch 1805/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.3886 - mae: 6.5423 - val_loss: 81.2779 - val_mae: 6.5810\n",
            "Epoch 1806/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.4266 - mae: 6.5496 - val_loss: 81.1209 - val_mae: 6.5805\n",
            "Epoch 1807/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.4594 - mae: 6.5637 - val_loss: 81.3152 - val_mae: 6.5828\n",
            "Epoch 1808/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.2117 - mae: 6.5515 - val_loss: 81.1635 - val_mae: 6.5792\n",
            "Epoch 1809/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.3438 - mae: 6.5659 - val_loss: 81.3800 - val_mae: 6.5834\n",
            "Epoch 1810/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.4156 - mae: 6.5652 - val_loss: 81.1824 - val_mae: 6.5798\n",
            "Epoch 1811/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.3613 - mae: 6.5524 - val_loss: 81.4191 - val_mae: 6.5843\n",
            "Epoch 1812/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.9773 - mae: 6.5251 - val_loss: 81.2068 - val_mae: 6.5816\n",
            "Epoch 1813/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.9557 - mae: 6.5340 - val_loss: 80.9871 - val_mae: 6.5777\n",
            "Epoch 1814/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.0698 - mae: 6.5341 - val_loss: 81.1968 - val_mae: 6.5827\n",
            "Epoch 1815/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.6931 - mae: 6.5712 - val_loss: 81.1273 - val_mae: 6.5806\n",
            "Epoch 1816/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.0998 - mae: 6.5513 - val_loss: 81.1064 - val_mae: 6.5807\n",
            "Epoch 1817/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.7754 - mae: 6.5708 - val_loss: 81.1191 - val_mae: 6.5798\n",
            "Epoch 1818/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.5127 - mae: 6.5685 - val_loss: 81.1716 - val_mae: 6.5807\n",
            "Epoch 1819/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.9885 - mae: 6.5412 - val_loss: 81.0125 - val_mae: 6.5778\n",
            "Epoch 1820/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.3788 - mae: 6.5677 - val_loss: 81.0404 - val_mae: 6.5811\n",
            "Epoch 1821/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.9764 - mae: 6.5444 - val_loss: 81.0885 - val_mae: 6.5816\n",
            "Epoch 1822/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.2127 - mae: 6.5416 - val_loss: 81.1601 - val_mae: 6.5799\n",
            "Epoch 1823/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.2781 - mae: 6.5512 - val_loss: 80.9635 - val_mae: 6.5768\n",
            "Epoch 1824/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.1961 - mae: 6.5519 - val_loss: 81.1389 - val_mae: 6.5797\n",
            "Epoch 1825/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.0244 - mae: 6.5597 - val_loss: 81.1865 - val_mae: 6.5799\n",
            "Epoch 1826/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.2209 - mae: 6.5454 - val_loss: 81.1495 - val_mae: 6.5796\n",
            "Epoch 1827/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.4424 - mae: 6.5709 - val_loss: 81.0245 - val_mae: 6.5787\n",
            "Epoch 1828/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.5534 - mae: 6.5577 - val_loss: 80.9467 - val_mae: 6.5771\n",
            "Epoch 1829/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.1938 - mae: 6.5519 - val_loss: 80.9824 - val_mae: 6.5769\n",
            "Epoch 1830/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.9893 - mae: 6.5467 - val_loss: 80.8211 - val_mae: 6.5753\n",
            "Epoch 1831/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.1250 - mae: 6.5525 - val_loss: 80.8822 - val_mae: 6.5792\n",
            "Epoch 1832/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 79.0503 - mae: 6.5529 - val_loss: 81.0160 - val_mae: 6.5792\n",
            "Epoch 1833/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.4223 - mae: 6.5584 - val_loss: 80.9806 - val_mae: 6.5778\n",
            "Epoch 1834/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 79.0719 - mae: 6.5536 - val_loss: 80.9618 - val_mae: 6.5785\n",
            "Epoch 1835/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.9424 - mae: 6.5475 - val_loss: 80.9332 - val_mae: 6.5771\n",
            "Epoch 1836/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 79.1288 - mae: 6.5622 - val_loss: 81.0283 - val_mae: 6.5768\n",
            "Epoch 1837/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.2607 - mae: 6.5632 - val_loss: 80.9173 - val_mae: 6.5772\n",
            "Epoch 1838/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.7730 - mae: 6.5321 - val_loss: 81.0622 - val_mae: 6.5777\n",
            "Epoch 1839/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.2238 - mae: 6.5584 - val_loss: 80.9283 - val_mae: 6.5780\n",
            "Epoch 1840/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.8889 - mae: 6.5363 - val_loss: 80.7398 - val_mae: 6.5751\n",
            "Epoch 1841/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.6084 - mae: 6.5295 - val_loss: 80.8276 - val_mae: 6.5761\n",
            "Epoch 1842/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.8302 - mae: 6.5321 - val_loss: 80.7559 - val_mae: 6.5761\n",
            "Epoch 1843/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 79.6221 - mae: 6.5831 - val_loss: 80.7816 - val_mae: 6.5762\n",
            "Epoch 1844/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.0219 - mae: 6.5592 - val_loss: 80.9899 - val_mae: 6.5763\n",
            "Epoch 1845/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.9529 - mae: 6.5555 - val_loss: 80.7080 - val_mae: 6.5749\n",
            "Epoch 1846/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.2757 - mae: 6.5510 - val_loss: 80.7177 - val_mae: 6.5744\n",
            "Epoch 1847/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.7772 - mae: 6.5375 - val_loss: 80.7019 - val_mae: 6.5762\n",
            "Epoch 1848/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.9736 - mae: 6.5370 - val_loss: 80.8235 - val_mae: 6.5778\n",
            "Epoch 1849/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.7043 - mae: 6.5310 - val_loss: 80.7495 - val_mae: 6.5761\n",
            "Epoch 1850/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.6048 - mae: 6.5294 - val_loss: 80.6898 - val_mae: 6.5757\n",
            "Epoch 1851/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 79.1424 - mae: 6.5535 - val_loss: 80.5546 - val_mae: 6.5731\n",
            "Epoch 1852/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.8014 - mae: 6.5248 - val_loss: 80.7495 - val_mae: 6.5738\n",
            "Epoch 1853/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.1408 - mae: 6.5084 - val_loss: 80.6047 - val_mae: 6.5735\n",
            "Epoch 1854/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 78.1788 - mae: 6.5101 - val_loss: 80.5641 - val_mae: 6.5731\n",
            "Epoch 1855/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.9250 - mae: 6.5663 - val_loss: 80.6459 - val_mae: 6.5747\n",
            "Epoch 1856/10000\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 78.3924 - mae: 6.5192 - val_loss: 80.5464 - val_mae: 6.5738\n",
            "Epoch 1857/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.8332 - mae: 6.5481 - val_loss: 80.5866 - val_mae: 6.5745\n",
            "Epoch 1858/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.7268 - mae: 6.5352 - val_loss: 80.7648 - val_mae: 6.5763\n",
            "Epoch 1859/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.9600 - mae: 6.5592 - val_loss: 80.5751 - val_mae: 6.5760\n",
            "Epoch 1860/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.8007 - mae: 6.5374 - val_loss: 80.6659 - val_mae: 6.5733\n",
            "Epoch 1861/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.8624 - mae: 6.5471 - val_loss: 80.6146 - val_mae: 6.5720\n",
            "Epoch 1862/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.5901 - mae: 6.5494 - val_loss: 80.5631 - val_mae: 6.5736\n",
            "Epoch 1863/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.8657 - mae: 6.5393 - val_loss: 80.6965 - val_mae: 6.5723\n",
            "Epoch 1864/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.9925 - mae: 6.5519 - val_loss: 80.6538 - val_mae: 6.5749\n",
            "Epoch 1865/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.3543 - mae: 6.5358 - val_loss: 80.4455 - val_mae: 6.5735\n",
            "Epoch 1866/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.2133 - mae: 6.5318 - val_loss: 80.4498 - val_mae: 6.5730\n",
            "Epoch 1867/10000\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 78.4496 - mae: 6.5308 - val_loss: 80.5247 - val_mae: 6.5716\n",
            "Epoch 1868/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.7168 - mae: 6.5324 - val_loss: 80.5342 - val_mae: 6.5715\n",
            "Epoch 1869/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.8627 - mae: 6.5333 - val_loss: 80.5015 - val_mae: 6.5721\n",
            "Epoch 1870/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.4898 - mae: 6.5297 - val_loss: 80.5542 - val_mae: 6.5721\n",
            "Epoch 1871/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.8710 - mae: 6.5489 - val_loss: 80.6831 - val_mae: 6.5738\n",
            "Epoch 1872/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.5211 - mae: 6.5346 - val_loss: 80.4426 - val_mae: 6.5722\n",
            "Epoch 1873/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.7592 - mae: 6.5494 - val_loss: 80.4961 - val_mae: 6.5729\n",
            "Epoch 1874/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.3537 - mae: 6.5377 - val_loss: 80.5521 - val_mae: 6.5727\n",
            "Epoch 1875/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.4840 - mae: 6.5328 - val_loss: 80.5000 - val_mae: 6.5724\n",
            "Epoch 1876/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.8251 - mae: 6.5555 - val_loss: 80.2726 - val_mae: 6.5686\n",
            "Epoch 1877/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.2926 - mae: 6.5309 - val_loss: 80.3572 - val_mae: 6.5699\n",
            "Epoch 1878/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.5412 - mae: 6.5408 - val_loss: 80.3052 - val_mae: 6.5697\n",
            "Epoch 1879/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.5636 - mae: 6.5336 - val_loss: 80.5088 - val_mae: 6.5714\n",
            "Epoch 1880/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.3719 - mae: 6.5368 - val_loss: 80.4675 - val_mae: 6.5727\n",
            "Epoch 1881/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.2254 - mae: 6.5191 - val_loss: 80.3731 - val_mae: 6.5713\n",
            "Epoch 1882/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.7011 - mae: 6.5401 - val_loss: 80.3867 - val_mae: 6.5707\n",
            "Epoch 1883/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.6784 - mae: 6.5398 - val_loss: 80.2456 - val_mae: 6.5690\n",
            "Epoch 1884/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.4785 - mae: 6.5333 - val_loss: 80.3444 - val_mae: 6.5695\n",
            "Epoch 1885/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.3284 - mae: 6.5327 - val_loss: 80.3481 - val_mae: 6.5692\n",
            "Epoch 1886/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 78.1551 - mae: 6.5205 - val_loss: 80.1126 - val_mae: 6.5689\n",
            "Epoch 1887/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.0502 - mae: 6.5127 - val_loss: 80.1946 - val_mae: 6.5687\n",
            "Epoch 1888/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.6621 - mae: 6.5568 - val_loss: 80.1922 - val_mae: 6.5700\n",
            "Epoch 1889/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.2988 - mae: 6.5347 - val_loss: 80.3765 - val_mae: 6.5701\n",
            "Epoch 1890/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.4008 - mae: 6.5411 - val_loss: 80.3755 - val_mae: 6.5715\n",
            "Epoch 1891/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.9747 - mae: 6.5135 - val_loss: 80.4121 - val_mae: 6.5704\n",
            "Epoch 1892/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.6030 - mae: 6.5557 - val_loss: 80.3006 - val_mae: 6.5699\n",
            "Epoch 1893/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.5788 - mae: 6.5541 - val_loss: 80.2222 - val_mae: 6.5701\n",
            "Epoch 1894/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.6010 - mae: 6.5292 - val_loss: 80.1963 - val_mae: 6.5690\n",
            "Epoch 1895/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.6577 - mae: 6.5537 - val_loss: 80.2630 - val_mae: 6.5682\n",
            "Epoch 1896/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.5519 - mae: 6.5477 - val_loss: 80.1391 - val_mae: 6.5682\n",
            "Epoch 1897/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.5176 - mae: 6.5409 - val_loss: 80.2834 - val_mae: 6.5700\n",
            "Epoch 1898/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.4425 - mae: 6.5319 - val_loss: 80.4269 - val_mae: 6.5705\n",
            "Epoch 1899/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.4882 - mae: 6.5358 - val_loss: 80.0881 - val_mae: 6.5676\n",
            "Epoch 1900/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.2224 - mae: 6.5323 - val_loss: 80.2284 - val_mae: 6.5683\n",
            "Epoch 1901/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.1642 - mae: 6.5196 - val_loss: 80.2186 - val_mae: 6.5694\n",
            "Epoch 1902/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.1710 - mae: 6.5310 - val_loss: 80.1763 - val_mae: 6.5691\n",
            "Epoch 1903/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.6044 - mae: 6.5322 - val_loss: 80.0500 - val_mae: 6.5672\n",
            "Epoch 1904/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.7758 - mae: 6.5678 - val_loss: 80.3878 - val_mae: 6.5687\n",
            "Epoch 1905/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.4757 - mae: 6.5553 - val_loss: 80.1565 - val_mae: 6.5668\n",
            "Epoch 1906/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.3038 - mae: 6.5355 - val_loss: 80.1399 - val_mae: 6.5679\n",
            "Epoch 1907/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.3729 - mae: 6.5249 - val_loss: 80.1644 - val_mae: 6.5696\n",
            "Epoch 1908/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.2997 - mae: 6.5329 - val_loss: 80.3659 - val_mae: 6.5698\n",
            "Epoch 1909/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.0900 - mae: 6.5240 - val_loss: 80.1566 - val_mae: 6.5686\n",
            "Epoch 1910/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.0679 - mae: 6.5258 - val_loss: 80.2897 - val_mae: 6.5700\n",
            "Epoch 1911/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.9833 - mae: 6.5265 - val_loss: 80.1330 - val_mae: 6.5668\n",
            "Epoch 1912/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 78.4547 - mae: 6.5496 - val_loss: 80.0861 - val_mae: 6.5679\n",
            "Epoch 1913/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.1535 - mae: 6.5284 - val_loss: 79.9654 - val_mae: 6.5665\n",
            "Epoch 1914/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.0442 - mae: 6.5170 - val_loss: 80.2655 - val_mae: 6.5694\n",
            "Epoch 1915/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.5561 - mae: 6.5582 - val_loss: 79.9254 - val_mae: 6.5660\n",
            "Epoch 1916/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.9502 - mae: 6.5187 - val_loss: 79.9261 - val_mae: 6.5658\n",
            "Epoch 1917/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.7875 - mae: 6.5168 - val_loss: 79.9551 - val_mae: 6.5660\n",
            "Epoch 1918/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.8512 - mae: 6.5205 - val_loss: 80.2101 - val_mae: 6.5671\n",
            "Epoch 1919/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.6582 - mae: 6.5243 - val_loss: 80.0893 - val_mae: 6.5669\n",
            "Epoch 1920/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.1051 - mae: 6.5376 - val_loss: 80.0426 - val_mae: 6.5664\n",
            "Epoch 1921/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.6602 - mae: 6.5299 - val_loss: 79.7916 - val_mae: 6.5649\n",
            "Epoch 1922/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.4065 - mae: 6.5462 - val_loss: 79.8509 - val_mae: 6.5654\n",
            "Epoch 1923/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.1748 - mae: 6.5286 - val_loss: 79.9367 - val_mae: 6.5640\n",
            "Epoch 1924/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.2284 - mae: 6.5483 - val_loss: 79.9707 - val_mae: 6.5676\n",
            "Epoch 1925/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.3842 - mae: 6.5309 - val_loss: 79.9332 - val_mae: 6.5662\n",
            "Epoch 1926/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.9151 - mae: 6.5402 - val_loss: 79.9458 - val_mae: 6.5653\n",
            "Epoch 1927/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.8134 - mae: 6.5393 - val_loss: 79.9478 - val_mae: 6.5666\n",
            "Epoch 1928/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.0931 - mae: 6.5428 - val_loss: 80.1171 - val_mae: 6.5661\n",
            "Epoch 1929/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.8060 - mae: 6.5330 - val_loss: 79.8609 - val_mae: 6.5646\n",
            "Epoch 1930/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.7757 - mae: 6.5275 - val_loss: 79.8829 - val_mae: 6.5668\n",
            "Epoch 1931/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 78.1753 - mae: 6.5515 - val_loss: 79.8466 - val_mae: 6.5644\n",
            "Epoch 1932/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.8030 - mae: 6.5181 - val_loss: 79.9657 - val_mae: 6.5663\n",
            "Epoch 1933/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.0278 - mae: 6.5496 - val_loss: 79.8211 - val_mae: 6.5633\n",
            "Epoch 1934/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.9495 - mae: 6.5456 - val_loss: 79.8491 - val_mae: 6.5644\n",
            "Epoch 1935/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.9944 - mae: 6.5299 - val_loss: 79.7338 - val_mae: 6.5653\n",
            "Epoch 1936/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.2111 - mae: 6.5385 - val_loss: 79.7371 - val_mae: 6.5638\n",
            "Epoch 1937/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.9582 - mae: 6.5332 - val_loss: 79.8514 - val_mae: 6.5647\n",
            "Epoch 1938/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.7890 - mae: 6.5307 - val_loss: 79.7323 - val_mae: 6.5649\n",
            "Epoch 1939/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.0680 - mae: 6.5370 - val_loss: 79.7355 - val_mae: 6.5638\n",
            "Epoch 1940/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 77.8464 - mae: 6.5215 - val_loss: 79.7439 - val_mae: 6.5647\n",
            "Epoch 1941/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.9346 - mae: 6.5191 - val_loss: 79.8537 - val_mae: 6.5645\n",
            "Epoch 1942/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.7604 - mae: 6.5194 - val_loss: 79.7303 - val_mae: 6.5650\n",
            "Epoch 1943/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.4503 - mae: 6.5123 - val_loss: 79.7189 - val_mae: 6.5634\n",
            "Epoch 1944/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.6947 - mae: 6.5338 - val_loss: 80.0141 - val_mae: 6.5654\n",
            "Epoch 1945/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 77.8529 - mae: 6.5274 - val_loss: 79.8319 - val_mae: 6.5639\n",
            "Epoch 1946/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.1500 - mae: 6.5582 - val_loss: 79.7541 - val_mae: 6.5655\n",
            "Epoch 1947/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.9184 - mae: 6.5280 - val_loss: 79.8047 - val_mae: 6.5642\n",
            "Epoch 1948/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.8740 - mae: 6.5413 - val_loss: 79.7332 - val_mae: 6.5627\n",
            "Epoch 1949/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.0920 - mae: 6.5514 - val_loss: 79.6411 - val_mae: 6.5632\n",
            "Epoch 1950/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.7849 - mae: 6.5196 - val_loss: 79.4306 - val_mae: 6.5593\n",
            "Epoch 1951/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.8869 - mae: 6.5424 - val_loss: 79.6700 - val_mae: 6.5648\n",
            "Epoch 1952/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.6327 - mae: 6.5231 - val_loss: 79.7158 - val_mae: 6.5635\n",
            "Epoch 1953/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.0561 - mae: 6.5442 - val_loss: 79.6034 - val_mae: 6.5631\n",
            "Epoch 1954/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.6753 - mae: 6.5232 - val_loss: 79.6491 - val_mae: 6.5612\n",
            "Epoch 1955/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.8736 - mae: 6.5261 - val_loss: 79.5667 - val_mae: 6.5617\n",
            "Epoch 1956/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 77.4683 - mae: 6.5093 - val_loss: 79.7155 - val_mae: 6.5632\n",
            "Epoch 1957/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 78.1041 - mae: 6.5425 - val_loss: 79.6935 - val_mae: 6.5615\n",
            "Epoch 1958/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.8674 - mae: 6.5449 - val_loss: 79.5742 - val_mae: 6.5607\n",
            "Epoch 1959/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.9285 - mae: 6.5404 - val_loss: 79.6266 - val_mae: 6.5611\n",
            "Epoch 1960/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.6215 - mae: 6.5280 - val_loss: 79.6701 - val_mae: 6.5620\n",
            "Epoch 1961/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 78.1853 - mae: 6.5525 - val_loss: 79.5628 - val_mae: 6.5588\n",
            "Epoch 1962/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.6241 - mae: 6.5107 - val_loss: 79.5031 - val_mae: 6.5611\n",
            "Epoch 1963/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.4732 - mae: 6.5083 - val_loss: 79.5927 - val_mae: 6.5631\n",
            "Epoch 1964/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.7713 - mae: 6.5456 - val_loss: 79.4269 - val_mae: 6.5608\n",
            "Epoch 1965/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.2266 - mae: 6.5546 - val_loss: 79.4886 - val_mae: 6.5603\n",
            "Epoch 1966/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.7120 - mae: 6.5277 - val_loss: 79.5995 - val_mae: 6.5617\n",
            "Epoch 1967/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.4709 - mae: 6.5234 - val_loss: 79.6263 - val_mae: 6.5617\n",
            "Epoch 1968/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.4342 - mae: 6.5197 - val_loss: 79.5234 - val_mae: 6.5613\n",
            "Epoch 1969/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.8574 - mae: 6.5326 - val_loss: 79.4983 - val_mae: 6.5610\n",
            "Epoch 1970/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.8878 - mae: 6.5400 - val_loss: 79.4572 - val_mae: 6.5603\n",
            "Epoch 1971/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.8672 - mae: 6.5316 - val_loss: 79.4715 - val_mae: 6.5625\n",
            "Epoch 1972/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.5638 - mae: 6.5266 - val_loss: 79.4397 - val_mae: 6.5613\n",
            "Epoch 1973/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.4164 - mae: 6.5367 - val_loss: 79.5584 - val_mae: 6.5625\n",
            "Epoch 1974/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.5398 - mae: 6.5259 - val_loss: 79.2983 - val_mae: 6.5594\n",
            "Epoch 1975/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.7610 - mae: 6.5231 - val_loss: 79.5368 - val_mae: 6.5606\n",
            "Epoch 1976/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.2045 - mae: 6.5164 - val_loss: 79.4184 - val_mae: 6.5613\n",
            "Epoch 1977/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.5905 - mae: 6.5246 - val_loss: 79.4399 - val_mae: 6.5614\n",
            "Epoch 1978/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.5939 - mae: 6.5280 - val_loss: 79.3006 - val_mae: 6.5594\n",
            "Epoch 1979/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.4206 - mae: 6.5206 - val_loss: 79.5127 - val_mae: 6.5599\n",
            "Epoch 1980/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.8273 - mae: 6.5455 - val_loss: 79.5174 - val_mae: 6.5612\n",
            "Epoch 1981/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.2840 - mae: 6.5140 - val_loss: 79.3785 - val_mae: 6.5603\n",
            "Epoch 1982/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.3566 - mae: 6.5101 - val_loss: 79.3964 - val_mae: 6.5584\n",
            "Epoch 1983/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.8735 - mae: 6.5437 - val_loss: 79.3150 - val_mae: 6.5604\n",
            "Epoch 1984/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9774 - mae: 6.4962 - val_loss: 79.3321 - val_mae: 6.5593\n",
            "Epoch 1985/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.4930 - mae: 6.5233 - val_loss: 79.2727 - val_mae: 6.5601\n",
            "Epoch 1986/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.5825 - mae: 6.5485 - val_loss: 79.4431 - val_mae: 6.5610\n",
            "Epoch 1987/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.2631 - mae: 6.5283 - val_loss: 79.2626 - val_mae: 6.5590\n",
            "Epoch 1988/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.6939 - mae: 6.5314 - val_loss: 79.4354 - val_mae: 6.5607\n",
            "Epoch 1989/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.6528 - mae: 6.5102 - val_loss: 79.2429 - val_mae: 6.5583\n",
            "Epoch 1990/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.8590 - mae: 6.5456 - val_loss: 79.3625 - val_mae: 6.5598\n",
            "Epoch 1991/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.1312 - mae: 6.5241 - val_loss: 79.1868 - val_mae: 6.5574\n",
            "Epoch 1992/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.5508 - mae: 6.5469 - val_loss: 79.3110 - val_mae: 6.5572\n",
            "Epoch 1993/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.3441 - mae: 6.5205 - val_loss: 79.4369 - val_mae: 6.5590\n",
            "Epoch 1994/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.5293 - mae: 6.5066 - val_loss: 79.3283 - val_mae: 6.5580\n",
            "Epoch 1995/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.1466 - mae: 6.5075 - val_loss: 79.3552 - val_mae: 6.5592\n",
            "Epoch 1996/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.4741 - mae: 6.5323 - val_loss: 79.3797 - val_mae: 6.5594\n",
            "Epoch 1997/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.8748 - mae: 6.5567 - val_loss: 79.2068 - val_mae: 6.5589\n",
            "Epoch 1998/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 78.1803 - mae: 6.5450 - val_loss: 79.2823 - val_mae: 6.5589\n",
            "Epoch 1999/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.3641 - mae: 6.5216 - val_loss: 79.1282 - val_mae: 6.5595\n",
            "Epoch 2000/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.7754 - mae: 6.5424 - val_loss: 79.2982 - val_mae: 6.5589\n",
            "Epoch 2001/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.4950 - mae: 6.5299 - val_loss: 79.1651 - val_mae: 6.5587\n",
            "Epoch 2002/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.3464 - mae: 6.5143 - val_loss: 79.0685 - val_mae: 6.5576\n",
            "Epoch 2003/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.9636 - mae: 6.4951 - val_loss: 79.0951 - val_mae: 6.5583\n",
            "Epoch 2004/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.3933 - mae: 6.5322 - val_loss: 79.2002 - val_mae: 6.5577\n",
            "Epoch 2005/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.3380 - mae: 6.5268 - val_loss: 79.1855 - val_mae: 6.5567\n",
            "Epoch 2006/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 77.3498 - mae: 6.5285 - val_loss: 79.2363 - val_mae: 6.5579\n",
            "Epoch 2007/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.3639 - mae: 6.5413 - val_loss: 79.0177 - val_mae: 6.5571\n",
            "Epoch 2008/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.1747 - mae: 6.5257 - val_loss: 79.0947 - val_mae: 6.5558\n",
            "Epoch 2009/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.1285 - mae: 6.5072 - val_loss: 79.2316 - val_mae: 6.5587\n",
            "Epoch 2010/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.9646 - mae: 6.5205 - val_loss: 78.9675 - val_mae: 6.5572\n",
            "Epoch 2011/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.8175 - mae: 6.4981 - val_loss: 79.0053 - val_mae: 6.5575\n",
            "Epoch 2012/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9903 - mae: 6.5041 - val_loss: 79.0948 - val_mae: 6.5570\n",
            "Epoch 2013/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.1525 - mae: 6.5180 - val_loss: 78.9542 - val_mae: 6.5561\n",
            "Epoch 2014/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.2222 - mae: 6.5302 - val_loss: 79.1269 - val_mae: 6.5574\n",
            "Epoch 2015/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.1666 - mae: 6.5314 - val_loss: 79.0996 - val_mae: 6.5577\n",
            "Epoch 2016/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.3801 - mae: 6.5315 - val_loss: 79.0737 - val_mae: 6.5584\n",
            "Epoch 2017/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.4050 - mae: 6.5215 - val_loss: 79.0973 - val_mae: 6.5567\n",
            "Epoch 2018/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.4476 - mae: 6.5400 - val_loss: 79.0605 - val_mae: 6.5579\n",
            "Epoch 2019/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.4356 - mae: 6.5375 - val_loss: 78.9899 - val_mae: 6.5576\n",
            "Epoch 2020/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9923 - mae: 6.5172 - val_loss: 79.0840 - val_mae: 6.5574\n",
            "Epoch 2021/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.3667 - mae: 6.5371 - val_loss: 79.0779 - val_mae: 6.5569\n",
            "Epoch 2022/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.5314 - mae: 6.5420 - val_loss: 79.0365 - val_mae: 6.5561\n",
            "Epoch 2023/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.2632 - mae: 6.5218 - val_loss: 79.0580 - val_mae: 6.5552\n",
            "Epoch 2024/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.5272 - mae: 6.5324 - val_loss: 78.9716 - val_mae: 6.5562\n",
            "Epoch 2025/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.3010 - mae: 6.5322 - val_loss: 79.0088 - val_mae: 6.5567\n",
            "Epoch 2026/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.1788 - mae: 6.5321 - val_loss: 78.8321 - val_mae: 6.5559\n",
            "Epoch 2027/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.5202 - mae: 6.5413 - val_loss: 79.0317 - val_mae: 6.5551\n",
            "Epoch 2028/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.2084 - mae: 6.5383 - val_loss: 78.9801 - val_mae: 6.5575\n",
            "Epoch 2029/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9306 - mae: 6.5166 - val_loss: 78.9860 - val_mae: 6.5558\n",
            "Epoch 2030/10000\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 76.6295 - mae: 6.4983 - val_loss: 78.9601 - val_mae: 6.5576\n",
            "Epoch 2031/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.3687 - mae: 6.5444 - val_loss: 78.7995 - val_mae: 6.5547\n",
            "Epoch 2032/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.2213 - mae: 6.5365 - val_loss: 78.8827 - val_mae: 6.5559\n",
            "Epoch 2033/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.1022 - mae: 6.5346 - val_loss: 78.9667 - val_mae: 6.5564\n",
            "Epoch 2034/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.0768 - mae: 6.5280 - val_loss: 78.8788 - val_mae: 6.5559\n",
            "Epoch 2035/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.3000 - mae: 6.5365 - val_loss: 79.0083 - val_mae: 6.5548\n",
            "Epoch 2036/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 77.4060 - mae: 6.5376 - val_loss: 78.9003 - val_mae: 6.5551\n",
            "Epoch 2037/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9237 - mae: 6.5184 - val_loss: 78.7894 - val_mae: 6.5552\n",
            "Epoch 2038/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7825 - mae: 6.5015 - val_loss: 78.9310 - val_mae: 6.5545\n",
            "Epoch 2039/10000\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 77.0136 - mae: 6.5087 - val_loss: 78.8888 - val_mae: 6.5545\n",
            "Epoch 2040/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.8156 - mae: 6.5022 - val_loss: 78.6790 - val_mae: 6.5559\n",
            "Epoch 2041/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7036 - mae: 6.5029 - val_loss: 78.8148 - val_mae: 6.5544\n",
            "Epoch 2042/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.2723 - mae: 6.5170 - val_loss: 78.7940 - val_mae: 6.5545\n",
            "Epoch 2043/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.0108 - mae: 6.5285 - val_loss: 78.6700 - val_mae: 6.5538\n",
            "Epoch 2044/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.7425 - mae: 6.5083 - val_loss: 78.8126 - val_mae: 6.5527\n",
            "Epoch 2045/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.4688 - mae: 6.5499 - val_loss: 78.8812 - val_mae: 6.5551\n",
            "Epoch 2046/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.8163 - mae: 6.5248 - val_loss: 78.8355 - val_mae: 6.5538\n",
            "Epoch 2047/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.9457 - mae: 6.5349 - val_loss: 78.8026 - val_mae: 6.5555\n",
            "Epoch 2048/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.3161 - mae: 6.5268 - val_loss: 78.7829 - val_mae: 6.5560\n",
            "Epoch 2049/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8566 - mae: 6.5165 - val_loss: 78.8053 - val_mae: 6.5546\n",
            "Epoch 2050/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8889 - mae: 6.5194 - val_loss: 78.5640 - val_mae: 6.5539\n",
            "Epoch 2051/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.5457 - mae: 6.5414 - val_loss: 78.6301 - val_mae: 6.5526\n",
            "Epoch 2052/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.9622 - mae: 6.5308 - val_loss: 78.8402 - val_mae: 6.5545\n",
            "Epoch 2053/10000\n",
            "500/500 [==============================] - 3s 6ms/step - loss: 76.6281 - mae: 6.5141 - val_loss: 78.6124 - val_mae: 6.5546\n",
            "Epoch 2054/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.2795 - mae: 6.5373 - val_loss: 78.6884 - val_mae: 6.5534\n",
            "Epoch 2055/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.0279 - mae: 6.5214 - val_loss: 78.7620 - val_mae: 6.5537\n",
            "Epoch 2056/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5742 - mae: 6.5052 - val_loss: 78.7042 - val_mae: 6.5526\n",
            "Epoch 2057/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.5044 - mae: 6.5010 - val_loss: 78.5911 - val_mae: 6.5553\n",
            "Epoch 2058/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.7012 - mae: 6.5207 - val_loss: 78.6061 - val_mae: 6.5529\n",
            "Epoch 2059/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9620 - mae: 6.5304 - val_loss: 78.6636 - val_mae: 6.5531\n",
            "Epoch 2060/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8375 - mae: 6.5291 - val_loss: 78.6980 - val_mae: 6.5527\n",
            "Epoch 2061/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.6516 - mae: 6.5051 - val_loss: 78.6846 - val_mae: 6.5536\n",
            "Epoch 2062/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.0111 - mae: 6.5254 - val_loss: 78.8188 - val_mae: 6.5532\n",
            "Epoch 2063/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.9174 - mae: 6.5230 - val_loss: 78.6082 - val_mae: 6.5515\n",
            "Epoch 2064/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9482 - mae: 6.5515 - val_loss: 78.7276 - val_mae: 6.5528\n",
            "Epoch 2065/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.6957 - mae: 6.5128 - val_loss: 78.5214 - val_mae: 6.5539\n",
            "Epoch 2066/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5733 - mae: 6.5155 - val_loss: 78.6399 - val_mae: 6.5516\n",
            "Epoch 2067/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9519 - mae: 6.5083 - val_loss: 78.5603 - val_mae: 6.5531\n",
            "Epoch 2068/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 77.0043 - mae: 6.5147 - val_loss: 78.4858 - val_mae: 6.5537\n",
            "Epoch 2069/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.8267 - mae: 6.5215 - val_loss: 78.3753 - val_mae: 6.5518\n",
            "Epoch 2070/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9331 - mae: 6.5293 - val_loss: 78.4112 - val_mae: 6.5525\n",
            "Epoch 2071/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.0636 - mae: 6.5269 - val_loss: 78.4476 - val_mae: 6.5524\n",
            "Epoch 2072/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7275 - mae: 6.5074 - val_loss: 78.4791 - val_mae: 6.5525\n",
            "Epoch 2073/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8301 - mae: 6.5289 - val_loss: 78.3741 - val_mae: 6.5534\n",
            "Epoch 2074/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.7554 - mae: 6.5179 - val_loss: 78.3501 - val_mae: 6.5514\n",
            "Epoch 2075/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9437 - mae: 6.5314 - val_loss: 78.5342 - val_mae: 6.5536\n",
            "Epoch 2076/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8899 - mae: 6.5313 - val_loss: 78.4870 - val_mae: 6.5533\n",
            "Epoch 2077/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 77.0021 - mae: 6.5130 - val_loss: 78.4262 - val_mae: 6.5526\n",
            "Epoch 2078/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.4045 - mae: 6.4963 - val_loss: 78.3575 - val_mae: 6.5520\n",
            "Epoch 2079/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.4565 - mae: 6.5087 - val_loss: 78.5657 - val_mae: 6.5516\n",
            "Epoch 2080/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8137 - mae: 6.5168 - val_loss: 78.4441 - val_mae: 6.5500\n",
            "Epoch 2081/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.9899 - mae: 6.5403 - val_loss: 78.5721 - val_mae: 6.5530\n",
            "Epoch 2082/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.0462 - mae: 6.5385 - val_loss: 78.6846 - val_mae: 6.5531\n",
            "Epoch 2083/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3590 - mae: 6.4883 - val_loss: 78.5650 - val_mae: 6.5512\n",
            "Epoch 2084/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.5728 - mae: 6.5147 - val_loss: 78.3615 - val_mae: 6.5529\n",
            "Epoch 2085/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5708 - mae: 6.5166 - val_loss: 78.4571 - val_mae: 6.5504\n",
            "Epoch 2086/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8683 - mae: 6.5277 - val_loss: 78.5493 - val_mae: 6.5527\n",
            "Epoch 2087/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.6651 - mae: 6.5196 - val_loss: 78.3234 - val_mae: 6.5524\n",
            "Epoch 2088/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.6635 - mae: 6.5206 - val_loss: 78.4303 - val_mae: 6.5520\n",
            "Epoch 2089/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5046 - mae: 6.5075 - val_loss: 78.3730 - val_mae: 6.5518\n",
            "Epoch 2090/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8577 - mae: 6.5207 - val_loss: 78.4224 - val_mae: 6.5519\n",
            "Epoch 2091/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.5631 - mae: 6.5142 - val_loss: 78.4384 - val_mae: 6.5531\n",
            "Epoch 2092/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5858 - mae: 6.5110 - val_loss: 78.3508 - val_mae: 6.5514\n",
            "Epoch 2093/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5617 - mae: 6.5032 - val_loss: 78.4137 - val_mae: 6.5515\n",
            "Epoch 2094/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.3076 - mae: 6.5095 - val_loss: 78.2400 - val_mae: 6.5508\n",
            "Epoch 2095/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.6020 - mae: 6.5197 - val_loss: 78.4767 - val_mae: 6.5501\n",
            "Epoch 2096/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.5544 - mae: 6.5057 - val_loss: 78.2914 - val_mae: 6.5512\n",
            "Epoch 2097/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7838 - mae: 6.5361 - val_loss: 78.1885 - val_mae: 6.5517\n",
            "Epoch 2098/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7536 - mae: 6.5266 - val_loss: 78.3632 - val_mae: 6.5521\n",
            "Epoch 2099/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5465 - mae: 6.5166 - val_loss: 78.3138 - val_mae: 6.5494\n",
            "Epoch 2100/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.5731 - mae: 6.5251 - val_loss: 78.3302 - val_mae: 6.5503\n",
            "Epoch 2101/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3315 - mae: 6.5057 - val_loss: 78.2638 - val_mae: 6.5502\n",
            "Epoch 2102/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8964 - mae: 6.5318 - val_loss: 78.3817 - val_mae: 6.5512\n",
            "Epoch 2103/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.8918 - mae: 6.5362 - val_loss: 78.2982 - val_mae: 6.5495\n",
            "Epoch 2104/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.6120 - mae: 6.5296 - val_loss: 78.3360 - val_mae: 6.5531\n",
            "Epoch 2105/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.8328 - mae: 6.5282 - val_loss: 78.3494 - val_mae: 6.5520\n",
            "Epoch 2106/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7781 - mae: 6.5305 - val_loss: 78.1922 - val_mae: 6.5518\n",
            "Epoch 2107/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.4129 - mae: 6.5181 - val_loss: 78.1762 - val_mae: 6.5531\n",
            "Epoch 2108/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 77.0631 - mae: 6.5473 - val_loss: 78.1503 - val_mae: 6.5517\n",
            "Epoch 2109/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7414 - mae: 6.5170 - val_loss: 78.1163 - val_mae: 6.5512\n",
            "Epoch 2110/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9606 - mae: 6.4818 - val_loss: 78.3327 - val_mae: 6.5498\n",
            "Epoch 2111/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.2844 - mae: 6.5071 - val_loss: 78.1224 - val_mae: 6.5507\n",
            "Epoch 2112/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3527 - mae: 6.4978 - val_loss: 78.3172 - val_mae: 6.5523\n",
            "Epoch 2113/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.1935 - mae: 6.5146 - val_loss: 78.1269 - val_mae: 6.5499\n",
            "Epoch 2114/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3889 - mae: 6.5240 - val_loss: 77.9651 - val_mae: 6.5497\n",
            "Epoch 2115/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.2607 - mae: 6.5126 - val_loss: 78.3077 - val_mae: 6.5496\n",
            "Epoch 2116/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 76.6042 - mae: 6.5255 - val_loss: 78.2927 - val_mae: 6.5503\n",
            "Epoch 2117/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.1980 - mae: 6.5046 - val_loss: 78.2307 - val_mae: 6.5507\n",
            "Epoch 2118/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.5934 - mae: 6.5349 - val_loss: 78.1110 - val_mae: 6.5507\n",
            "Epoch 2119/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.8169 - mae: 6.5288 - val_loss: 78.1479 - val_mae: 6.5515\n",
            "Epoch 2120/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.4642 - mae: 6.5191 - val_loss: 78.2169 - val_mae: 6.5496\n",
            "Epoch 2121/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7675 - mae: 6.5261 - val_loss: 78.1619 - val_mae: 6.5512\n",
            "Epoch 2122/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.2891 - mae: 6.5164 - val_loss: 78.0581 - val_mae: 6.5502\n",
            "Epoch 2123/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.1620 - mae: 6.5015 - val_loss: 78.0578 - val_mae: 6.5496\n",
            "Epoch 2124/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3000 - mae: 6.5097 - val_loss: 78.0292 - val_mae: 6.5507\n",
            "Epoch 2125/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.2625 - mae: 6.5134 - val_loss: 78.0257 - val_mae: 6.5505\n",
            "Epoch 2126/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.2125 - mae: 6.5143 - val_loss: 78.0429 - val_mae: 6.5510\n",
            "Epoch 2127/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5130 - mae: 6.5307 - val_loss: 78.1798 - val_mae: 6.5503\n",
            "Epoch 2128/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3575 - mae: 6.5142 - val_loss: 78.1288 - val_mae: 6.5503\n",
            "Epoch 2129/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.4229 - mae: 6.5141 - val_loss: 77.9449 - val_mae: 6.5493\n",
            "Epoch 2130/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.7996 - mae: 6.4944 - val_loss: 78.0655 - val_mae: 6.5508\n",
            "Epoch 2131/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.5883 - mae: 6.5296 - val_loss: 77.9329 - val_mae: 6.5506\n",
            "Epoch 2132/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.4609 - mae: 6.5195 - val_loss: 78.0832 - val_mae: 6.5494\n",
            "Epoch 2133/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.2919 - mae: 6.5084 - val_loss: 78.1184 - val_mae: 6.5488\n",
            "Epoch 2134/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.1907 - mae: 6.5130 - val_loss: 77.9570 - val_mae: 6.5493\n",
            "Epoch 2135/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.0507 - mae: 6.5080 - val_loss: 77.8968 - val_mae: 6.5487\n",
            "Epoch 2136/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 75.8812 - mae: 6.5076 - val_loss: 78.0850 - val_mae: 6.5495\n",
            "Epoch 2137/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.6954 - mae: 6.5176 - val_loss: 78.0236 - val_mae: 6.5489\n",
            "Epoch 2138/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.1310 - mae: 6.5146 - val_loss: 77.9834 - val_mae: 6.5487\n",
            "Epoch 2139/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.9264 - mae: 6.5005 - val_loss: 77.8617 - val_mae: 6.5513\n",
            "Epoch 2140/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.2254 - mae: 6.5164 - val_loss: 77.9355 - val_mae: 6.5490\n",
            "Epoch 2141/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.0580 - mae: 6.5057 - val_loss: 77.9636 - val_mae: 6.5485\n",
            "Epoch 2142/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3007 - mae: 6.5010 - val_loss: 77.9462 - val_mae: 6.5497\n",
            "Epoch 2143/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9105 - mae: 6.4958 - val_loss: 77.8887 - val_mae: 6.5503\n",
            "Epoch 2144/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.2451 - mae: 6.5194 - val_loss: 78.0165 - val_mae: 6.5495\n",
            "Epoch 2145/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.7920 - mae: 6.5019 - val_loss: 77.9589 - val_mae: 6.5493\n",
            "Epoch 2146/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.4457 - mae: 6.5283 - val_loss: 77.9043 - val_mae: 6.5491\n",
            "Epoch 2147/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.7321 - mae: 6.5297 - val_loss: 77.8012 - val_mae: 6.5501\n",
            "Epoch 2148/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3363 - mae: 6.5269 - val_loss: 77.8265 - val_mae: 6.5489\n",
            "Epoch 2149/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3995 - mae: 6.5162 - val_loss: 77.9009 - val_mae: 6.5490\n",
            "Epoch 2150/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.1692 - mae: 6.5245 - val_loss: 77.8914 - val_mae: 6.5485\n",
            "Epoch 2151/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5722 - mae: 6.5205 - val_loss: 77.6900 - val_mae: 6.5489\n",
            "Epoch 2152/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.1923 - mae: 6.5078 - val_loss: 77.9666 - val_mae: 6.5471\n",
            "Epoch 2153/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.0066 - mae: 6.5191 - val_loss: 77.8490 - val_mae: 6.5495\n",
            "Epoch 2154/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.5586 - mae: 6.5341 - val_loss: 77.8095 - val_mae: 6.5488\n",
            "Epoch 2155/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.4604 - mae: 6.5196 - val_loss: 77.8335 - val_mae: 6.5480\n",
            "Epoch 2156/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 75.6570 - mae: 6.4778 - val_loss: 77.7763 - val_mae: 6.5508\n",
            "Epoch 2157/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 75.7346 - mae: 6.4792 - val_loss: 77.9145 - val_mae: 6.5490\n",
            "Epoch 2158/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.1786 - mae: 6.5058 - val_loss: 77.7682 - val_mae: 6.5474\n",
            "Epoch 2159/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0973 - mae: 6.5115 - val_loss: 77.8030 - val_mae: 6.5493\n",
            "Epoch 2160/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3147 - mae: 6.5272 - val_loss: 77.6867 - val_mae: 6.5488\n",
            "Epoch 2161/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3527 - mae: 6.5316 - val_loss: 77.8753 - val_mae: 6.5493\n",
            "Epoch 2162/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6859 - mae: 6.4839 - val_loss: 77.7371 - val_mae: 6.5487\n",
            "Epoch 2163/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.2264 - mae: 6.5320 - val_loss: 77.9160 - val_mae: 6.5479\n",
            "Epoch 2164/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6048 - mae: 6.4773 - val_loss: 77.7582 - val_mae: 6.5494\n",
            "Epoch 2165/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.1472 - mae: 6.5223 - val_loss: 77.7472 - val_mae: 6.5489\n",
            "Epoch 2166/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.4398 - mae: 6.5283 - val_loss: 77.6217 - val_mae: 6.5476\n",
            "Epoch 2167/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 75.8378 - mae: 6.5142 - val_loss: 77.7761 - val_mae: 6.5483\n",
            "Epoch 2168/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.1024 - mae: 6.5256 - val_loss: 77.7503 - val_mae: 6.5464\n",
            "Epoch 2169/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.2938 - mae: 6.5237 - val_loss: 77.6946 - val_mae: 6.5494\n",
            "Epoch 2170/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.2185 - mae: 6.5235 - val_loss: 77.6972 - val_mae: 6.5473\n",
            "Epoch 2171/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.8139 - mae: 6.5128 - val_loss: 77.8681 - val_mae: 6.5499\n",
            "Epoch 2172/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0909 - mae: 6.5206 - val_loss: 77.6482 - val_mae: 6.5501\n",
            "Epoch 2173/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9000 - mae: 6.5005 - val_loss: 77.6430 - val_mae: 6.5492\n",
            "Epoch 2174/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0589 - mae: 6.5077 - val_loss: 77.7465 - val_mae: 6.5470\n",
            "Epoch 2175/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0792 - mae: 6.5143 - val_loss: 77.6389 - val_mae: 6.5488\n",
            "Epoch 2176/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.1068 - mae: 6.5225 - val_loss: 77.6025 - val_mae: 6.5478\n",
            "Epoch 2177/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.9753 - mae: 6.5242 - val_loss: 77.6687 - val_mae: 6.5469\n",
            "Epoch 2178/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.8860 - mae: 6.5111 - val_loss: 77.6419 - val_mae: 6.5473\n",
            "Epoch 2179/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.2053 - mae: 6.5106 - val_loss: 77.5610 - val_mae: 6.5488\n",
            "Epoch 2180/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.2662 - mae: 6.5307 - val_loss: 77.6411 - val_mae: 6.5462\n",
            "Epoch 2181/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9730 - mae: 6.5098 - val_loss: 77.6095 - val_mae: 6.5470\n",
            "Epoch 2182/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.8301 - mae: 6.5093 - val_loss: 77.5903 - val_mae: 6.5468\n",
            "Epoch 2183/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 75.8411 - mae: 6.5235 - val_loss: 77.7646 - val_mae: 6.5472\n",
            "Epoch 2184/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.1196 - mae: 6.5215 - val_loss: 77.4835 - val_mae: 6.5485\n",
            "Epoch 2185/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.7072 - mae: 6.4973 - val_loss: 77.5357 - val_mae: 6.5485\n",
            "Epoch 2186/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9949 - mae: 6.5075 - val_loss: 77.5907 - val_mae: 6.5475\n",
            "Epoch 2187/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.7741 - mae: 6.4943 - val_loss: 77.5459 - val_mae: 6.5480\n",
            "Epoch 2188/10000\n",
            "500/500 [==============================] - 5s 9ms/step - loss: 75.9899 - mae: 6.5128 - val_loss: 77.5828 - val_mae: 6.5488\n",
            "Epoch 2189/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0648 - mae: 6.5253 - val_loss: 77.4969 - val_mae: 6.5477\n",
            "Epoch 2190/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 75.8432 - mae: 6.4826 - val_loss: 77.5714 - val_mae: 6.5469\n",
            "Epoch 2191/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9579 - mae: 6.5251 - val_loss: 77.5569 - val_mae: 6.5478\n",
            "Epoch 2192/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.9570 - mae: 6.5128 - val_loss: 77.3736 - val_mae: 6.5481\n",
            "Epoch 2193/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.9249 - mae: 6.5039 - val_loss: 77.5127 - val_mae: 6.5480\n",
            "Epoch 2194/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.0156 - mae: 6.5132 - val_loss: 77.5648 - val_mae: 6.5461\n",
            "Epoch 2195/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.8574 - mae: 6.5183 - val_loss: 77.4605 - val_mae: 6.5474\n",
            "Epoch 2196/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.1699 - mae: 6.5344 - val_loss: 77.4660 - val_mae: 6.5486\n",
            "Epoch 2197/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.7138 - mae: 6.5073 - val_loss: 77.4761 - val_mae: 6.5472\n",
            "Epoch 2198/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.4901 - mae: 6.4957 - val_loss: 77.6991 - val_mae: 6.5464\n",
            "Epoch 2199/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.7636 - mae: 6.5108 - val_loss: 77.5194 - val_mae: 6.5479\n",
            "Epoch 2200/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.3145 - mae: 6.5247 - val_loss: 77.7036 - val_mae: 6.5478\n",
            "Epoch 2201/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0309 - mae: 6.5153 - val_loss: 77.5131 - val_mae: 6.5460\n",
            "Epoch 2202/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6537 - mae: 6.4993 - val_loss: 77.5039 - val_mae: 6.5478\n",
            "Epoch 2203/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.6153 - mae: 6.5062 - val_loss: 77.4461 - val_mae: 6.5479\n",
            "Epoch 2204/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.3312 - mae: 6.5038 - val_loss: 77.4666 - val_mae: 6.5467\n",
            "Epoch 2205/10000\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 75.8915 - mae: 6.5206 - val_loss: 77.4807 - val_mae: 6.5479\n",
            "Epoch 2206/10000\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 75.4603 - mae: 6.4888 - val_loss: 77.4321 - val_mae: 6.5460\n",
            "Epoch 2207/10000\n",
            "500/500 [==============================] - 5s 10ms/step - loss: 75.6498 - mae: 6.5138 - val_loss: 77.3936 - val_mae: 6.5474\n",
            "Epoch 2208/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.6182 - mae: 6.4996 - val_loss: 77.5994 - val_mae: 6.5474\n",
            "Epoch 2209/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.9350 - mae: 6.5126 - val_loss: 77.5246 - val_mae: 6.5473\n",
            "Epoch 2210/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.8061 - mae: 6.4955 - val_loss: 77.2609 - val_mae: 6.5482\n",
            "Epoch 2211/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 75.9199 - mae: 6.5164 - val_loss: 77.4516 - val_mae: 6.5457\n",
            "Epoch 2212/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0238 - mae: 6.5294 - val_loss: 77.3272 - val_mae: 6.5464\n",
            "Epoch 2213/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.4192 - mae: 6.4976 - val_loss: 77.4007 - val_mae: 6.5457\n",
            "Epoch 2214/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0215 - mae: 6.5292 - val_loss: 77.3121 - val_mae: 6.5468\n",
            "Epoch 2215/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.8020 - mae: 6.5307 - val_loss: 77.4575 - val_mae: 6.5460\n",
            "Epoch 2216/10000\n",
            "500/500 [==============================] - 3s 7ms/step - loss: 75.4050 - mae: 6.4982 - val_loss: 77.4125 - val_mae: 6.5475\n",
            "Epoch 2217/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.8982 - mae: 6.5113 - val_loss: 77.3347 - val_mae: 6.5468\n",
            "Epoch 2218/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.0585 - mae: 6.4861 - val_loss: 77.2314 - val_mae: 6.5478\n",
            "Epoch 2219/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.8698 - mae: 6.5254 - val_loss: 77.4715 - val_mae: 6.5477\n",
            "Epoch 2220/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0402 - mae: 6.5324 - val_loss: 77.4148 - val_mae: 6.5469\n",
            "Epoch 2221/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.5538 - mae: 6.4928 - val_loss: 77.4311 - val_mae: 6.5456\n",
            "Epoch 2222/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 76.0608 - mae: 6.5284 - val_loss: 77.3606 - val_mae: 6.5470\n",
            "Epoch 2223/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 75.1578 - mae: 6.4929 - val_loss: 77.2218 - val_mae: 6.5478\n",
            "Epoch 2224/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6725 - mae: 6.4912 - val_loss: 77.3013 - val_mae: 6.5487\n",
            "Epoch 2225/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6101 - mae: 6.5015 - val_loss: 77.4590 - val_mae: 6.5453\n",
            "Epoch 2226/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6799 - mae: 6.5094 - val_loss: 77.3041 - val_mae: 6.5462\n",
            "Epoch 2227/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6616 - mae: 6.5051 - val_loss: 77.3528 - val_mae: 6.5463\n",
            "Epoch 2228/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9458 - mae: 6.5230 - val_loss: 77.1991 - val_mae: 6.5480\n",
            "Epoch 2229/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.2527 - mae: 6.5027 - val_loss: 77.1505 - val_mae: 6.5429\n",
            "Epoch 2230/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6709 - mae: 6.5074 - val_loss: 77.2402 - val_mae: 6.5467\n",
            "Epoch 2231/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9021 - mae: 6.5300 - val_loss: 77.2764 - val_mae: 6.5449\n",
            "Epoch 2232/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.5442 - mae: 6.5239 - val_loss: 77.2352 - val_mae: 6.5459\n",
            "Epoch 2233/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 76.0917 - mae: 6.5241 - val_loss: 77.1924 - val_mae: 6.5470\n",
            "Epoch 2234/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6067 - mae: 6.4996 - val_loss: 77.2767 - val_mae: 6.5459\n",
            "Epoch 2235/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.7198 - mae: 6.5196 - val_loss: 77.1178 - val_mae: 6.5463\n",
            "Epoch 2236/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 76.0242 - mae: 6.5262 - val_loss: 77.2342 - val_mae: 6.5461\n",
            "Epoch 2237/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9382 - mae: 6.5232 - val_loss: 77.1546 - val_mae: 6.5458\n",
            "Epoch 2238/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 75.7313 - mae: 6.5120 - val_loss: 77.1556 - val_mae: 6.5463\n",
            "Epoch 2239/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 75.4697 - mae: 6.5072 - val_loss: 77.2825 - val_mae: 6.5442\n",
            "Epoch 2240/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.9010 - mae: 6.5036 - val_loss: 77.1612 - val_mae: 6.5460\n",
            "Epoch 2241/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.4755 - mae: 6.5125 - val_loss: 77.1577 - val_mae: 6.5472\n",
            "Epoch 2242/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.6328 - mae: 6.5110 - val_loss: 77.3177 - val_mae: 6.5437\n",
            "Epoch 2243/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.5899 - mae: 6.5119 - val_loss: 77.2992 - val_mae: 6.5437\n",
            "Epoch 2244/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.5115 - mae: 6.5073 - val_loss: 77.0913 - val_mae: 6.5464\n",
            "Epoch 2245/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.3182 - mae: 6.5034 - val_loss: 77.1988 - val_mae: 6.5450\n",
            "Epoch 2246/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.3900 - mae: 6.5180 - val_loss: 77.2658 - val_mae: 6.5443\n",
            "Epoch 2247/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.4316 - mae: 6.5165 - val_loss: 77.1592 - val_mae: 6.5467\n",
            "Epoch 2248/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.4144 - mae: 6.5217 - val_loss: 77.2083 - val_mae: 6.5464\n",
            "Epoch 2249/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.1976 - mae: 6.4951 - val_loss: 77.1839 - val_mae: 6.5451\n",
            "Epoch 2250/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.5189 - mae: 6.4920 - val_loss: 77.0858 - val_mae: 6.5471\n",
            "Epoch 2251/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.6626 - mae: 6.5299 - val_loss: 77.2025 - val_mae: 6.5451\n",
            "Epoch 2252/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.2591 - mae: 6.5085 - val_loss: 77.1886 - val_mae: 6.5464\n",
            "Epoch 2253/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.5357 - mae: 6.5084 - val_loss: 77.2057 - val_mae: 6.5454\n",
            "Epoch 2254/10000\n",
            "500/500 [==============================] - 4s 7ms/step - loss: 75.2774 - mae: 6.5068 - val_loss: 77.1987 - val_mae: 6.5464\n",
            "Epoch 2255/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.5757 - mae: 6.5090 - val_loss: 77.1286 - val_mae: 6.5443\n",
            "Epoch 2256/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.2969 - mae: 6.5045 - val_loss: 77.2216 - val_mae: 6.5438\n",
            "Epoch 2257/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.3848 - mae: 6.5053 - val_loss: 77.0824 - val_mae: 6.5440\n",
            "Epoch 2258/10000\n",
            "500/500 [==============================] - 4s 9ms/step - loss: 75.3797 - mae: 6.5061 - val_loss: 77.0489 - val_mae: 6.5452\n",
            "Epoch 2259/10000\n",
            "500/500 [==============================] - 4s 8ms/step - loss: 75.7318 - mae: 6.5159 - val_loss: 77.0902 - val_mae: 6.5456\n",
            "157/157 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "history_1 = model_1.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10000,\n",
        "    verbose=1,\n",
        "    validation_split=0.2,\n",
        "    callbacks=callback\n",
        ")\n",
        "\n",
        "y_test_hat_1 = model_1.predict(x_test)\n",
        "\n",
        "df_ensemble['model_1'] = y_test_hat_1.reshape(-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6gLkztTiRfL"
      },
      "source": [
        "**Model 2 (Boosting) predictions:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGavlolCgcaW"
      },
      "outputs": [],
      "source": [
        "model_2 = ensemble.GradientBoostingRegressor(\n",
        "                n_estimators=8000,\n",
        "                min_samples_split=250,\n",
        "                min_samples_leaf=10,\n",
        "                learning_rate=0.5,\n",
        "                )\n",
        "\n",
        "model_2.fit(x_train, y_train)\n",
        "y_test_hat_2 = model_2.predict(x_test)\n",
        "\n",
        "df_ensemble['model_2'] = y_test_hat_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOKpoW8eiTWp"
      },
      "source": [
        "**Model 3 (Random Forest) predictions:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGZbEppDg1rm"
      },
      "outputs": [],
      "source": [
        "model_3 = ensemble.RandomForestRegressor(\n",
        "                n_estimators=500,\n",
        "                min_samples_split=20,\n",
        "                min_samples_leaf=10,\n",
        "                max_depth=None,\n",
        "                max_features=20,\n",
        "                )\n",
        "\n",
        "model_3.fit(x_train, y_train)\n",
        "y_test_hat_3 = model_3.predict(x_test)\n",
        "\n",
        "df_ensemble['model_3'] = y_test_hat_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFgtq8xzimXx"
      },
      "source": [
        "### The average prediction over the three models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bRYIuKfipsn",
        "outputId": "d04adcd3-bc11-439e-8789-e6dd96b75b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        model_1    model_2    model_3    average\n",
            "0      6.129264  10.422166   8.078810   8.210080\n",
            "1      5.923067   5.080645   9.020399   6.674703\n",
            "2      6.377745   3.161189   8.518992   6.019309\n",
            "3      5.546168   5.883326   8.213910   6.547801\n",
            "4     10.324500  21.553088  10.171601  14.016396\n",
            "...         ...        ...        ...        ...\n",
            "4995   7.265414   0.131600   9.337331   5.578115\n",
            "4996   6.472367  19.041145  10.627036  12.046849\n",
            "4997   5.628162   7.331959   7.751156   6.903759\n",
            "4998   6.155091  16.110981   8.895622  10.387231\n",
            "4999   7.124936   3.606870   9.545064   6.758956\n",
            "\n",
            "[5000 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "df_ensemble['average'] = df_ensemble.mean(axis=1)\n",
        "\n",
        "print(df_ensemble)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ensemble = pd.DataFrame({\n",
        "    'Id': range(len(df_ensemble)),\n",
        "    'Predicted': df_ensemble['model_3'].values,\n",
        "})\n",
        "\n",
        "path_on_drive = '/content/gdrive/My Drive/Assignment 3/pred.csv'\n",
        "df_ensemble.to_csv(path_on_drive, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "lr-f8MDHKbkZ",
        "outputId": "2f6f8c9d-2e50-48d2-d6fe-13b969816e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'model_3'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c39838fabd20>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df_ensemble = pd.DataFrame({\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_ensemble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m })\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'model_3'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_hat_1 = model_1.predict(x_test)\n",
        "\n",
        "df_ensemble['model_1'] = y_test_hat_1.reshape(-1)\n",
        "\n",
        "\n",
        "y_test_hat_2 = model_2.predict(x_test)\n",
        "\n",
        "df_ensemble['model_2'] = y_test_hat_2\n",
        "\n",
        "\n",
        "y_test_hat_3 = model_3.predict(x_test)\n",
        "\n",
        "df_ensemble['model_3'] = y_test_hat_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seSkllTqLaUV",
        "outputId": "edc5e667-44bd-42da-be88-29b60014117f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ensemble = pd.DataFrame({\n",
        "    'Id': range(len(df_ensemble)),\n",
        "    'Predicted': df_ensemble['model_1'].values,\n",
        "})\n",
        "\n",
        "path_on_drive = '/content/gdrive/My Drive/Assignment 3/pred.csv'\n",
        "df_ensemble.to_csv(path_on_drive, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "NLcGoohjMDhA",
        "outputId": "cd2d5f33-8562-41a4-a220-9dc405a65714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'model_1'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-56959be427d7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m df_ensemble = pd.DataFrame({\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'Id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_ensemble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf_ensemble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m })\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'model_1'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 1: 8.89**\n",
        "\n",
        "**Model 2: 9.98**\n",
        "\n",
        "**Model 3: 8.463**\n",
        "\n",
        "Train model 1 and 2.\n",
        "\n",
        "Make predictions with the new hyperparameters...\n",
        "\n"
      ],
      "metadata": {
        "id": "5xvwiKIzNK9R"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}