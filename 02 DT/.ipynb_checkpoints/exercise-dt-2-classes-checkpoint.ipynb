{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - DT for classification of 2 classes\n",
    "\n",
    "1. Use the **load_breast_cancer** data (remember to split your data into a train and a test set). Try to implement a decision tree classifer (with default settings). How well does it perform (i.e. what is its accuracy in diagnosing whether patients have cancer)? \n",
    "1. Try different values for **max_depth** (must be integers), **min_samples_split** (must be integers OR a fraction), **min_samples_leaf** (must be integers OR a fraction), and **max_features** (can be an integer, a fraction, or one of \"auto\", \"log2\").\n",
    "\n",
    "**See slides for more details!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Use the **load_breast_cancer** data (remember to split your data into a train and a test set). Try to implement a decision tree classifer (with default settings). How well does it perform (i.e. what is its accuracy in diagnosing whether patients have cancer)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1189019093.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 11\u001b[1;36m\u001b[0m\n\u001b[1;33m    X_train, X_test, y_train, y_test =\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Use the `load_breast_cancer` function to construct your dataset\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Use `train_test_split` to split your data into a train and a test set.\n",
    "X_train, X_test, y_train, y_test = train_test\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DT\n",
    "dt_default = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Fit your DT\n",
    "dt_default\n",
    "\n",
    "# Predict on your test data with your DT\n",
    "y_test_hat_default = \n",
    "\n",
    "# Obtain accuracy by using the `accuracy_score` function\n",
    "accuracy_default = \n",
    "\n",
    "# Print results\n",
    "print(f'DT with default settings achieved {round(accuracy_default * 100, 1)}% accuracy.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try also to print the depth of the tree (see slides for example code).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the tree - you do not have to chance any code here. It will be a bit small.\n",
    "fig = plt.figure(figsize=plt.figaspect(0.2))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "tree.plot_tree(dt_default, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Try different values for **max_depth** (must be integers), **min_samples_split** (must be integers OR a fraction), **min_samples_leaf** (must be integers OR a fraction), and **max_features** (can be an integer, a fraction, or one of \"auto\", \"log2\").\n",
    "\n",
    "I suggest going through each setting one at a time, just playing around with a more restricted (specifically smaller) setting than the default value. The reason is that the default value of each is the unrestricted version.\n",
    "\n",
    "This means that you should try low values for **max_depth**, **min_samples_split**, **min_samples_leaf**, and **max_features**. However, note that you may use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try low values for max_depth.\n",
    "\n",
    "max_depth = 5 # try more values than just 5 here! Also try fractions!\n",
    "\n",
    "# Initialize DT\n",
    "dt_low_max_depth = tree.DecisionTreeClassifier(max_depth=max_depth)\n",
    "\n",
    "# Fit your DT\n",
    "dt_low_max_depth\n",
    "\n",
    "# Predict on your test data\n",
    "y_test_hat_dt_low_max_depth = \n",
    "\n",
    "# Obtain accuraciy\n",
    "accuracy_low_max_depth = \n",
    "\n",
    "# Print results\n",
    "print(f'DT with restricted max_depth achieved {round(accuracy_low_max_depth * 100, 1)}% accuracy.')\n",
    "\n",
    "# Try also to print the depth of the tree (see slides for example code). This should be what you set it to!\n",
    "print(f'Depth with restricted max_depth: {dt_low_max_depth.get_depth()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try low values for min_samples_split.\n",
    "\n",
    "min_samples_split = 10 # try more values than just 10 here! Also try fractions!\n",
    "\n",
    "# Initialize DT\n",
    "dt_low_min_samples_split = tree.DecisionTreeClassifier(min_samples_split=min_samples_split)\n",
    "\n",
    "# Fit your DT\n",
    "dt_low_min_samples_split\n",
    "\n",
    "# Predict on your test data\n",
    "y_test_hat_dt_low_min_samples_split = \n",
    "\n",
    "# Obtain accuraciy\n",
    "accuracy_low_min_samples_split = \n",
    "\n",
    "# Print results\n",
    "\n",
    "\n",
    "# Try also to print the depth of the tree (see slides for example code).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try low values for max_features.\n",
    "\n",
    "min_samples_leaf = 3 # try more values than just 3 here!\n",
    "\n",
    "# Initialize DT\n",
    "dt_low_min_samples_leaf = tree.DecisionTreeClassifier(min_samples_leaf=min_samples_leaf)\n",
    "\n",
    "# Fit your DT\n",
    "dt_low_min_samples_leaf\n",
    "\n",
    "# Predict on your test data\n",
    "y_test_hat_dt_low_min_samples_leaf = \n",
    "\n",
    "# Obtain accuraciy\n",
    "accuracy_low_min_samples_leaf = \n",
    "\n",
    "# Print results\n",
    "print(f'DT with restricted min_samples_leaf achieved {round(accuracy_low_min_samples_leaf * 100, 1)}% accuracy.')\n",
    "\n",
    "# Try also to print the depth of the tree (see slides for example code).\n",
    "print(f'Depth with restricted max_depth: {dt_low_min_samples_leaf.get_depth()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try low values for min_samples_leaf.\n",
    "\n",
    "max_features = 5 # try more values than just 5 here! Also try fraction, \"auto\", and \"log2\"\n",
    "\n",
    "# Initialize DT\n",
    "dt_low_max_features = \n",
    "\n",
    "# Fit your DT\n",
    "dt_low_max_features\n",
    "\n",
    "# Predict on your test data\n",
    "y_test_hat_dt_low_max_features = dt_low_max_features\n",
    "\n",
    "# Obtain accuraciy\n",
    "accuracy_low_max_features = \n",
    "\n",
    "# Print results\n",
    "print(f'DT with restricted max_features achieved {round(accuracy_low_max_features * 100, 1)}% accuracy.')\n",
    "\n",
    "# Try also to print the depth of the tree (see slides for example code).\n",
    "print(f'Depth with restricted max_depth: {dt_low_max_features.get_depth()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
