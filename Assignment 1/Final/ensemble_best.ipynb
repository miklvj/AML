{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz1WoPP36A3m"
   },
   "source": [
    "**Imports:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "yrasc0955zP9"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import mode\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98iXXryHyCJ8"
   },
   "source": [
    "**Get acess to the data from google drive:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QI1cYs8lu7ol",
    "outputId": "3b9c8833-8e10-4e1c-8080-31766b804a02"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dUu5IOEJ6FEq"
   },
   "source": [
    "**Defining a function that grayscale, resize and flattens the image:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Wjgt4QFf6Gdu"
   },
   "outputs": [],
   "source": [
    "def convert_sample(image):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.image.resize(image,[32,32]).numpy()\n",
    "    image = image.reshape(1,-1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yn7GtsWJ6PI4"
   },
   "source": [
    "**Create X, y and Xtest - the function convert_sample is used:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ao53S8Dc6QIh",
    "outputId": "01e51621-a379-4435-f98b-e6465c9250ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikke\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data features (observations,features): (26214, 1024)\n",
      "Shape of training data labels (observations,): (26214,)\n",
      "Shape of test data features (observations,features): (1638, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mikke\\anaconda3\\envs\\amlfall23\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:591: FutureWarning: Passing an int for a boolean parameter is deprecated in version 1.2 and won't be supported anymore in version 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = np.load('C:/Users/mikke/OneDrive - Syddansk Universitet/Data Science/10. Anvendt Maskinlæring/project/Assignment 1/Xtrain.npy')\n",
    "X = np.vstack(list(map(convert_sample,X)))\n",
    "X = StandardScaler(with_mean=0, with_std=1).fit_transform(X)\n",
    "print(f'Shape of training data features (observations,features): {X.shape}')\n",
    "\n",
    "y = np.load('C:/Users/mikke/OneDrive - Syddansk Universitet/Data Science/10. Anvendt Maskinlæring/project/Assignment 1/ytrain.npy')\n",
    "y = y.reshape(-1,)\n",
    "print(f'Shape of training data labels (observations,): {y.shape}')\n",
    "\n",
    "Xtest = np.load('C:/Users/mikke/OneDrive - Syddansk Universitet/Data Science/10. Anvendt Maskinlæring/project/Assignment 1/Xtest.npy')\n",
    "Xtest = np.vstack(list(map(convert_sample,Xtest)))\n",
    "Xtest = StandardScaler(with_mean=0, with_std=1).fit_transform(Xtest)\n",
    "print(f'Shape of test data features (observations,features): {Xtest.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4dbiQbQ_GKg"
   },
   "source": [
    "**Compute the explained variance over the principal components:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "su548XZg_cx0"
   },
   "source": [
    "**We want to explain 95 pct. of the variance:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH8DTg6z_kLI"
   },
   "source": [
    "**Reduce the dimentions to the number of principal components that explain 0.95 pct. of the variance:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8BbApHq1Bwb3"
   },
   "source": [
    "**Split in train/val for hyperparameter search:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "quc0OKpcBrBK"
   },
   "outputs": [],
   "source": [
    "X_reduced, _, y_reduced, _ = train_test_split(X, y, test_size=0.90, random_state=42)\n",
    "\n",
    "X_train_h, X_val_h, y_train_h, y_val_h = train_test_split(X_reduced, y_reduced, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRW1cNX4eucY"
   },
   "source": [
    "**Create 9 ensambles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "e-094zUH7LL2"
   },
   "outputs": [],
   "source": [
    "num_ensembles = 9\n",
    "samples_per_ensemble = X.shape[0] // num_ensembles\n",
    "\n",
    "#np.random.seed(42)\n",
    "\n",
    "for i in range(1, 10):\n",
    "\n",
    "    indices = np.random.choice(X.shape[0], samples_per_ensemble, replace=False)\n",
    "\n",
    "    X_subset = X[indices]\n",
    "    y_subset = y[indices]\n",
    "\n",
    "    globals()[f'X_{i}'] = X_subset\n",
    "    globals()[f'y_{i}'] = y_subset\n",
    "\n",
    "    X = np.delete(X, indices, axis=0)\n",
    "    y = np.delete(y, indices, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHWiCCewgS7g"
   },
   "source": [
    "**Print the shape of the ensambles:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4S4K-0ufqq6",
    "outputId": "8a34b31b-55b7-4e32-eae7-885f040ebad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2912, 1024)\n",
      "(2912,)\n",
      "(2912, 1024)\n",
      "(2912,)\n",
      "(2912, 1024)\n",
      "(2912,)\n",
      "(2912, 1024)\n",
      "(2912,)\n",
      "(2912, 1024)\n",
      "(2912,)\n",
      "(2912, 1024)\n",
      "(2912,)\n",
      "(2912, 1024)\n",
      "(2912,)\n",
      "(2912, 1024)\n",
      "(2912,)\n",
      "(2912, 1024)\n",
      "(2912,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    X = globals()[f'X_{i}']\n",
    "    y = globals()[f'y_{i}']\n",
    "    print(X.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDEGCNYxmKuj"
   },
   "source": [
    "**Hyperparameter search SVM:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Oy7g58mWmJla"
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'C': [0.1, 0.25, 0.5, 0.75, 1, 10], })\n",
    "\n",
    "score_ = 0\n",
    "params_ = None\n",
    "for params in param_grid:\n",
    "  svm_rbf = svm.SVC(kernel='rbf', C=params['C'])\n",
    "  svm_rbf.fit(X_train_h, y_train_h)\n",
    "  y_val_hat_rbf = svm_rbf.predict(X_val_h)\n",
    "  accuracy_rbf = accuracy_score(y_val_hat_rbf, y_val_h)\n",
    "  if accuracy_rbf > score_:\n",
    "    score_ = accuracy_rbf\n",
    "    params_ = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DNfd9pLCHaw",
    "outputId": "d49db93d-868a-4393-c7bb-35844dabd979"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For SVM - using radial and the best hyperparameter C: {'C': 0.5}, the accuracy of the model is: 0.7219047619047619\n"
     ]
    }
   ],
   "source": [
    "print(f\"For SVM - using radial and the best hyperparameter C: {params_}, the accuracy of the model is: {accuracy_rbf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Up36V6OU5dYa"
   },
   "source": [
    "**Hyperparameter search RF:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "LZrEyL5V5ik5"
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'n_estimators': [500, 1000],\n",
    "    'min_samples_split': [10, 20, 50],\n",
    "    'min_samples_leaf': [10, 20, 50],\n",
    "    'max_depth': [None, 300, 200],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "    })\n",
    "\n",
    "score_ = 0\n",
    "params_ = None\n",
    "for params in param_grid:\n",
    "  rf_current = ensemble.RandomForestClassifier(\n",
    "                n_estimators=params['n_estimators'],\n",
    "                min_samples_split=params['min_samples_split'],\n",
    "                min_samples_leaf=params['min_samples_leaf'],\n",
    "                max_depth=params['max_depth'],\n",
    "                max_features=params['max_features'],\n",
    "                )\n",
    "  rf_current.fit(X_train_h, y_train_h)\n",
    "  y_val_hat = rf_current.predict(X_val_h)\n",
    "  accuracy = accuracy_score(y_val_hat, y_val_h)\n",
    "  if accuracy > score_:\n",
    "    score_ = accuracy\n",
    "    params_ = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MS-KIBtDCKJ-",
    "outputId": "ad70d2e6-f561-4c60-9158-195440a85689"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For RF the best hyperparameters are: {'max_depth': 300, 'max_features': 'log2', 'min_samples_leaf': 10, 'min_samples_split': 50, 'n_estimators': 500}, the accuracy of the model is: 0.7314285714285714\n"
     ]
    }
   ],
   "source": [
    "print(f\"For RF the best hyperparameters are: {params_}, the accuracy of the model is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoKjRoqUBGWg"
   },
   "source": [
    "**Hyperparameter search GB:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "Wo8-HI6Ms44z",
    "outputId": "1fa0cd4f-b172-43eb-8b3a-06ab168d1f6c"
   },
   "outputs": [],
   "source": [
    "\n",
    "param_grid = ParameterGrid({\n",
    "    'n_estimators': [500, 1000],\n",
    "    'min_samples_split': [10, 20, 50],\n",
    "    'min_samples_leaf': [10, 20, 50],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 0.75],\n",
    "    })\n",
    "\n",
    "score_ = 0\n",
    "params_ = None\n",
    "\n",
    "for params in param_grid:\n",
    "  gbt_current = ensemble.GradientBoostingClassifier(\n",
    "                n_estimators=params['n_estimators'],\n",
    "                min_samples_split=params['min_samples_split'],\n",
    "                min_samples_leaf=params['min_samples_leaf'],\n",
    "                learning_rate=params['learning_rate'],\n",
    "                )\n",
    "  gbt_current.fit(X_train_h, y_train_h)\n",
    "  y_val_hat = gbt_current.predict(X_val_h)\n",
    "  accuracy = accuracy_score(y_val_hat, y_val_h)\n",
    "  if accuracy > score_:\n",
    "    score_ = accuracy\n",
    "    params_ = params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "UMtgfrMnEvk4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For GB the best hyperparameters are: {'learning_rate': 0.1, 'min_samples_leaf': 20, 'min_samples_split': 50, 'n_estimators': 1000}, the accuracy of the model is: 0.7561904761904762\n"
     ]
    }
   ],
   "source": [
    "print(f\"For GB the best hyperparameters are: {params_}, the accuracy of the model is: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65vKS4vCEXHf"
   },
   "source": [
    "**Initiate the models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_6aAFWWPC5jz"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm1 = svm.SVC(kernel='rbf', C=0.75)\n",
    "\n",
    "rf1 = ensemble.RandomForestClassifier(\n",
    "                n_estimators=500,\n",
    "                min_samples_split=50,\n",
    "                min_samples_leaf=10,\n",
    "                max_depth=300,\n",
    "                max_features='sqrt',\n",
    "                )\n",
    "\n",
    "gb1 = ensemble.GradientBoostingClassifier(\n",
    "                n_estimators=500,\n",
    "                min_samples_split=10,\n",
    "                min_samples_leaf=20,\n",
    "                learning_rate=0.05,\n",
    "                )\n",
    "\n",
    "models1 = [svm1, rf1, gb1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Xmw13Elru0HT"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm2 = svm.SVC(kernel='rbf', C=1.0)\n",
    "\n",
    "rf2 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=800,\n",
    "    min_samples_split=40,\n",
    "    min_samples_leaf=5,\n",
    "    max_depth=200,\n",
    "    max_features='log2',\n",
    ")\n",
    "\n",
    "gb2 = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=800,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "models2 = [svm2, rf2, gb2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "bIahQib6u0ba"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm3 = svm.SVC(kernel='rbf', C=0.5)\n",
    "\n",
    "rf3 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=1000,\n",
    "    min_samples_split=30,\n",
    "    min_samples_leaf=2,\n",
    "    max_depth=700,\n",
    "    max_features=20,\n",
    ")\n",
    "\n",
    "gb3 = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=1000,\n",
    "    min_samples_split=40,\n",
    "    min_samples_leaf=5,\n",
    "    learning_rate=0.15,\n",
    ")\n",
    "\n",
    "models3 = [svm3, rf3, gb3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "R9P-TP1nu0lh"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm4 = svm.SVC(kernel='rbf', C=1.5)\n",
    "\n",
    "rf4 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=1200,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=1,\n",
    "    max_depth=400,\n",
    "    max_features=50,\n",
    ")\n",
    "\n",
    "gb4 = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=1200,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=30,\n",
    "    learning_rate=0.01,\n",
    ")\n",
    "\n",
    "models4 = [svm4, rf4, gb4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "4cLTNWRWu0sM"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm5 = svm.SVC(kernel='rbf', C=1.2)\n",
    "\n",
    "rf5 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=1500,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=4,\n",
    "    max_depth=150,\n",
    "    max_features='log2',\n",
    ")\n",
    "\n",
    "gb5 = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=750,\n",
    "    min_samples_split=30,\n",
    "    min_samples_leaf=15,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "models5 = [svm5, rf5, gb5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "wUE46BX5u0wd"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm6 = svm.SVC(kernel='rbf', C=0.9)\n",
    "\n",
    "rf6 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=1700,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_depth=250,\n",
    "    max_features=150,\n",
    ")\n",
    "\n",
    "gb6 = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=1100,\n",
    "    min_samples_split=50,\n",
    "    min_samples_leaf=5,\n",
    "    learning_rate=0.05,\n",
    ")\n",
    "\n",
    "models6 = [svm6, rf6, gb6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PJLWaZS4u0z-"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm7 = svm.SVC(kernel='rbf', C=0.8)\n",
    "\n",
    "rf7 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=2000,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=1,\n",
    "    max_depth=350,\n",
    "    max_features=200,\n",
    ")\n",
    "\n",
    "gb7 = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=10,\n",
    "    learning_rate=0.2,\n",
    ")\n",
    "\n",
    "models7 = [svm7, rf7, gb7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "NEoHJWKwu03f"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm8 = svm.SVC(kernel='rbf', C=1.3)\n",
    "\n",
    "rf8 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=1700,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    max_depth=400,\n",
    "    max_features='sqrt',\n",
    ")\n",
    "\n",
    "gb8 = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=900,\n",
    "    min_samples_split=25,\n",
    "    min_samples_leaf=7,\n",
    "    learning_rate=0.15,\n",
    ")\n",
    "\n",
    "models8 = [svm8, rf8, gb8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "RF7Pv6Ynu07D"
   },
   "outputs": [],
   "source": [
    "\n",
    "svm9 = svm.SVC(kernel='rbf', C=0.6)\n",
    "\n",
    "rf9 = ensemble.RandomForestClassifier(\n",
    "    n_estimators=1250,\n",
    "    min_samples_split=30,\n",
    "    min_samples_leaf=3,\n",
    "    max_depth=450,\n",
    "    max_features=50,\n",
    ")\n",
    "\n",
    "gb9 = ensemble.GradientBoostingClassifier(\n",
    "    n_estimators=800,\n",
    "    min_samples_split=35,\n",
    "    min_samples_leaf=20,\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "\n",
    "models9 = [svm9, rf9, gb9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "GYdY7ItcDEN7"
   },
   "outputs": [],
   "source": [
    "df_ensemble = pd.DataFrame(columns=['df1', 'df2', 'df3', 'df4', 'df5', 'df6', 'df7', 'df8', 'df9'])\n",
    "\n",
    "for i in range(1, 10):\n",
    "\n",
    "  globals()[f'df{i}'] = pd.DataFrame(columns=['svm', 'rf', 'gb'])\n",
    "\n",
    "  X = globals()[f'X_{i}']\n",
    "  y = globals()[f'y_{i}']\n",
    "\n",
    "  current_df = globals()[f'df{i}']\n",
    "\n",
    "  column_index = 0\n",
    "\n",
    "  models = globals()[f'models{i}']\n",
    "\n",
    "  for model in models:\n",
    "    z = model.fit(X, y)\n",
    "    q = z.predict(Xtest)\n",
    "\n",
    "    column_name = current_df.columns[column_index]\n",
    "    current_df[column_name] = q\n",
    "    column_index += 1\n",
    "\n",
    "def calculate_majority(row):\n",
    "  counts = pd.Series(row).value_counts()\n",
    "  majority = counts.idxmax()\n",
    "  return majority\n",
    "\n",
    "column_index = 0\n",
    "\n",
    "for i in range(1, 10):\n",
    "\n",
    "  d = globals()[f'df{i}']\n",
    "  d['majority'] = d.apply(calculate_majority, axis=1)\n",
    "\n",
    "  df_ensemble.iloc[:, column_index] = d['majority']\n",
    "  column_index += 1\n",
    "\n",
    "df_ensemble['majority'] = df_ensemble.apply(calculate_majority, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RT4aLZQwwBSt"
   },
   "source": [
    "**Pred to CSV:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "XjeO2mZrwAgU"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_ensemble = pd.DataFrame({\n",
    "    'Id': range(len(df_ensemble)),\n",
    "    'Predicted': df_ensemble['majority'].values,\n",
    "})\n",
    "\n",
    "path_on_drive = 'C:/Users/mikke/OneDrive - Syddansk Universitet/Data Science/10. Anvendt Maskinlæring/project/Assignment 1/pred.csv'\n",
    "df_ensemble.to_csv(path_on_drive, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
